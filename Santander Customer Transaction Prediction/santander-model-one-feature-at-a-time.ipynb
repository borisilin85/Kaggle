{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge test/train datasets into a single one and separate unneeded columns\n",
    "target = train_df.pop('target')\n",
    "len_train = len(train_df)\n",
    "merged_df = pd.concat([train_df, test_df])\n",
    "#ID = merged_df.pop('ID_code')[len_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              test_0\n",
       "1              test_1\n",
       "2              test_2\n",
       "3              test_3\n",
       "4              test_4\n",
       "5              test_5\n",
       "6              test_6\n",
       "7              test_7\n",
       "8              test_8\n",
       "9              test_9\n",
       "10            test_10\n",
       "11            test_11\n",
       "12            test_12\n",
       "13            test_13\n",
       "14            test_14\n",
       "15            test_15\n",
       "16            test_16\n",
       "17            test_17\n",
       "18            test_18\n",
       "19            test_19\n",
       "20            test_20\n",
       "21            test_21\n",
       "22            test_22\n",
       "23            test_23\n",
       "24            test_24\n",
       "25            test_25\n",
       "26            test_26\n",
       "27            test_27\n",
       "28            test_28\n",
       "29            test_29\n",
       "             ...     \n",
       "199970    test_199970\n",
       "199971    test_199971\n",
       "199972    test_199972\n",
       "199973    test_199973\n",
       "199974    test_199974\n",
       "199975    test_199975\n",
       "199976    test_199976\n",
       "199977    test_199977\n",
       "199978    test_199978\n",
       "199979    test_199979\n",
       "199980    test_199980\n",
       "199981    test_199981\n",
       "199982    test_199982\n",
       "199983    test_199983\n",
       "199984    test_199984\n",
       "199985    test_199985\n",
       "199986    test_199986\n",
       "199987    test_199987\n",
       "199988    test_199988\n",
       "199989    test_199989\n",
       "199990    test_199990\n",
       "199991    test_199991\n",
       "199992    test_199992\n",
       "199993    test_199993\n",
       "199994    test_199994\n",
       "199995    test_199995\n",
       "199996    test_199996\n",
       "199997    test_199997\n",
       "199998    test_199998\n",
       "199999    test_199999\n",
       "Name: ID_code, Length: 200000, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.pop('ID_code')[len_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use lightgbm for prediction\n",
    "# Assume all features are independent, so fit model to one feature at a time\n",
    "# Then final prediction is a product of all predictions based on a single feature\n",
    "# Since data contains only one feature, do not use CV - just used fixed number of iterations\n",
    "params = {\n",
    "    'task': 'train', 'max_depth': 1, 'boosting_type': 'gbdt',\n",
    "    'objective': 'binary', 'num_leaves': 3, 'learning_rate': 0.1,\n",
    "    'feature_fraction': 0.9, 'bagging_fraction': 0.8, 'bagging_freq': 5,\n",
    "    'lambda_l1': 1, 'lambda_l2': 60, 'verbose': -99\n",
    "}\n",
    "num_runs = merged_df.shape[1]\n",
    "sub_preds = np.zeros([num_runs, merged_df.shape[0]-len_train])\n",
    "for run in range(num_runs): # loop over all features\n",
    "    lgb_train = lgb.Dataset(merged_df.iloc[:len_train, run:run+1], target)\n",
    "    gbm = lgb.train(params, lgb_train, 45, verbose_eval=1000)\n",
    "    sub_preds[run, :] = gbm.predict(merged_df.iloc[len_train:, run:run+1], num_iteration=gbm.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale prediction by inverse average target - to avoid very small numbers\n",
    "# Then multiply them for all features and write submission file\n",
    "sub_preds2 = (10 * sub_preds).prod(axis=0)\n",
    "out_df = pd.DataFrame({'ID_code': ID, 'target': sub_preds2.astype('float32')})\n",
    "out_df.to_csv('sub1f.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
