{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_curve,auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('train.csv')\n",
    "test=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
       "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
       "\n",
       "     var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  14.6155  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "3  14.9250  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
       "4  19.2514  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 202)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 201)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Columns: 202 entries, ID_code to var_199\n",
      "dtypes: float64(200), int64(1), object(1)\n",
      "memory usage: 308.2+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.100490</td>\n",
       "      <td>10.679914</td>\n",
       "      <td>-1.627622</td>\n",
       "      <td>10.715192</td>\n",
       "      <td>6.796529</td>\n",
       "      <td>11.078333</td>\n",
       "      <td>-5.065317</td>\n",
       "      <td>5.408949</td>\n",
       "      <td>16.545850</td>\n",
       "      <td>0.284162</td>\n",
       "      <td>...</td>\n",
       "      <td>3.234440</td>\n",
       "      <td>7.438408</td>\n",
       "      <td>1.927839</td>\n",
       "      <td>3.331774</td>\n",
       "      <td>17.993784</td>\n",
       "      <td>-0.142088</td>\n",
       "      <td>2.303335</td>\n",
       "      <td>8.908158</td>\n",
       "      <td>15.870720</td>\n",
       "      <td>-3.326537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.300653</td>\n",
       "      <td>3.040051</td>\n",
       "      <td>4.050044</td>\n",
       "      <td>2.640894</td>\n",
       "      <td>2.043319</td>\n",
       "      <td>1.623150</td>\n",
       "      <td>7.863267</td>\n",
       "      <td>0.866607</td>\n",
       "      <td>3.418076</td>\n",
       "      <td>3.332634</td>\n",
       "      <td>...</td>\n",
       "      <td>4.559922</td>\n",
       "      <td>3.023272</td>\n",
       "      <td>1.478423</td>\n",
       "      <td>3.992030</td>\n",
       "      <td>3.135162</td>\n",
       "      <td>1.429372</td>\n",
       "      <td>5.454369</td>\n",
       "      <td>0.921625</td>\n",
       "      <td>3.010945</td>\n",
       "      <td>10.438015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408400</td>\n",
       "      <td>-15.043400</td>\n",
       "      <td>2.117100</td>\n",
       "      <td>-0.040200</td>\n",
       "      <td>5.074800</td>\n",
       "      <td>-32.562600</td>\n",
       "      <td>2.347300</td>\n",
       "      <td>5.349700</td>\n",
       "      <td>-10.505500</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.093300</td>\n",
       "      <td>-2.691700</td>\n",
       "      <td>-3.814500</td>\n",
       "      <td>-11.783400</td>\n",
       "      <td>8.694400</td>\n",
       "      <td>-5.261000</td>\n",
       "      <td>-14.209600</td>\n",
       "      <td>5.960600</td>\n",
       "      <td>6.299300</td>\n",
       "      <td>-38.852800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.453850</td>\n",
       "      <td>-4.740025</td>\n",
       "      <td>8.722475</td>\n",
       "      <td>5.254075</td>\n",
       "      <td>9.883175</td>\n",
       "      <td>-11.200350</td>\n",
       "      <td>4.767700</td>\n",
       "      <td>13.943800</td>\n",
       "      <td>-2.317800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058825</td>\n",
       "      <td>5.157400</td>\n",
       "      <td>0.889775</td>\n",
       "      <td>0.584600</td>\n",
       "      <td>15.629800</td>\n",
       "      <td>-1.170700</td>\n",
       "      <td>-1.946925</td>\n",
       "      <td>8.252800</td>\n",
       "      <td>13.829700</td>\n",
       "      <td>-11.208475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.524750</td>\n",
       "      <td>-1.608050</td>\n",
       "      <td>10.580000</td>\n",
       "      <td>6.825000</td>\n",
       "      <td>11.108250</td>\n",
       "      <td>-4.833150</td>\n",
       "      <td>5.385100</td>\n",
       "      <td>16.456800</td>\n",
       "      <td>0.393700</td>\n",
       "      <td>...</td>\n",
       "      <td>3.203600</td>\n",
       "      <td>7.347750</td>\n",
       "      <td>1.901300</td>\n",
       "      <td>3.396350</td>\n",
       "      <td>17.957950</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>2.408900</td>\n",
       "      <td>8.888200</td>\n",
       "      <td>15.934050</td>\n",
       "      <td>-2.819550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.758200</td>\n",
       "      <td>1.358625</td>\n",
       "      <td>12.516700</td>\n",
       "      <td>8.324100</td>\n",
       "      <td>12.261125</td>\n",
       "      <td>0.924800</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.102900</td>\n",
       "      <td>2.937900</td>\n",
       "      <td>...</td>\n",
       "      <td>6.406200</td>\n",
       "      <td>9.512525</td>\n",
       "      <td>2.949500</td>\n",
       "      <td>6.205800</td>\n",
       "      <td>20.396525</td>\n",
       "      <td>0.829600</td>\n",
       "      <td>6.556725</td>\n",
       "      <td>9.593300</td>\n",
       "      <td>18.064725</td>\n",
       "      <td>4.836800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.315000</td>\n",
       "      <td>10.376800</td>\n",
       "      <td>19.353000</td>\n",
       "      <td>13.188300</td>\n",
       "      <td>16.671400</td>\n",
       "      <td>17.251600</td>\n",
       "      <td>8.447700</td>\n",
       "      <td>27.691800</td>\n",
       "      <td>10.151300</td>\n",
       "      <td>...</td>\n",
       "      <td>18.440900</td>\n",
       "      <td>16.716500</td>\n",
       "      <td>8.402400</td>\n",
       "      <td>18.281800</td>\n",
       "      <td>27.928800</td>\n",
       "      <td>4.272900</td>\n",
       "      <td>18.321500</td>\n",
       "      <td>12.000400</td>\n",
       "      <td>26.079100</td>\n",
       "      <td>28.500700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              target          var_0          var_1          var_2  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        0.100490      10.679914      -1.627622      10.715192   \n",
       "std         0.300653       3.040051       4.050044       2.640894   \n",
       "min         0.000000       0.408400     -15.043400       2.117100   \n",
       "25%         0.000000       8.453850      -4.740025       8.722475   \n",
       "50%         0.000000      10.524750      -1.608050      10.580000   \n",
       "75%         0.000000      12.758200       1.358625      12.516700   \n",
       "max         1.000000      20.315000      10.376800      19.353000   \n",
       "\n",
       "               var_3          var_4          var_5          var_6  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        6.796529      11.078333      -5.065317       5.408949   \n",
       "std         2.043319       1.623150       7.863267       0.866607   \n",
       "min        -0.040200       5.074800     -32.562600       2.347300   \n",
       "25%         5.254075       9.883175     -11.200350       4.767700   \n",
       "50%         6.825000      11.108250      -4.833150       5.385100   \n",
       "75%         8.324100      12.261125       0.924800       6.003000   \n",
       "max        13.188300      16.671400      17.251600       8.447700   \n",
       "\n",
       "               var_7          var_8  ...        var_190        var_191  \\\n",
       "count  200000.000000  200000.000000  ...  200000.000000  200000.000000   \n",
       "mean       16.545850       0.284162  ...       3.234440       7.438408   \n",
       "std         3.418076       3.332634  ...       4.559922       3.023272   \n",
       "min         5.349700     -10.505500  ...     -14.093300      -2.691700   \n",
       "25%        13.943800      -2.317800  ...      -0.058825       5.157400   \n",
       "50%        16.456800       0.393700  ...       3.203600       7.347750   \n",
       "75%        19.102900       2.937900  ...       6.406200       9.512525   \n",
       "max        27.691800      10.151300  ...      18.440900      16.716500   \n",
       "\n",
       "             var_192        var_193        var_194        var_195  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        1.927839       3.331774      17.993784      -0.142088   \n",
       "std         1.478423       3.992030       3.135162       1.429372   \n",
       "min        -3.814500     -11.783400       8.694400      -5.261000   \n",
       "25%         0.889775       0.584600      15.629800      -1.170700   \n",
       "50%         1.901300       3.396350      17.957950      -0.172700   \n",
       "75%         2.949500       6.205800      20.396525       0.829600   \n",
       "max         8.402400      18.281800      27.928800       4.272900   \n",
       "\n",
       "             var_196        var_197        var_198        var_199  \n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000  \n",
       "mean        2.303335       8.908158      15.870720      -3.326537  \n",
       "std         5.454369       0.921625       3.010945      10.438015  \n",
       "min       -14.209600       5.960600       6.299300     -38.852800  \n",
       "25%        -1.946925       8.252800      13.829700     -11.208475  \n",
       "50%         2.408900       8.888200      15.934050      -2.819550  \n",
       "75%         6.556725       9.593300      18.064725       4.836800  \n",
       "max        18.321500      12.000400      26.079100      28.500700  \n",
       "\n",
       "[8 rows x 201 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    179902\n",
       "1     20098\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_variance=[train[col].var() for col in train.columns[2:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9.241909296254263,\n",
       " 16.40285794058822,\n",
       " 6.974322132282455,\n",
       " 4.175152602617283,\n",
       " 2.634614409519367,\n",
       " 61.83096293547501,\n",
       " 0.7510081538599311,\n",
       " 11.683240663326504,\n",
       " 11.106446290054727,\n",
       " 1.5253977203803928,\n",
       " 30.25872370797137,\n",
       " 35.64392202439157,\n",
       " 0.03612251207720378,\n",
       " 21.52528967438517,\n",
       " 5.053091478198166,\n",
       " 0.16950629489308655,\n",
       " 6.540402138844952,\n",
       " 45.059165737617775,\n",
       " 61.64401466587767,\n",
       " 63.947111864741515,\n",
       " 34.530359963607,\n",
       " 67.18365560330284,\n",
       " 8.110864427020736,\n",
       " 0.27761671125509313,\n",
       " 14.267581524106065,\n",
       " 0.08153049999252396,\n",
       " 35.0725686923962,\n",
       " 2.32170504162537,\n",
       " 0.613664291894683,\n",
       " 6.843149984916999,\n",
       " 63.44438276774046,\n",
       " 4.665127421719668,\n",
       " 6.696861749472218,\n",
       " 18.68249155139209,\n",
       " 0.2933459379035042,\n",
       " 26.827831424098203,\n",
       " 9.734261692885541,\n",
       " 5.061284521485547,\n",
       " 18.309009471592272,\n",
       " 16.555496918533027,\n",
       " 68.5461327365231,\n",
       " 35.26088426217378,\n",
       " 0.48440360238838115,\n",
       " 0.09585180318760592,\n",
       " 34.846270320743535,\n",
       " 458.1702382354569,\n",
       " 8.182521178329633,\n",
       " 111.93346997096565,\n",
       " 129.60300968049432,\n",
       " 61.713004269903614,\n",
       " 0.4784614337142094,\n",
       " 67.03197789639206,\n",
       " 24.855531911015294,\n",
       " 0.5848471230793754,\n",
       " 70.79945360410574,\n",
       " 32.376921039586755,\n",
       " 12.532831111731577,\n",
       " 0.6320665654729449,\n",
       " 18.46150986911292,\n",
       " 0.7306798949018329,\n",
       " 17.82857081201673,\n",
       " 135.09292425660362,\n",
       " 4.105638607346244,\n",
       " 9.691323277884253,\n",
       " 2.207761500394476,\n",
       " 14.337532631352554,\n",
       " 1.2574606963083383,\n",
       " 54.24492204023734,\n",
       " 5.1642446088294624e-05,\n",
       " 15.647742513913117,\n",
       " 142.84412831168794,\n",
       " 0.07112682112397815,\n",
       " 15.56068042827099,\n",
       " 55.74568565259931,\n",
       " 199.1652161165729,\n",
       " 36.66691967281255,\n",
       " 63.017420619090515,\n",
       " 14.57172175875388,\n",
       " 3.975206917107163,\n",
       " 1.713624656088826,\n",
       " 55.30505370684103,\n",
       " 5.288008915361299,\n",
       " 71.89776863929201,\n",
       " 68.84401052308071,\n",
       " 38.75442840840141,\n",
       " 15.276653498219945,\n",
       " 60.080203049760605,\n",
       " 32.05673839699424,\n",
       " 6.207373109713438,\n",
       " 12.67754132542783,\n",
       " 172.9963985918896,\n",
       " 0.023299171617988657,\n",
       " 17.524702484020118,\n",
       " 0.2952195446138365,\n",
       " 7.66236957367715,\n",
       " 0.38579662569910045,\n",
       " 72.68244297433466,\n",
       " 159.82982523145836,\n",
       " 0.5124206876452136,\n",
       " 3.4690910666821586,\n",
       " 84.3032982665314,\n",
       " 24.507817531675098,\n",
       " 74.44547928926067,\n",
       " 0.034232233058071146,\n",
       " 3.8829472476319133,\n",
       " 0.7322190589501146,\n",
       " 3.5906408824774285,\n",
       " 57.83180841570865,\n",
       " 0.029272193026847693,\n",
       " 18.966295263276255,\n",
       " 14.617267319960321,\n",
       " 1.1715984390201037,\n",
       " 2.531821018068801,\n",
       " 19.88337034240079,\n",
       " 0.971005630967715,\n",
       " 6.874103650417825,\n",
       " 2.725510829015469,\n",
       " 176.8278225548891,\n",
       " 77.42711980319245,\n",
       " 17.495780459775336,\n",
       " 146.9190265794729,\n",
       " 2.9392234073711045,\n",
       " 26.713172411928063,\n",
       " 37.789846891145245,\n",
       " 7.49019120243809,\n",
       " 0.10118766692336462,\n",
       " 0.602262147361116,\n",
       " 9.845058630482303,\n",
       " 10.484920777755002,\n",
       " 17.11023945877045,\n",
       " 0.692555274058881,\n",
       " 0.20819167883268025,\n",
       " 2.121351996936042,\n",
       " 0.141077985674394,\n",
       " 38.021108675581196,\n",
       " 58.02984691842037,\n",
       " 107.79080736288752,\n",
       " 79.04126677626911,\n",
       " 20.71842737665156,\n",
       " 59.08125290123177,\n",
       " 23.973998985965366,\n",
       " 45.099783912418616,\n",
       " 32.398131668521025,\n",
       " 8.612499411366429,\n",
       " 0.8509483216075276,\n",
       " 15.204394720676335,\n",
       " 6.344771866933688,\n",
       " 54.95703415593999,\n",
       " 0.03967764673933614,\n",
       " 107.85098049830538,\n",
       " 6.072071330005399,\n",
       " 15.7008177190476,\n",
       " 9.032268708595192,\n",
       " 4.057003262865484,\n",
       " 24.61824382857035,\n",
       " 33.30745329288803,\n",
       " 0.9122928747696245,\n",
       " 31.027929025759562,\n",
       " 62.18235690182805,\n",
       " 16.998401360817436,\n",
       " 118.38011439376987,\n",
       " 0.047497113257654995,\n",
       " 2.0152990159312694,\n",
       " 27.689230273020335,\n",
       " 29.787409091995176,\n",
       " 25.24240817036739,\n",
       " 0.13666661743786737,\n",
       " 60.809117710762216,\n",
       " 9.647149459792605,\n",
       " 0.13648363396163077,\n",
       " 19.57726950153735,\n",
       " 28.92297517437227,\n",
       " 75.24123617114502,\n",
       " 35.6012002356236,\n",
       " 50.92858473231368,\n",
       " 8.364630954258903,\n",
       " 56.45928026476969,\n",
       " 6.91108691111698,\n",
       " 73.61314371085886,\n",
       " 7.83415686390565,\n",
       " 27.680674472195456,\n",
       " 1.8820062473235304,\n",
       " 80.34315020406109,\n",
       " 20.02494423293715,\n",
       " 86.83034743882251,\n",
       " 22.327202068304427,\n",
       " 10.174565271955734,\n",
       " 133.9738606621053,\n",
       " 15.559902941190009,\n",
       " 0.9532551816151627,\n",
       " 20.792885726919902,\n",
       " 9.140172344773319,\n",
       " 2.1857342485850144,\n",
       " 15.936306458250437,\n",
       " 9.829240743837941,\n",
       " 2.0431053561344465,\n",
       " 29.750143916101127,\n",
       " 0.8493935336685322,\n",
       " 9.065792751108674,\n",
       " 108.95215938132333]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var_81    -0.080917\n",
       "var_139   -0.074080\n",
       "var_12    -0.069489\n",
       "var_146   -0.063644\n",
       "var_76    -0.061917\n",
       "var_174   -0.061669\n",
       "var_21    -0.058483\n",
       "var_166   -0.057773\n",
       "var_80    -0.057609\n",
       "var_165   -0.055734\n",
       "var_13    -0.055156\n",
       "var_148   -0.055011\n",
       "var_198   -0.053000\n",
       "var_34    -0.052692\n",
       "var_115   -0.050174\n",
       "var_109   -0.049926\n",
       "var_44    -0.049039\n",
       "var_169   -0.048382\n",
       "var_149   -0.047319\n",
       "var_92    -0.046295\n",
       "var_154   -0.046106\n",
       "var_108   -0.044791\n",
       "var_33    -0.044334\n",
       "var_192   -0.042858\n",
       "var_9     -0.042805\n",
       "var_122   -0.042461\n",
       "var_123   -0.040291\n",
       "var_107   -0.039997\n",
       "var_121   -0.039788\n",
       "var_86    -0.039126\n",
       "             ...   \n",
       "var_35     0.036567\n",
       "var_155    0.037240\n",
       "var_95     0.038531\n",
       "var_89     0.039369\n",
       "var_91     0.040127\n",
       "var_147    0.040280\n",
       "var_118    0.040358\n",
       "var_164    0.040997\n",
       "var_173    0.042022\n",
       "var_18     0.043479\n",
       "var_67     0.044673\n",
       "var_94     0.046296\n",
       "var_191    0.047114\n",
       "var_170    0.047973\n",
       "var_78     0.048245\n",
       "var_184    0.048315\n",
       "var_40     0.049530\n",
       "var_179    0.050002\n",
       "var_1      0.050343\n",
       "var_0      0.052390\n",
       "var_133    0.054548\n",
       "var_2      0.055870\n",
       "var_190    0.055973\n",
       "var_99     0.058367\n",
       "var_22     0.060558\n",
       "var_26     0.062422\n",
       "var_53     0.063399\n",
       "var_110    0.064275\n",
       "var_6      0.066731\n",
       "target     1.000000\n",
       "Name: target, Length: 201, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.corr()['target'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train.drop(['target','ID_code'],axis=1,inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=test.drop('ID_code',axis=1,inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=train['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGB Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_validation,Y_train,Y_validation=train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model= xgb.XGBClassifier( learning_rate =0.2, n_estimators=250, max_depth=8, min_child_weight=1, gamma=0, subsample=0.8,\n",
    " colsample_bytree=0.8, objective= 'binary:logistic', eval_metric=\"auc\",nthread=4, scale_pos_weight=1, seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, Y_train)\n",
    "dvalid = xgb.DMatrix(X_validation, Y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"booster\" : \"gbtree\",\n",
    "        \"eval_metric\": \"auc\",\n",
    "        \"eta\": 0.2,\n",
    "        \"tree_method\": 'exact',\n",
    "        \"max_depth\": 17,\n",
    "        \"subsample\": 1,\n",
    "        \"colsample_bytree\": 1,\n",
    "        \"silent\": 1,\n",
    "        \"min_chil_weight\":1,\n",
    "        \"seed\": 42,\n",
    "        #\"num_class\" : 22,\n",
    "    }\n",
    "num_boost_round = 2000\n",
    "early_stopping_rounds = 50\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'eval')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.794417\teval-auc:0.647241\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 50 rounds.\n",
      "[1]\ttrain-auc:0.860938\teval-auc:0.683979\n",
      "[2]\ttrain-auc:0.901269\teval-auc:0.704109\n",
      "[3]\ttrain-auc:0.929424\teval-auc:0.717268\n",
      "[4]\ttrain-auc:0.951667\teval-auc:0.725409\n",
      "[5]\ttrain-auc:0.963111\teval-auc:0.731121\n",
      "[6]\ttrain-auc:0.97229\teval-auc:0.736253\n",
      "[7]\ttrain-auc:0.983059\teval-auc:0.740522\n",
      "[8]\ttrain-auc:0.989305\teval-auc:0.746759\n",
      "[9]\ttrain-auc:0.993497\teval-auc:0.751596\n",
      "[10]\ttrain-auc:0.99663\teval-auc:0.755888\n",
      "[11]\ttrain-auc:0.997713\teval-auc:0.760159\n",
      "[12]\ttrain-auc:0.99897\teval-auc:0.763408\n",
      "[13]\ttrain-auc:0.999277\teval-auc:0.767835\n",
      "[14]\ttrain-auc:0.99957\teval-auc:0.771044\n",
      "[15]\ttrain-auc:0.999755\teval-auc:0.774304\n",
      "[16]\ttrain-auc:0.999931\teval-auc:0.777495\n",
      "[17]\ttrain-auc:0.999976\teval-auc:0.779998\n",
      "[18]\ttrain-auc:0.999986\teval-auc:0.783587\n",
      "[19]\ttrain-auc:0.999988\teval-auc:0.78677\n",
      "[20]\ttrain-auc:0.999998\teval-auc:0.788501\n",
      "[21]\ttrain-auc:1\teval-auc:0.79105\n",
      "[22]\ttrain-auc:1\teval-auc:0.793628\n",
      "[23]\ttrain-auc:0.999999\teval-auc:0.794768\n",
      "[24]\ttrain-auc:1\teval-auc:0.797853\n",
      "[25]\ttrain-auc:1\teval-auc:0.799025\n",
      "[26]\ttrain-auc:1\teval-auc:0.800773\n",
      "[27]\ttrain-auc:1\teval-auc:0.802609\n",
      "[28]\ttrain-auc:1\teval-auc:0.804058\n",
      "[29]\ttrain-auc:1\teval-auc:0.805751\n",
      "[30]\ttrain-auc:1\teval-auc:0.807575\n",
      "[31]\ttrain-auc:1\teval-auc:0.809507\n",
      "[32]\ttrain-auc:1\teval-auc:0.811192\n",
      "[33]\ttrain-auc:1\teval-auc:0.812211\n",
      "[34]\ttrain-auc:1\teval-auc:0.81398\n",
      "[35]\ttrain-auc:1\teval-auc:0.815141\n",
      "[36]\ttrain-auc:1\teval-auc:0.816163\n",
      "[37]\ttrain-auc:1\teval-auc:0.817162\n",
      "[38]\ttrain-auc:1\teval-auc:0.818197\n",
      "[39]\ttrain-auc:1\teval-auc:0.818889\n",
      "[40]\ttrain-auc:1\teval-auc:0.820603\n",
      "[41]\ttrain-auc:1\teval-auc:0.821472\n",
      "[42]\ttrain-auc:1\teval-auc:0.822609\n",
      "[43]\ttrain-auc:1\teval-auc:0.823761\n",
      "[44]\ttrain-auc:1\teval-auc:0.824856\n",
      "[45]\ttrain-auc:1\teval-auc:0.825682\n",
      "[46]\ttrain-auc:1\teval-auc:0.826621\n",
      "[47]\ttrain-auc:1\teval-auc:0.827542\n",
      "[48]\ttrain-auc:1\teval-auc:0.828225\n",
      "[49]\ttrain-auc:1\teval-auc:0.829205\n",
      "[50]\ttrain-auc:1\teval-auc:0.830147\n",
      "[51]\ttrain-auc:1\teval-auc:0.830839\n",
      "[52]\ttrain-auc:1\teval-auc:0.831742\n",
      "[53]\ttrain-auc:1\teval-auc:0.832384\n",
      "[54]\ttrain-auc:1\teval-auc:0.833211\n",
      "[55]\ttrain-auc:1\teval-auc:0.834059\n",
      "[56]\ttrain-auc:1\teval-auc:0.835049\n",
      "[57]\ttrain-auc:1\teval-auc:0.835677\n",
      "[58]\ttrain-auc:1\teval-auc:0.836348\n",
      "[59]\ttrain-auc:1\teval-auc:0.836936\n",
      "[60]\ttrain-auc:1\teval-auc:0.837648\n",
      "[61]\ttrain-auc:1\teval-auc:0.838087\n",
      "[62]\ttrain-auc:1\teval-auc:0.838535\n",
      "[63]\ttrain-auc:1\teval-auc:0.839218\n",
      "[64]\ttrain-auc:1\teval-auc:0.839796\n",
      "[65]\ttrain-auc:1\teval-auc:0.840498\n",
      "[66]\ttrain-auc:1\teval-auc:0.840798\n",
      "[67]\ttrain-auc:1\teval-auc:0.841299\n",
      "[68]\ttrain-auc:1\teval-auc:0.841752\n",
      "[69]\ttrain-auc:1\teval-auc:0.842109\n",
      "[70]\ttrain-auc:1\teval-auc:0.842503\n",
      "[71]\ttrain-auc:1\teval-auc:0.842862\n",
      "[72]\ttrain-auc:1\teval-auc:0.843286\n",
      "[73]\ttrain-auc:1\teval-auc:0.843812\n",
      "[74]\ttrain-auc:1\teval-auc:0.844242\n",
      "[75]\ttrain-auc:1\teval-auc:0.844724\n",
      "[76]\ttrain-auc:1\teval-auc:0.845068\n",
      "[77]\ttrain-auc:1\teval-auc:0.845471\n",
      "[78]\ttrain-auc:1\teval-auc:0.84585\n",
      "[79]\ttrain-auc:1\teval-auc:0.846242\n",
      "[80]\ttrain-auc:1\teval-auc:0.846537\n",
      "[81]\ttrain-auc:1\teval-auc:0.846907\n",
      "[82]\ttrain-auc:1\teval-auc:0.847264\n",
      "[83]\ttrain-auc:1\teval-auc:0.847843\n",
      "[84]\ttrain-auc:1\teval-auc:0.848375\n",
      "[85]\ttrain-auc:1\teval-auc:0.848698\n",
      "[86]\ttrain-auc:1\teval-auc:0.849054\n",
      "[87]\ttrain-auc:1\teval-auc:0.849225\n",
      "[88]\ttrain-auc:1\teval-auc:0.849715\n",
      "[89]\ttrain-auc:1\teval-auc:0.850185\n",
      "[90]\ttrain-auc:1\teval-auc:0.850521\n",
      "[91]\ttrain-auc:1\teval-auc:0.850914\n",
      "[92]\ttrain-auc:1\teval-auc:0.851222\n",
      "[93]\ttrain-auc:1\teval-auc:0.851565\n",
      "[94]\ttrain-auc:1\teval-auc:0.851905\n",
      "[95]\ttrain-auc:1\teval-auc:0.852197\n",
      "[96]\ttrain-auc:1\teval-auc:0.85245\n",
      "[97]\ttrain-auc:1\teval-auc:0.852819\n",
      "[98]\ttrain-auc:1\teval-auc:0.853066\n",
      "[99]\ttrain-auc:1\teval-auc:0.853487\n",
      "[100]\ttrain-auc:1\teval-auc:0.853789\n",
      "[101]\ttrain-auc:1\teval-auc:0.854055\n",
      "[102]\ttrain-auc:1\teval-auc:0.854352\n",
      "[103]\ttrain-auc:1\teval-auc:0.854467\n",
      "[104]\ttrain-auc:1\teval-auc:0.854684\n",
      "[105]\ttrain-auc:1\teval-auc:0.85494\n",
      "[106]\ttrain-auc:1\teval-auc:0.855221\n",
      "[107]\ttrain-auc:1\teval-auc:0.855559\n",
      "[108]\ttrain-auc:1\teval-auc:0.855819\n",
      "[109]\ttrain-auc:1\teval-auc:0.856116\n",
      "[110]\ttrain-auc:1\teval-auc:0.856199\n",
      "[111]\ttrain-auc:1\teval-auc:0.856532\n",
      "[112]\ttrain-auc:1\teval-auc:0.856865\n",
      "[113]\ttrain-auc:1\teval-auc:0.857055\n",
      "[114]\ttrain-auc:1\teval-auc:0.857214\n",
      "[115]\ttrain-auc:1\teval-auc:0.857494\n",
      "[116]\ttrain-auc:1\teval-auc:0.857854\n",
      "[117]\ttrain-auc:1\teval-auc:0.858151\n",
      "[118]\ttrain-auc:1\teval-auc:0.858372\n",
      "[119]\ttrain-auc:1\teval-auc:0.858653\n",
      "[120]\ttrain-auc:1\teval-auc:0.858876\n",
      "[121]\ttrain-auc:1\teval-auc:0.859182\n",
      "[122]\ttrain-auc:1\teval-auc:0.859391\n",
      "[123]\ttrain-auc:1\teval-auc:0.859507\n",
      "[124]\ttrain-auc:1\teval-auc:0.859734\n",
      "[125]\ttrain-auc:1\teval-auc:0.859917\n",
      "[126]\ttrain-auc:1\teval-auc:0.860259\n",
      "[127]\ttrain-auc:1\teval-auc:0.86039\n",
      "[128]\ttrain-auc:1\teval-auc:0.860674\n",
      "[129]\ttrain-auc:1\teval-auc:0.860893\n",
      "[130]\ttrain-auc:1\teval-auc:0.861139\n",
      "[131]\ttrain-auc:1\teval-auc:0.861407\n",
      "[132]\ttrain-auc:1\teval-auc:0.861606\n",
      "[133]\ttrain-auc:1\teval-auc:0.861773\n",
      "[134]\ttrain-auc:1\teval-auc:0.861952\n",
      "[135]\ttrain-auc:1\teval-auc:0.862197\n",
      "[136]\ttrain-auc:1\teval-auc:0.86235\n",
      "[137]\ttrain-auc:1\teval-auc:0.862451\n",
      "[138]\ttrain-auc:1\teval-auc:0.86263\n",
      "[139]\ttrain-auc:1\teval-auc:0.862725\n",
      "[140]\ttrain-auc:1\teval-auc:0.862789\n",
      "[141]\ttrain-auc:1\teval-auc:0.862982\n",
      "[142]\ttrain-auc:1\teval-auc:0.863093\n",
      "[143]\ttrain-auc:1\teval-auc:0.863327\n",
      "[144]\ttrain-auc:1\teval-auc:0.863522\n",
      "[145]\ttrain-auc:1\teval-auc:0.863771\n",
      "[146]\ttrain-auc:1\teval-auc:0.863861\n",
      "[147]\ttrain-auc:1\teval-auc:0.86403\n",
      "[148]\ttrain-auc:1\teval-auc:0.864182\n",
      "[149]\ttrain-auc:1\teval-auc:0.864386\n",
      "[150]\ttrain-auc:1\teval-auc:0.864596\n",
      "[151]\ttrain-auc:1\teval-auc:0.864727\n",
      "[152]\ttrain-auc:1\teval-auc:0.864891\n",
      "[153]\ttrain-auc:1\teval-auc:0.865021\n",
      "[154]\ttrain-auc:1\teval-auc:0.865151\n",
      "[155]\ttrain-auc:1\teval-auc:0.865279\n",
      "[156]\ttrain-auc:1\teval-auc:0.865391\n",
      "[157]\ttrain-auc:1\teval-auc:0.865548\n",
      "[158]\ttrain-auc:1\teval-auc:0.865758\n",
      "[159]\ttrain-auc:1\teval-auc:0.865892\n",
      "[160]\ttrain-auc:1\teval-auc:0.866024\n",
      "[161]\ttrain-auc:1\teval-auc:0.866209\n",
      "[162]\ttrain-auc:1\teval-auc:0.866159\n",
      "[163]\ttrain-auc:1\teval-auc:0.866304\n",
      "[164]\ttrain-auc:1\teval-auc:0.866373\n",
      "[165]\ttrain-auc:1\teval-auc:0.866516\n",
      "[166]\ttrain-auc:1\teval-auc:0.866572\n",
      "[167]\ttrain-auc:1\teval-auc:0.866647\n",
      "[168]\ttrain-auc:1\teval-auc:0.866767\n",
      "[169]\ttrain-auc:1\teval-auc:0.866818\n",
      "[170]\ttrain-auc:1\teval-auc:0.866989\n",
      "[171]\ttrain-auc:1\teval-auc:0.867036\n",
      "[172]\ttrain-auc:1\teval-auc:0.867231\n",
      "[173]\ttrain-auc:1\teval-auc:0.867349\n",
      "[174]\ttrain-auc:1\teval-auc:0.867454\n",
      "[175]\ttrain-auc:1\teval-auc:0.86752\n",
      "[176]\ttrain-auc:1\teval-auc:0.867573\n",
      "[177]\ttrain-auc:1\teval-auc:0.867639\n",
      "[178]\ttrain-auc:1\teval-auc:0.86774\n",
      "[179]\ttrain-auc:1\teval-auc:0.86786\n",
      "[180]\ttrain-auc:1\teval-auc:0.867832\n",
      "[181]\ttrain-auc:1\teval-auc:0.867883\n",
      "[182]\ttrain-auc:1\teval-auc:0.867957\n",
      "[183]\ttrain-auc:1\teval-auc:0.868\n",
      "[184]\ttrain-auc:1\teval-auc:0.868011\n",
      "[185]\ttrain-auc:1\teval-auc:0.868134\n",
      "[186]\ttrain-auc:1\teval-auc:0.868242\n",
      "[187]\ttrain-auc:1\teval-auc:0.868301\n",
      "[188]\ttrain-auc:1\teval-auc:0.868365\n",
      "[189]\ttrain-auc:1\teval-auc:0.868469\n",
      "[190]\ttrain-auc:1\teval-auc:0.868541\n",
      "[191]\ttrain-auc:1\teval-auc:0.868524\n",
      "[192]\ttrain-auc:1\teval-auc:0.868667\n",
      "[193]\ttrain-auc:1\teval-auc:0.868783\n",
      "[194]\ttrain-auc:1\teval-auc:0.868882\n",
      "[195]\ttrain-auc:1\teval-auc:0.868955\n",
      "[196]\ttrain-auc:1\teval-auc:0.869044\n",
      "[197]\ttrain-auc:1\teval-auc:0.869078\n",
      "[198]\ttrain-auc:1\teval-auc:0.869207\n",
      "[199]\ttrain-auc:1\teval-auc:0.869311\n",
      "[200]\ttrain-auc:1\teval-auc:0.86935\n",
      "[201]\ttrain-auc:1\teval-auc:0.869457\n",
      "[202]\ttrain-auc:1\teval-auc:0.869511\n",
      "[203]\ttrain-auc:1\teval-auc:0.869553\n",
      "[204]\ttrain-auc:1\teval-auc:0.869647\n",
      "[205]\ttrain-auc:1\teval-auc:0.869702\n",
      "[206]\ttrain-auc:1\teval-auc:0.869781\n",
      "[207]\ttrain-auc:1\teval-auc:0.869876\n",
      "[208]\ttrain-auc:1\teval-auc:0.869965\n",
      "[209]\ttrain-auc:1\teval-auc:0.870039\n",
      "[210]\ttrain-auc:1\teval-auc:0.87003\n",
      "[211]\ttrain-auc:1\teval-auc:0.87014\n",
      "[212]\ttrain-auc:1\teval-auc:0.870216\n",
      "[213]\ttrain-auc:1\teval-auc:0.870295\n",
      "[214]\ttrain-auc:1\teval-auc:0.870344\n",
      "[215]\ttrain-auc:1\teval-auc:0.870397\n",
      "[216]\ttrain-auc:1\teval-auc:0.870432\n",
      "[217]\ttrain-auc:1\teval-auc:0.870531\n",
      "[218]\ttrain-auc:1\teval-auc:0.870551\n",
      "[219]\ttrain-auc:1\teval-auc:0.870631\n",
      "[220]\ttrain-auc:1\teval-auc:0.870637\n",
      "[221]\ttrain-auc:1\teval-auc:0.870724\n",
      "[222]\ttrain-auc:1\teval-auc:0.870821\n",
      "[223]\ttrain-auc:1\teval-auc:0.870903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[224]\ttrain-auc:1\teval-auc:0.870947\n",
      "[225]\ttrain-auc:1\teval-auc:0.871004\n",
      "[226]\ttrain-auc:1\teval-auc:0.87107\n",
      "[227]\ttrain-auc:1\teval-auc:0.871185\n",
      "[228]\ttrain-auc:1\teval-auc:0.871194\n",
      "[229]\ttrain-auc:1\teval-auc:0.871252\n",
      "[230]\ttrain-auc:1\teval-auc:0.87129\n",
      "[231]\ttrain-auc:1\teval-auc:0.871352\n",
      "[232]\ttrain-auc:1\teval-auc:0.871436\n",
      "[233]\ttrain-auc:1\teval-auc:0.871485\n",
      "[234]\ttrain-auc:1\teval-auc:0.871608\n",
      "[235]\ttrain-auc:1\teval-auc:0.871674\n",
      "[236]\ttrain-auc:1\teval-auc:0.871734\n",
      "[237]\ttrain-auc:1\teval-auc:0.871851\n",
      "[238]\ttrain-auc:1\teval-auc:0.871956\n",
      "[239]\ttrain-auc:1\teval-auc:0.872035\n",
      "[240]\ttrain-auc:1\teval-auc:0.872126\n",
      "[241]\ttrain-auc:1\teval-auc:0.872171\n",
      "[242]\ttrain-auc:1\teval-auc:0.872199\n",
      "[243]\ttrain-auc:1\teval-auc:0.872258\n",
      "[244]\ttrain-auc:1\teval-auc:0.872348\n",
      "[245]\ttrain-auc:1\teval-auc:0.872415\n",
      "[246]\ttrain-auc:1\teval-auc:0.872466\n",
      "[247]\ttrain-auc:1\teval-auc:0.872489\n",
      "[248]\ttrain-auc:1\teval-auc:0.872538\n",
      "[249]\ttrain-auc:1\teval-auc:0.872624\n",
      "[250]\ttrain-auc:1\teval-auc:0.872639\n",
      "[251]\ttrain-auc:1\teval-auc:0.872786\n",
      "[252]\ttrain-auc:1\teval-auc:0.872798\n",
      "[253]\ttrain-auc:1\teval-auc:0.872824\n",
      "[254]\ttrain-auc:1\teval-auc:0.87284\n",
      "[255]\ttrain-auc:1\teval-auc:0.872876\n",
      "[256]\ttrain-auc:1\teval-auc:0.872938\n",
      "[257]\ttrain-auc:1\teval-auc:0.873029\n",
      "[258]\ttrain-auc:1\teval-auc:0.873068\n",
      "[259]\ttrain-auc:1\teval-auc:0.873149\n",
      "[260]\ttrain-auc:1\teval-auc:0.873232\n",
      "[261]\ttrain-auc:1\teval-auc:0.873336\n",
      "[262]\ttrain-auc:1\teval-auc:0.873421\n",
      "[263]\ttrain-auc:1\teval-auc:0.873512\n",
      "[264]\ttrain-auc:1\teval-auc:0.873563\n",
      "[265]\ttrain-auc:1\teval-auc:0.873569\n",
      "[266]\ttrain-auc:1\teval-auc:0.873557\n",
      "[267]\ttrain-auc:1\teval-auc:0.873602\n",
      "[268]\ttrain-auc:1\teval-auc:0.873686\n",
      "[269]\ttrain-auc:1\teval-auc:0.87375\n",
      "[270]\ttrain-auc:1\teval-auc:0.87377\n",
      "[271]\ttrain-auc:1\teval-auc:0.873791\n",
      "[272]\ttrain-auc:1\teval-auc:0.873846\n",
      "[273]\ttrain-auc:1\teval-auc:0.873891\n",
      "[274]\ttrain-auc:1\teval-auc:0.873952\n",
      "[275]\ttrain-auc:1\teval-auc:0.873958\n",
      "[276]\ttrain-auc:1\teval-auc:0.874034\n",
      "[277]\ttrain-auc:1\teval-auc:0.874103\n",
      "[278]\ttrain-auc:1\teval-auc:0.874135\n",
      "[279]\ttrain-auc:1\teval-auc:0.874145\n",
      "[280]\ttrain-auc:1\teval-auc:0.874177\n",
      "[281]\ttrain-auc:1\teval-auc:0.874304\n",
      "[282]\ttrain-auc:1\teval-auc:0.87435\n",
      "[283]\ttrain-auc:1\teval-auc:0.874387\n",
      "[284]\ttrain-auc:1\teval-auc:0.874429\n",
      "[285]\ttrain-auc:1\teval-auc:0.874469\n",
      "[286]\ttrain-auc:1\teval-auc:0.87447\n",
      "[287]\ttrain-auc:1\teval-auc:0.874506\n",
      "[288]\ttrain-auc:1\teval-auc:0.874598\n",
      "[289]\ttrain-auc:1\teval-auc:0.874648\n",
      "[290]\ttrain-auc:1\teval-auc:0.874683\n",
      "[291]\ttrain-auc:1\teval-auc:0.87473\n",
      "[292]\ttrain-auc:1\teval-auc:0.874755\n",
      "[293]\ttrain-auc:1\teval-auc:0.874805\n",
      "[294]\ttrain-auc:1\teval-auc:0.874804\n",
      "[295]\ttrain-auc:1\teval-auc:0.874801\n",
      "[296]\ttrain-auc:1\teval-auc:0.874803\n",
      "[297]\ttrain-auc:1\teval-auc:0.874822\n",
      "[298]\ttrain-auc:1\teval-auc:0.874807\n",
      "[299]\ttrain-auc:1\teval-auc:0.87483\n",
      "[300]\ttrain-auc:1\teval-auc:0.874863\n",
      "[301]\ttrain-auc:1\teval-auc:0.8749\n",
      "[302]\ttrain-auc:1\teval-auc:0.874925\n",
      "[303]\ttrain-auc:1\teval-auc:0.874982\n",
      "[304]\ttrain-auc:1\teval-auc:0.87501\n",
      "[305]\ttrain-auc:1\teval-auc:0.875046\n",
      "[306]\ttrain-auc:1\teval-auc:0.875043\n",
      "[307]\ttrain-auc:1\teval-auc:0.875045\n",
      "[308]\ttrain-auc:1\teval-auc:0.875099\n",
      "[309]\ttrain-auc:1\teval-auc:0.875146\n",
      "[310]\ttrain-auc:1\teval-auc:0.875187\n",
      "[311]\ttrain-auc:1\teval-auc:0.875236\n",
      "[312]\ttrain-auc:1\teval-auc:0.875297\n",
      "[313]\ttrain-auc:1\teval-auc:0.875385\n",
      "[314]\ttrain-auc:1\teval-auc:0.875413\n",
      "[315]\ttrain-auc:1\teval-auc:0.875417\n",
      "[316]\ttrain-auc:1\teval-auc:0.87542\n",
      "[317]\ttrain-auc:1\teval-auc:0.875429\n",
      "[318]\ttrain-auc:1\teval-auc:0.875472\n",
      "[319]\ttrain-auc:1\teval-auc:0.875492\n",
      "[320]\ttrain-auc:1\teval-auc:0.875479\n",
      "[321]\ttrain-auc:1\teval-auc:0.875486\n",
      "[322]\ttrain-auc:1\teval-auc:0.875509\n",
      "[323]\ttrain-auc:1\teval-auc:0.875585\n",
      "[324]\ttrain-auc:1\teval-auc:0.875597\n",
      "[325]\ttrain-auc:1\teval-auc:0.875647\n",
      "[326]\ttrain-auc:1\teval-auc:0.875625\n",
      "[327]\ttrain-auc:1\teval-auc:0.875606\n",
      "[328]\ttrain-auc:1\teval-auc:0.875621\n",
      "[329]\ttrain-auc:1\teval-auc:0.875629\n",
      "[330]\ttrain-auc:1\teval-auc:0.875633\n",
      "[331]\ttrain-auc:1\teval-auc:0.875672\n",
      "[332]\ttrain-auc:1\teval-auc:0.875718\n",
      "[333]\ttrain-auc:1\teval-auc:0.875742\n",
      "[334]\ttrain-auc:1\teval-auc:0.875758\n",
      "[335]\ttrain-auc:1\teval-auc:0.87585\n",
      "[336]\ttrain-auc:1\teval-auc:0.875849\n",
      "[337]\ttrain-auc:1\teval-auc:0.875868\n",
      "[338]\ttrain-auc:1\teval-auc:0.875932\n",
      "[339]\ttrain-auc:1\teval-auc:0.875928\n",
      "[340]\ttrain-auc:1\teval-auc:0.875916\n",
      "[341]\ttrain-auc:1\teval-auc:0.87593\n",
      "[342]\ttrain-auc:1\teval-auc:0.875966\n",
      "[343]\ttrain-auc:1\teval-auc:0.876004\n",
      "[344]\ttrain-auc:1\teval-auc:0.876039\n",
      "[345]\ttrain-auc:1\teval-auc:0.876048\n",
      "[346]\ttrain-auc:1\teval-auc:0.876029\n",
      "[347]\ttrain-auc:1\teval-auc:0.876051\n",
      "[348]\ttrain-auc:1\teval-auc:0.876031\n",
      "[349]\ttrain-auc:1\teval-auc:0.876078\n",
      "[350]\ttrain-auc:1\teval-auc:0.876105\n",
      "[351]\ttrain-auc:1\teval-auc:0.876146\n",
      "[352]\ttrain-auc:1\teval-auc:0.876175\n",
      "[353]\ttrain-auc:1\teval-auc:0.876218\n",
      "[354]\ttrain-auc:1\teval-auc:0.876263\n",
      "[355]\ttrain-auc:1\teval-auc:0.87627\n",
      "[356]\ttrain-auc:1\teval-auc:0.876309\n",
      "[357]\ttrain-auc:1\teval-auc:0.876346\n",
      "[358]\ttrain-auc:1\teval-auc:0.876365\n",
      "[359]\ttrain-auc:1\teval-auc:0.87638\n",
      "[360]\ttrain-auc:1\teval-auc:0.876427\n",
      "[361]\ttrain-auc:1\teval-auc:0.876481\n",
      "[362]\ttrain-auc:1\teval-auc:0.876511\n",
      "[363]\ttrain-auc:1\teval-auc:0.876549\n",
      "[364]\ttrain-auc:1\teval-auc:0.876604\n",
      "[365]\ttrain-auc:1\teval-auc:0.876598\n",
      "[366]\ttrain-auc:1\teval-auc:0.876656\n",
      "[367]\ttrain-auc:1\teval-auc:0.876735\n",
      "[368]\ttrain-auc:1\teval-auc:0.876743\n",
      "[369]\ttrain-auc:1\teval-auc:0.876753\n",
      "[370]\ttrain-auc:1\teval-auc:0.87678\n",
      "[371]\ttrain-auc:1\teval-auc:0.876813\n",
      "[372]\ttrain-auc:1\teval-auc:0.876781\n",
      "[373]\ttrain-auc:1\teval-auc:0.876848\n",
      "[374]\ttrain-auc:1\teval-auc:0.876858\n",
      "[375]\ttrain-auc:1\teval-auc:0.876885\n",
      "[376]\ttrain-auc:1\teval-auc:0.876932\n",
      "[377]\ttrain-auc:1\teval-auc:0.876992\n",
      "[378]\ttrain-auc:1\teval-auc:0.876991\n",
      "[379]\ttrain-auc:1\teval-auc:0.87703\n",
      "[380]\ttrain-auc:1\teval-auc:0.877048\n",
      "[381]\ttrain-auc:1\teval-auc:0.87714\n",
      "[382]\ttrain-auc:1\teval-auc:0.877149\n",
      "[383]\ttrain-auc:1\teval-auc:0.877167\n",
      "[384]\ttrain-auc:1\teval-auc:0.877198\n",
      "[385]\ttrain-auc:1\teval-auc:0.877244\n",
      "[386]\ttrain-auc:1\teval-auc:0.877279\n",
      "[387]\ttrain-auc:1\teval-auc:0.877307\n",
      "[388]\ttrain-auc:1\teval-auc:0.877314\n",
      "[389]\ttrain-auc:1\teval-auc:0.877355\n",
      "[390]\ttrain-auc:1\teval-auc:0.877358\n",
      "[391]\ttrain-auc:1\teval-auc:0.877338\n",
      "[392]\ttrain-auc:1\teval-auc:0.877338\n",
      "[393]\ttrain-auc:1\teval-auc:0.877379\n",
      "[394]\ttrain-auc:1\teval-auc:0.87737\n",
      "[395]\ttrain-auc:1\teval-auc:0.877435\n",
      "[396]\ttrain-auc:1\teval-auc:0.877464\n",
      "[397]\ttrain-auc:1\teval-auc:0.877479\n",
      "[398]\ttrain-auc:1\teval-auc:0.877522\n",
      "[399]\ttrain-auc:1\teval-auc:0.877508\n",
      "[400]\ttrain-auc:1\teval-auc:0.87755\n",
      "[401]\ttrain-auc:1\teval-auc:0.877551\n",
      "[402]\ttrain-auc:1\teval-auc:0.87758\n",
      "[403]\ttrain-auc:1\teval-auc:0.877583\n",
      "[404]\ttrain-auc:1\teval-auc:0.877645\n",
      "[405]\ttrain-auc:1\teval-auc:0.877646\n",
      "[406]\ttrain-auc:1\teval-auc:0.877679\n",
      "[407]\ttrain-auc:1\teval-auc:0.877705\n",
      "[408]\ttrain-auc:1\teval-auc:0.87772\n",
      "[409]\ttrain-auc:1\teval-auc:0.877752\n",
      "[410]\ttrain-auc:1\teval-auc:0.877776\n",
      "[411]\ttrain-auc:1\teval-auc:0.877763\n",
      "[412]\ttrain-auc:1\teval-auc:0.877801\n",
      "[413]\ttrain-auc:1\teval-auc:0.877788\n",
      "[414]\ttrain-auc:1\teval-auc:0.877784\n",
      "[415]\ttrain-auc:1\teval-auc:0.877777\n",
      "[416]\ttrain-auc:1\teval-auc:0.877835\n",
      "[417]\ttrain-auc:1\teval-auc:0.87789\n",
      "[418]\ttrain-auc:1\teval-auc:0.877899\n",
      "[419]\ttrain-auc:1\teval-auc:0.877921\n",
      "[420]\ttrain-auc:1\teval-auc:0.877972\n",
      "[421]\ttrain-auc:1\teval-auc:0.877938\n",
      "[422]\ttrain-auc:1\teval-auc:0.877954\n",
      "[423]\ttrain-auc:1\teval-auc:0.877965\n",
      "[424]\ttrain-auc:1\teval-auc:0.877933\n",
      "[425]\ttrain-auc:1\teval-auc:0.877956\n",
      "[426]\ttrain-auc:1\teval-auc:0.87795\n",
      "[427]\ttrain-auc:1\teval-auc:0.877994\n",
      "[428]\ttrain-auc:1\teval-auc:0.878038\n",
      "[429]\ttrain-auc:1\teval-auc:0.878061\n",
      "[430]\ttrain-auc:1\teval-auc:0.878076\n",
      "[431]\ttrain-auc:1\teval-auc:0.878093\n",
      "[432]\ttrain-auc:1\teval-auc:0.878084\n",
      "[433]\ttrain-auc:1\teval-auc:0.878102\n",
      "[434]\ttrain-auc:1\teval-auc:0.878139\n",
      "[435]\ttrain-auc:1\teval-auc:0.878135\n",
      "[436]\ttrain-auc:1\teval-auc:0.878161\n",
      "[437]\ttrain-auc:1\teval-auc:0.878188\n",
      "[438]\ttrain-auc:1\teval-auc:0.878183\n",
      "[439]\ttrain-auc:1\teval-auc:0.878197\n",
      "[440]\ttrain-auc:1\teval-auc:0.878204\n",
      "[441]\ttrain-auc:1\teval-auc:0.87819\n",
      "[442]\ttrain-auc:1\teval-auc:0.878226\n",
      "[443]\ttrain-auc:1\teval-auc:0.878226\n",
      "[444]\ttrain-auc:1\teval-auc:0.878277\n",
      "[445]\ttrain-auc:1\teval-auc:0.878314\n",
      "[446]\ttrain-auc:1\teval-auc:0.87832\n",
      "[447]\ttrain-auc:1\teval-auc:0.878331\n",
      "[448]\ttrain-auc:1\teval-auc:0.878354\n",
      "[449]\ttrain-auc:1\teval-auc:0.87834\n",
      "[450]\ttrain-auc:1\teval-auc:0.878364\n",
      "[451]\ttrain-auc:1\teval-auc:0.878381\n",
      "[452]\ttrain-auc:1\teval-auc:0.878394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[453]\ttrain-auc:1\teval-auc:0.878426\n",
      "[454]\ttrain-auc:1\teval-auc:0.878429\n",
      "[455]\ttrain-auc:1\teval-auc:0.87846\n",
      "[456]\ttrain-auc:1\teval-auc:0.878495\n",
      "[457]\ttrain-auc:1\teval-auc:0.878527\n",
      "[458]\ttrain-auc:1\teval-auc:0.87857\n",
      "[459]\ttrain-auc:1\teval-auc:0.878612\n",
      "[460]\ttrain-auc:1\teval-auc:0.878629\n",
      "[461]\ttrain-auc:1\teval-auc:0.87863\n",
      "[462]\ttrain-auc:1\teval-auc:0.878632\n",
      "[463]\ttrain-auc:1\teval-auc:0.878663\n",
      "[464]\ttrain-auc:1\teval-auc:0.878692\n",
      "[465]\ttrain-auc:1\teval-auc:0.878695\n",
      "[466]\ttrain-auc:1\teval-auc:0.878719\n",
      "[467]\ttrain-auc:1\teval-auc:0.878743\n",
      "[468]\ttrain-auc:1\teval-auc:0.878746\n",
      "[469]\ttrain-auc:1\teval-auc:0.878783\n",
      "[470]\ttrain-auc:1\teval-auc:0.878801\n",
      "[471]\ttrain-auc:1\teval-auc:0.878795\n",
      "[472]\ttrain-auc:1\teval-auc:0.878813\n",
      "[473]\ttrain-auc:1\teval-auc:0.878829\n",
      "[474]\ttrain-auc:1\teval-auc:0.878871\n",
      "[475]\ttrain-auc:1\teval-auc:0.878841\n",
      "[476]\ttrain-auc:1\teval-auc:0.878851\n",
      "[477]\ttrain-auc:1\teval-auc:0.878876\n",
      "[478]\ttrain-auc:1\teval-auc:0.878878\n",
      "[479]\ttrain-auc:1\teval-auc:0.878885\n",
      "[480]\ttrain-auc:1\teval-auc:0.878913\n",
      "[481]\ttrain-auc:1\teval-auc:0.878924\n",
      "[482]\ttrain-auc:1\teval-auc:0.878952\n",
      "[483]\ttrain-auc:1\teval-auc:0.878939\n",
      "[484]\ttrain-auc:1\teval-auc:0.878945\n",
      "[485]\ttrain-auc:1\teval-auc:0.878953\n",
      "[486]\ttrain-auc:1\teval-auc:0.87898\n",
      "[487]\ttrain-auc:1\teval-auc:0.879004\n",
      "[488]\ttrain-auc:1\teval-auc:0.879039\n",
      "[489]\ttrain-auc:1\teval-auc:0.879037\n",
      "[490]\ttrain-auc:1\teval-auc:0.879063\n",
      "[491]\ttrain-auc:1\teval-auc:0.87906\n",
      "[492]\ttrain-auc:1\teval-auc:0.879095\n",
      "[493]\ttrain-auc:1\teval-auc:0.879112\n",
      "[494]\ttrain-auc:1\teval-auc:0.879114\n",
      "[495]\ttrain-auc:1\teval-auc:0.879131\n",
      "[496]\ttrain-auc:1\teval-auc:0.879099\n",
      "[497]\ttrain-auc:1\teval-auc:0.879106\n",
      "[498]\ttrain-auc:1\teval-auc:0.879097\n",
      "[499]\ttrain-auc:1\teval-auc:0.879113\n",
      "[500]\ttrain-auc:1\teval-auc:0.879144\n",
      "[501]\ttrain-auc:1\teval-auc:0.879133\n",
      "[502]\ttrain-auc:1\teval-auc:0.879175\n",
      "[503]\ttrain-auc:1\teval-auc:0.879215\n",
      "[504]\ttrain-auc:1\teval-auc:0.879229\n",
      "[505]\ttrain-auc:1\teval-auc:0.879216\n",
      "[506]\ttrain-auc:1\teval-auc:0.879211\n",
      "[507]\ttrain-auc:1\teval-auc:0.879232\n",
      "[508]\ttrain-auc:1\teval-auc:0.879244\n",
      "[509]\ttrain-auc:1\teval-auc:0.879264\n",
      "[510]\ttrain-auc:1\teval-auc:0.87927\n",
      "[511]\ttrain-auc:1\teval-auc:0.879288\n",
      "[512]\ttrain-auc:1\teval-auc:0.879303\n",
      "[513]\ttrain-auc:1\teval-auc:0.879284\n",
      "[514]\ttrain-auc:1\teval-auc:0.879309\n",
      "[515]\ttrain-auc:1\teval-auc:0.879327\n",
      "[516]\ttrain-auc:1\teval-auc:0.879321\n",
      "[517]\ttrain-auc:1\teval-auc:0.879349\n",
      "[518]\ttrain-auc:1\teval-auc:0.879374\n",
      "[519]\ttrain-auc:1\teval-auc:0.87937\n",
      "[520]\ttrain-auc:1\teval-auc:0.879373\n",
      "[521]\ttrain-auc:1\teval-auc:0.879414\n",
      "[522]\ttrain-auc:1\teval-auc:0.879409\n",
      "[523]\ttrain-auc:1\teval-auc:0.879409\n",
      "[524]\ttrain-auc:1\teval-auc:0.87942\n",
      "[525]\ttrain-auc:1\teval-auc:0.87941\n",
      "[526]\ttrain-auc:1\teval-auc:0.879416\n",
      "[527]\ttrain-auc:1\teval-auc:0.879414\n",
      "[528]\ttrain-auc:1\teval-auc:0.879422\n",
      "[529]\ttrain-auc:1\teval-auc:0.879424\n",
      "[530]\ttrain-auc:1\teval-auc:0.879468\n",
      "[531]\ttrain-auc:1\teval-auc:0.879456\n",
      "[532]\ttrain-auc:1\teval-auc:0.879466\n",
      "[533]\ttrain-auc:1\teval-auc:0.879493\n",
      "[534]\ttrain-auc:1\teval-auc:0.879511\n",
      "[535]\ttrain-auc:1\teval-auc:0.879513\n",
      "[536]\ttrain-auc:1\teval-auc:0.879506\n",
      "[537]\ttrain-auc:1\teval-auc:0.879488\n",
      "[538]\ttrain-auc:1\teval-auc:0.879487\n",
      "[539]\ttrain-auc:1\teval-auc:0.879499\n",
      "[540]\ttrain-auc:1\teval-auc:0.879551\n",
      "[541]\ttrain-auc:1\teval-auc:0.879569\n",
      "[542]\ttrain-auc:1\teval-auc:0.879567\n",
      "[543]\ttrain-auc:1\teval-auc:0.879565\n",
      "[544]\ttrain-auc:1\teval-auc:0.879579\n",
      "[545]\ttrain-auc:1\teval-auc:0.879578\n",
      "[546]\ttrain-auc:1\teval-auc:0.879594\n",
      "[547]\ttrain-auc:1\teval-auc:0.879602\n",
      "[548]\ttrain-auc:1\teval-auc:0.879608\n",
      "[549]\ttrain-auc:1\teval-auc:0.879634\n",
      "[550]\ttrain-auc:1\teval-auc:0.879656\n",
      "[551]\ttrain-auc:1\teval-auc:0.879686\n",
      "[552]\ttrain-auc:1\teval-auc:0.879697\n",
      "[553]\ttrain-auc:1\teval-auc:0.879708\n",
      "[554]\ttrain-auc:1\teval-auc:0.87973\n",
      "[555]\ttrain-auc:1\teval-auc:0.879756\n",
      "[556]\ttrain-auc:1\teval-auc:0.87975\n",
      "[557]\ttrain-auc:1\teval-auc:0.879776\n",
      "[558]\ttrain-auc:1\teval-auc:0.879788\n",
      "[559]\ttrain-auc:1\teval-auc:0.879812\n",
      "[560]\ttrain-auc:1\teval-auc:0.879822\n",
      "[561]\ttrain-auc:1\teval-auc:0.879862\n",
      "[562]\ttrain-auc:1\teval-auc:0.879838\n",
      "[563]\ttrain-auc:1\teval-auc:0.879832\n",
      "[564]\ttrain-auc:1\teval-auc:0.879846\n",
      "[565]\ttrain-auc:1\teval-auc:0.879858\n",
      "[566]\ttrain-auc:1\teval-auc:0.879899\n",
      "[567]\ttrain-auc:1\teval-auc:0.879909\n",
      "[568]\ttrain-auc:1\teval-auc:0.879901\n",
      "[569]\ttrain-auc:1\teval-auc:0.879902\n",
      "[570]\ttrain-auc:1\teval-auc:0.879907\n",
      "[571]\ttrain-auc:1\teval-auc:0.879944\n",
      "[572]\ttrain-auc:1\teval-auc:0.879967\n",
      "[573]\ttrain-auc:1\teval-auc:0.879998\n",
      "[574]\ttrain-auc:1\teval-auc:0.880002\n",
      "[575]\ttrain-auc:1\teval-auc:0.880025\n",
      "[576]\ttrain-auc:1\teval-auc:0.880036\n",
      "[577]\ttrain-auc:1\teval-auc:0.880061\n",
      "[578]\ttrain-auc:1\teval-auc:0.880078\n",
      "[579]\ttrain-auc:1\teval-auc:0.88009\n",
      "[580]\ttrain-auc:1\teval-auc:0.880107\n",
      "[581]\ttrain-auc:1\teval-auc:0.880116\n",
      "[582]\ttrain-auc:1\teval-auc:0.880136\n",
      "[583]\ttrain-auc:1\teval-auc:0.880135\n",
      "[584]\ttrain-auc:1\teval-auc:0.880169\n",
      "[585]\ttrain-auc:1\teval-auc:0.88017\n",
      "[586]\ttrain-auc:1\teval-auc:0.880167\n",
      "[587]\ttrain-auc:1\teval-auc:0.880163\n",
      "[588]\ttrain-auc:1\teval-auc:0.88016\n",
      "[589]\ttrain-auc:1\teval-auc:0.880157\n",
      "[590]\ttrain-auc:1\teval-auc:0.880149\n",
      "[591]\ttrain-auc:1\teval-auc:0.88017\n",
      "[592]\ttrain-auc:1\teval-auc:0.880166\n",
      "[593]\ttrain-auc:1\teval-auc:0.880161\n",
      "[594]\ttrain-auc:1\teval-auc:0.880177\n",
      "[595]\ttrain-auc:1\teval-auc:0.880183\n",
      "[596]\ttrain-auc:1\teval-auc:0.880196\n",
      "[597]\ttrain-auc:1\teval-auc:0.880202\n",
      "[598]\ttrain-auc:1\teval-auc:0.880186\n",
      "[599]\ttrain-auc:1\teval-auc:0.880215\n",
      "[600]\ttrain-auc:1\teval-auc:0.880202\n",
      "[601]\ttrain-auc:1\teval-auc:0.880219\n",
      "[602]\ttrain-auc:1\teval-auc:0.880239\n",
      "[603]\ttrain-auc:1\teval-auc:0.880215\n",
      "[604]\ttrain-auc:1\teval-auc:0.880217\n",
      "[605]\ttrain-auc:1\teval-auc:0.880216\n",
      "[606]\ttrain-auc:1\teval-auc:0.880245\n",
      "[607]\ttrain-auc:1\teval-auc:0.880265\n",
      "[608]\ttrain-auc:1\teval-auc:0.880262\n",
      "[609]\ttrain-auc:1\teval-auc:0.880286\n",
      "[610]\ttrain-auc:1\teval-auc:0.880275\n",
      "[611]\ttrain-auc:1\teval-auc:0.880283\n",
      "[612]\ttrain-auc:1\teval-auc:0.880291\n",
      "[613]\ttrain-auc:1\teval-auc:0.8803\n",
      "[614]\ttrain-auc:1\teval-auc:0.880309\n",
      "[615]\ttrain-auc:1\teval-auc:0.880315\n",
      "[616]\ttrain-auc:1\teval-auc:0.880332\n",
      "[617]\ttrain-auc:1\teval-auc:0.880348\n",
      "[618]\ttrain-auc:1\teval-auc:0.880354\n",
      "[619]\ttrain-auc:1\teval-auc:0.880372\n",
      "[620]\ttrain-auc:1\teval-auc:0.880381\n",
      "[621]\ttrain-auc:1\teval-auc:0.880346\n",
      "[622]\ttrain-auc:1\teval-auc:0.880366\n",
      "[623]\ttrain-auc:1\teval-auc:0.880379\n",
      "[624]\ttrain-auc:1\teval-auc:0.88035\n",
      "[625]\ttrain-auc:1\teval-auc:0.880353\n",
      "[626]\ttrain-auc:1\teval-auc:0.880367\n",
      "[627]\ttrain-auc:1\teval-auc:0.880385\n",
      "[628]\ttrain-auc:1\teval-auc:0.880402\n",
      "[629]\ttrain-auc:1\teval-auc:0.880441\n",
      "[630]\ttrain-auc:1\teval-auc:0.880439\n",
      "[631]\ttrain-auc:1\teval-auc:0.880445\n",
      "[632]\ttrain-auc:1\teval-auc:0.880433\n",
      "[633]\ttrain-auc:1\teval-auc:0.880453\n",
      "[634]\ttrain-auc:1\teval-auc:0.880452\n",
      "[635]\ttrain-auc:1\teval-auc:0.880457\n",
      "[636]\ttrain-auc:1\teval-auc:0.880463\n",
      "[637]\ttrain-auc:1\teval-auc:0.880489\n",
      "[638]\ttrain-auc:1\teval-auc:0.880489\n",
      "[639]\ttrain-auc:1\teval-auc:0.880522\n",
      "[640]\ttrain-auc:1\teval-auc:0.880552\n",
      "[641]\ttrain-auc:1\teval-auc:0.880571\n",
      "[642]\ttrain-auc:1\teval-auc:0.880596\n",
      "[643]\ttrain-auc:1\teval-auc:0.880602\n",
      "[644]\ttrain-auc:1\teval-auc:0.880599\n",
      "[645]\ttrain-auc:1\teval-auc:0.880615\n",
      "[646]\ttrain-auc:1\teval-auc:0.880605\n",
      "[647]\ttrain-auc:1\teval-auc:0.880609\n",
      "[648]\ttrain-auc:1\teval-auc:0.880616\n",
      "[649]\ttrain-auc:1\teval-auc:0.880624\n",
      "[650]\ttrain-auc:1\teval-auc:0.880617\n",
      "[651]\ttrain-auc:1\teval-auc:0.880623\n",
      "[652]\ttrain-auc:1\teval-auc:0.880631\n",
      "[653]\ttrain-auc:1\teval-auc:0.880634\n",
      "[654]\ttrain-auc:1\teval-auc:0.880633\n",
      "[655]\ttrain-auc:1\teval-auc:0.880661\n",
      "[656]\ttrain-auc:1\teval-auc:0.880679\n",
      "[657]\ttrain-auc:1\teval-auc:0.880714\n",
      "[658]\ttrain-auc:1\teval-auc:0.880711\n",
      "[659]\ttrain-auc:1\teval-auc:0.880721\n",
      "[660]\ttrain-auc:1\teval-auc:0.880712\n",
      "[661]\ttrain-auc:1\teval-auc:0.880701\n",
      "[662]\ttrain-auc:1\teval-auc:0.880748\n",
      "[663]\ttrain-auc:1\teval-auc:0.880756\n",
      "[664]\ttrain-auc:1\teval-auc:0.880766\n",
      "[665]\ttrain-auc:1\teval-auc:0.880776\n",
      "[666]\ttrain-auc:1\teval-auc:0.880783\n",
      "[667]\ttrain-auc:1\teval-auc:0.880778\n",
      "[668]\ttrain-auc:1\teval-auc:0.880776\n",
      "[669]\ttrain-auc:1\teval-auc:0.880805\n",
      "[670]\ttrain-auc:1\teval-auc:0.880824\n",
      "[671]\ttrain-auc:1\teval-auc:0.880827\n",
      "[672]\ttrain-auc:1\teval-auc:0.880824\n",
      "[673]\ttrain-auc:1\teval-auc:0.880846\n",
      "[674]\ttrain-auc:1\teval-auc:0.880879\n",
      "[675]\ttrain-auc:1\teval-auc:0.880857\n",
      "[676]\ttrain-auc:1\teval-auc:0.880849\n",
      "[677]\ttrain-auc:1\teval-auc:0.880861\n",
      "[678]\ttrain-auc:1\teval-auc:0.880892\n",
      "[679]\ttrain-auc:1\teval-auc:0.880908\n",
      "[680]\ttrain-auc:1\teval-auc:0.88094\n",
      "[681]\ttrain-auc:1\teval-auc:0.880943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[682]\ttrain-auc:1\teval-auc:0.880953\n",
      "[683]\ttrain-auc:1\teval-auc:0.88097\n",
      "[684]\ttrain-auc:1\teval-auc:0.880979\n",
      "[685]\ttrain-auc:1\teval-auc:0.880993\n",
      "[686]\ttrain-auc:1\teval-auc:0.881014\n",
      "[687]\ttrain-auc:1\teval-auc:0.881025\n",
      "[688]\ttrain-auc:1\teval-auc:0.881047\n",
      "[689]\ttrain-auc:1\teval-auc:0.881054\n",
      "[690]\ttrain-auc:1\teval-auc:0.881062\n",
      "[691]\ttrain-auc:1\teval-auc:0.881074\n",
      "[692]\ttrain-auc:1\teval-auc:0.881061\n",
      "[693]\ttrain-auc:1\teval-auc:0.881059\n",
      "[694]\ttrain-auc:1\teval-auc:0.881066\n",
      "[695]\ttrain-auc:1\teval-auc:0.881058\n",
      "[696]\ttrain-auc:1\teval-auc:0.881089\n",
      "[697]\ttrain-auc:1\teval-auc:0.881089\n",
      "[698]\ttrain-auc:1\teval-auc:0.88109\n",
      "[699]\ttrain-auc:1\teval-auc:0.881105\n",
      "[700]\ttrain-auc:1\teval-auc:0.881105\n",
      "[701]\ttrain-auc:1\teval-auc:0.881102\n",
      "[702]\ttrain-auc:1\teval-auc:0.881123\n",
      "[703]\ttrain-auc:1\teval-auc:0.881136\n",
      "[704]\ttrain-auc:1\teval-auc:0.881164\n",
      "[705]\ttrain-auc:1\teval-auc:0.881163\n",
      "[706]\ttrain-auc:1\teval-auc:0.881186\n",
      "[707]\ttrain-auc:1\teval-auc:0.881188\n",
      "[708]\ttrain-auc:1\teval-auc:0.881206\n",
      "[709]\ttrain-auc:1\teval-auc:0.881214\n",
      "[710]\ttrain-auc:1\teval-auc:0.881214\n",
      "[711]\ttrain-auc:1\teval-auc:0.881233\n",
      "[712]\ttrain-auc:1\teval-auc:0.881239\n",
      "[713]\ttrain-auc:1\teval-auc:0.881259\n",
      "[714]\ttrain-auc:1\teval-auc:0.881271\n",
      "[715]\ttrain-auc:1\teval-auc:0.881263\n",
      "[716]\ttrain-auc:1\teval-auc:0.881254\n",
      "[717]\ttrain-auc:1\teval-auc:0.881262\n",
      "[718]\ttrain-auc:1\teval-auc:0.881239\n",
      "[719]\ttrain-auc:1\teval-auc:0.881243\n",
      "[720]\ttrain-auc:1\teval-auc:0.881255\n",
      "[721]\ttrain-auc:1\teval-auc:0.881253\n",
      "[722]\ttrain-auc:1\teval-auc:0.881268\n",
      "[723]\ttrain-auc:1\teval-auc:0.881265\n",
      "[724]\ttrain-auc:1\teval-auc:0.881287\n",
      "[725]\ttrain-auc:1\teval-auc:0.881293\n",
      "[726]\ttrain-auc:1\teval-auc:0.881299\n",
      "[727]\ttrain-auc:1\teval-auc:0.881298\n",
      "[728]\ttrain-auc:1\teval-auc:0.881304\n",
      "[729]\ttrain-auc:1\teval-auc:0.881309\n",
      "[730]\ttrain-auc:1\teval-auc:0.881314\n",
      "[731]\ttrain-auc:1\teval-auc:0.881325\n",
      "[732]\ttrain-auc:1\teval-auc:0.881317\n",
      "[733]\ttrain-auc:1\teval-auc:0.881331\n",
      "[734]\ttrain-auc:1\teval-auc:0.881337\n",
      "[735]\ttrain-auc:1\teval-auc:0.881348\n",
      "[736]\ttrain-auc:1\teval-auc:0.881361\n",
      "[737]\ttrain-auc:1\teval-auc:0.881365\n",
      "[738]\ttrain-auc:1\teval-auc:0.881385\n",
      "[739]\ttrain-auc:1\teval-auc:0.881388\n",
      "[740]\ttrain-auc:1\teval-auc:0.881384\n",
      "[741]\ttrain-auc:1\teval-auc:0.881384\n",
      "[742]\ttrain-auc:1\teval-auc:0.88141\n",
      "[743]\ttrain-auc:1\teval-auc:0.881414\n",
      "[744]\ttrain-auc:1\teval-auc:0.881419\n",
      "[745]\ttrain-auc:1\teval-auc:0.881409\n",
      "[746]\ttrain-auc:1\teval-auc:0.881414\n",
      "[747]\ttrain-auc:1\teval-auc:0.881435\n",
      "[748]\ttrain-auc:1\teval-auc:0.881442\n",
      "[749]\ttrain-auc:1\teval-auc:0.881434\n",
      "[750]\ttrain-auc:1\teval-auc:0.881432\n",
      "[751]\ttrain-auc:1\teval-auc:0.881437\n",
      "[752]\ttrain-auc:1\teval-auc:0.881472\n",
      "[753]\ttrain-auc:1\teval-auc:0.881468\n",
      "[754]\ttrain-auc:1\teval-auc:0.881468\n",
      "[755]\ttrain-auc:1\teval-auc:0.881463\n",
      "[756]\ttrain-auc:1\teval-auc:0.881445\n",
      "[757]\ttrain-auc:1\teval-auc:0.881448\n",
      "[758]\ttrain-auc:1\teval-auc:0.881469\n",
      "[759]\ttrain-auc:1\teval-auc:0.881476\n",
      "[760]\ttrain-auc:1\teval-auc:0.881487\n",
      "[761]\ttrain-auc:1\teval-auc:0.881495\n",
      "[762]\ttrain-auc:1\teval-auc:0.881486\n",
      "[763]\ttrain-auc:1\teval-auc:0.881471\n",
      "[764]\ttrain-auc:1\teval-auc:0.881492\n",
      "[765]\ttrain-auc:1\teval-auc:0.881485\n",
      "[766]\ttrain-auc:1\teval-auc:0.881479\n",
      "[767]\ttrain-auc:1\teval-auc:0.881491\n",
      "[768]\ttrain-auc:1\teval-auc:0.881509\n",
      "[769]\ttrain-auc:1\teval-auc:0.881501\n",
      "[770]\ttrain-auc:1\teval-auc:0.881521\n",
      "[771]\ttrain-auc:1\teval-auc:0.881532\n",
      "[772]\ttrain-auc:1\teval-auc:0.88157\n",
      "[773]\ttrain-auc:1\teval-auc:0.881581\n",
      "[774]\ttrain-auc:1\teval-auc:0.881577\n",
      "[775]\ttrain-auc:1\teval-auc:0.881586\n",
      "[776]\ttrain-auc:1\teval-auc:0.881586\n",
      "[777]\ttrain-auc:1\teval-auc:0.881605\n",
      "[778]\ttrain-auc:1\teval-auc:0.8816\n",
      "[779]\ttrain-auc:1\teval-auc:0.881588\n",
      "[780]\ttrain-auc:1\teval-auc:0.881593\n",
      "[781]\ttrain-auc:1\teval-auc:0.881614\n",
      "[782]\ttrain-auc:1\teval-auc:0.881621\n",
      "[783]\ttrain-auc:1\teval-auc:0.881612\n",
      "[784]\ttrain-auc:1\teval-auc:0.881611\n",
      "[785]\ttrain-auc:1\teval-auc:0.881641\n",
      "[786]\ttrain-auc:1\teval-auc:0.881643\n",
      "[787]\ttrain-auc:1\teval-auc:0.881635\n",
      "[788]\ttrain-auc:1\teval-auc:0.881636\n",
      "[789]\ttrain-auc:1\teval-auc:0.881629\n",
      "[790]\ttrain-auc:1\teval-auc:0.881629\n",
      "[791]\ttrain-auc:1\teval-auc:0.881629\n",
      "[792]\ttrain-auc:1\teval-auc:0.88163\n",
      "[793]\ttrain-auc:1\teval-auc:0.88163\n",
      "[794]\ttrain-auc:1\teval-auc:0.881659\n",
      "[795]\ttrain-auc:1\teval-auc:0.881664\n",
      "[796]\ttrain-auc:1\teval-auc:0.881666\n",
      "[797]\ttrain-auc:1\teval-auc:0.881679\n",
      "[798]\ttrain-auc:1\teval-auc:0.881681\n",
      "[799]\ttrain-auc:1\teval-auc:0.881687\n",
      "[800]\ttrain-auc:1\teval-auc:0.881683\n",
      "[801]\ttrain-auc:1\teval-auc:0.881669\n",
      "[802]\ttrain-auc:1\teval-auc:0.881668\n",
      "[803]\ttrain-auc:1\teval-auc:0.881683\n",
      "[804]\ttrain-auc:1\teval-auc:0.881712\n",
      "[805]\ttrain-auc:1\teval-auc:0.881719\n",
      "[806]\ttrain-auc:1\teval-auc:0.881727\n",
      "[807]\ttrain-auc:1\teval-auc:0.881737\n",
      "[808]\ttrain-auc:1\teval-auc:0.881738\n",
      "[809]\ttrain-auc:1\teval-auc:0.881753\n",
      "[810]\ttrain-auc:1\teval-auc:0.88175\n",
      "[811]\ttrain-auc:1\teval-auc:0.881759\n",
      "[812]\ttrain-auc:1\teval-auc:0.881762\n",
      "[813]\ttrain-auc:1\teval-auc:0.8818\n",
      "[814]\ttrain-auc:1\teval-auc:0.88181\n",
      "[815]\ttrain-auc:1\teval-auc:0.881823\n",
      "[816]\ttrain-auc:1\teval-auc:0.881828\n",
      "[817]\ttrain-auc:1\teval-auc:0.881827\n",
      "[818]\ttrain-auc:1\teval-auc:0.881838\n",
      "[819]\ttrain-auc:1\teval-auc:0.881833\n",
      "[820]\ttrain-auc:1\teval-auc:0.881832\n",
      "[821]\ttrain-auc:1\teval-auc:0.881822\n",
      "[822]\ttrain-auc:1\teval-auc:0.881829\n",
      "[823]\ttrain-auc:1\teval-auc:0.881818\n",
      "[824]\ttrain-auc:1\teval-auc:0.881813\n",
      "[825]\ttrain-auc:1\teval-auc:0.881803\n",
      "[826]\ttrain-auc:1\teval-auc:0.881823\n",
      "[827]\ttrain-auc:1\teval-auc:0.881837\n",
      "[828]\ttrain-auc:1\teval-auc:0.88187\n",
      "[829]\ttrain-auc:1\teval-auc:0.881866\n",
      "[830]\ttrain-auc:1\teval-auc:0.881855\n",
      "[831]\ttrain-auc:1\teval-auc:0.881879\n",
      "[832]\ttrain-auc:1\teval-auc:0.881865\n",
      "[833]\ttrain-auc:1\teval-auc:0.881863\n",
      "[834]\ttrain-auc:1\teval-auc:0.881871\n",
      "[835]\ttrain-auc:1\teval-auc:0.881881\n",
      "[836]\ttrain-auc:1\teval-auc:0.881875\n",
      "[837]\ttrain-auc:1\teval-auc:0.881886\n",
      "[838]\ttrain-auc:1\teval-auc:0.88191\n",
      "[839]\ttrain-auc:1\teval-auc:0.881909\n",
      "[840]\ttrain-auc:1\teval-auc:0.881917\n",
      "[841]\ttrain-auc:1\teval-auc:0.881917\n",
      "[842]\ttrain-auc:1\teval-auc:0.881906\n",
      "[843]\ttrain-auc:1\teval-auc:0.881908\n",
      "[844]\ttrain-auc:1\teval-auc:0.881903\n",
      "[845]\ttrain-auc:1\teval-auc:0.881908\n",
      "[846]\ttrain-auc:1\teval-auc:0.881905\n",
      "[847]\ttrain-auc:1\teval-auc:0.881928\n",
      "[848]\ttrain-auc:1\teval-auc:0.881923\n",
      "[849]\ttrain-auc:1\teval-auc:0.881922\n",
      "[850]\ttrain-auc:1\teval-auc:0.881924\n",
      "[851]\ttrain-auc:1\teval-auc:0.881921\n",
      "[852]\ttrain-auc:1\teval-auc:0.881919\n",
      "[853]\ttrain-auc:1\teval-auc:0.881924\n",
      "[854]\ttrain-auc:1\teval-auc:0.881928\n",
      "[855]\ttrain-auc:1\teval-auc:0.881929\n",
      "[856]\ttrain-auc:1\teval-auc:0.881917\n",
      "[857]\ttrain-auc:1\teval-auc:0.881918\n",
      "[858]\ttrain-auc:1\teval-auc:0.881907\n",
      "[859]\ttrain-auc:1\teval-auc:0.881905\n",
      "[860]\ttrain-auc:1\teval-auc:0.881902\n",
      "[861]\ttrain-auc:1\teval-auc:0.881917\n",
      "[862]\ttrain-auc:1\teval-auc:0.88193\n",
      "[863]\ttrain-auc:1\teval-auc:0.881935\n",
      "[864]\ttrain-auc:1\teval-auc:0.881952\n",
      "[865]\ttrain-auc:1\teval-auc:0.881968\n",
      "[866]\ttrain-auc:1\teval-auc:0.881958\n",
      "[867]\ttrain-auc:1\teval-auc:0.881977\n",
      "[868]\ttrain-auc:1\teval-auc:0.881979\n",
      "[869]\ttrain-auc:1\teval-auc:0.881997\n",
      "[870]\ttrain-auc:1\teval-auc:0.882003\n",
      "[871]\ttrain-auc:1\teval-auc:0.882011\n",
      "[872]\ttrain-auc:1\teval-auc:0.882019\n",
      "[873]\ttrain-auc:1\teval-auc:0.881995\n",
      "[874]\ttrain-auc:1\teval-auc:0.881986\n",
      "[875]\ttrain-auc:1\teval-auc:0.881988\n",
      "[876]\ttrain-auc:1\teval-auc:0.881979\n",
      "[877]\ttrain-auc:1\teval-auc:0.881985\n",
      "[878]\ttrain-auc:1\teval-auc:0.881992\n",
      "[879]\ttrain-auc:1\teval-auc:0.882007\n",
      "[880]\ttrain-auc:1\teval-auc:0.882018\n",
      "[881]\ttrain-auc:1\teval-auc:0.882001\n",
      "[882]\ttrain-auc:1\teval-auc:0.882002\n",
      "[883]\ttrain-auc:1\teval-auc:0.882009\n",
      "[884]\ttrain-auc:1\teval-auc:0.882002\n",
      "[885]\ttrain-auc:1\teval-auc:0.882007\n",
      "[886]\ttrain-auc:1\teval-auc:0.882022\n",
      "[887]\ttrain-auc:1\teval-auc:0.882035\n",
      "[888]\ttrain-auc:1\teval-auc:0.882042\n",
      "[889]\ttrain-auc:1\teval-auc:0.882046\n",
      "[890]\ttrain-auc:1\teval-auc:0.882061\n",
      "[891]\ttrain-auc:1\teval-auc:0.882085\n",
      "[892]\ttrain-auc:1\teval-auc:0.882102\n",
      "[893]\ttrain-auc:1\teval-auc:0.882091\n",
      "[894]\ttrain-auc:1\teval-auc:0.882079\n",
      "[895]\ttrain-auc:1\teval-auc:0.882088\n",
      "[896]\ttrain-auc:1\teval-auc:0.882099\n",
      "[897]\ttrain-auc:1\teval-auc:0.882104\n",
      "[898]\ttrain-auc:1\teval-auc:0.882095\n",
      "[899]\ttrain-auc:1\teval-auc:0.882096\n",
      "[900]\ttrain-auc:1\teval-auc:0.882097\n",
      "[901]\ttrain-auc:1\teval-auc:0.882109\n",
      "[902]\ttrain-auc:1\teval-auc:0.882103\n",
      "[903]\ttrain-auc:1\teval-auc:0.882111\n",
      "[904]\ttrain-auc:1\teval-auc:0.882125\n",
      "[905]\ttrain-auc:1\teval-auc:0.882134\n",
      "[906]\ttrain-auc:1\teval-auc:0.882131\n",
      "[907]\ttrain-auc:1\teval-auc:0.882139\n",
      "[908]\ttrain-auc:1\teval-auc:0.882137\n",
      "[909]\ttrain-auc:1\teval-auc:0.882126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[910]\ttrain-auc:1\teval-auc:0.882105\n",
      "[911]\ttrain-auc:1\teval-auc:0.882123\n",
      "[912]\ttrain-auc:1\teval-auc:0.882131\n",
      "[913]\ttrain-auc:1\teval-auc:0.882134\n",
      "[914]\ttrain-auc:1\teval-auc:0.882128\n",
      "[915]\ttrain-auc:1\teval-auc:0.882136\n",
      "[916]\ttrain-auc:1\teval-auc:0.882149\n",
      "[917]\ttrain-auc:1\teval-auc:0.882122\n",
      "[918]\ttrain-auc:1\teval-auc:0.882141\n",
      "[919]\ttrain-auc:1\teval-auc:0.882138\n",
      "[920]\ttrain-auc:1\teval-auc:0.882138\n",
      "[921]\ttrain-auc:1\teval-auc:0.882156\n",
      "[922]\ttrain-auc:1\teval-auc:0.882151\n",
      "[923]\ttrain-auc:1\teval-auc:0.88215\n",
      "[924]\ttrain-auc:1\teval-auc:0.882147\n",
      "[925]\ttrain-auc:1\teval-auc:0.882158\n",
      "[926]\ttrain-auc:1\teval-auc:0.882175\n",
      "[927]\ttrain-auc:1\teval-auc:0.88217\n",
      "[928]\ttrain-auc:1\teval-auc:0.882208\n",
      "[929]\ttrain-auc:1\teval-auc:0.882197\n",
      "[930]\ttrain-auc:1\teval-auc:0.88219\n",
      "[931]\ttrain-auc:1\teval-auc:0.882185\n",
      "[932]\ttrain-auc:1\teval-auc:0.882168\n",
      "[933]\ttrain-auc:1\teval-auc:0.882162\n",
      "[934]\ttrain-auc:1\teval-auc:0.882153\n",
      "[935]\ttrain-auc:1\teval-auc:0.88215\n",
      "[936]\ttrain-auc:1\teval-auc:0.882149\n",
      "[937]\ttrain-auc:1\teval-auc:0.882169\n",
      "[938]\ttrain-auc:1\teval-auc:0.882185\n",
      "[939]\ttrain-auc:1\teval-auc:0.882201\n",
      "[940]\ttrain-auc:1\teval-auc:0.88221\n",
      "[941]\ttrain-auc:1\teval-auc:0.882208\n",
      "[942]\ttrain-auc:1\teval-auc:0.882205\n",
      "[943]\ttrain-auc:1\teval-auc:0.882211\n",
      "[944]\ttrain-auc:1\teval-auc:0.88221\n",
      "[945]\ttrain-auc:1\teval-auc:0.882219\n",
      "[946]\ttrain-auc:1\teval-auc:0.882218\n",
      "[947]\ttrain-auc:1\teval-auc:0.882226\n",
      "[948]\ttrain-auc:1\teval-auc:0.882229\n",
      "[949]\ttrain-auc:1\teval-auc:0.882216\n",
      "[950]\ttrain-auc:1\teval-auc:0.882223\n",
      "[951]\ttrain-auc:1\teval-auc:0.882241\n",
      "[952]\ttrain-auc:1\teval-auc:0.882235\n",
      "[953]\ttrain-auc:1\teval-auc:0.882242\n",
      "[954]\ttrain-auc:1\teval-auc:0.882233\n",
      "[955]\ttrain-auc:1\teval-auc:0.882229\n",
      "[956]\ttrain-auc:1\teval-auc:0.882225\n",
      "[957]\ttrain-auc:1\teval-auc:0.882237\n",
      "[958]\ttrain-auc:1\teval-auc:0.882228\n",
      "[959]\ttrain-auc:1\teval-auc:0.88222\n",
      "[960]\ttrain-auc:1\teval-auc:0.882217\n",
      "[961]\ttrain-auc:1\teval-auc:0.882218\n",
      "[962]\ttrain-auc:1\teval-auc:0.882217\n",
      "[963]\ttrain-auc:1\teval-auc:0.882237\n",
      "[964]\ttrain-auc:1\teval-auc:0.882257\n",
      "[965]\ttrain-auc:1\teval-auc:0.882286\n",
      "[966]\ttrain-auc:1\teval-auc:0.882296\n",
      "[967]\ttrain-auc:1\teval-auc:0.882291\n",
      "[968]\ttrain-auc:1\teval-auc:0.882296\n",
      "[969]\ttrain-auc:1\teval-auc:0.882295\n",
      "[970]\ttrain-auc:1\teval-auc:0.882308\n",
      "[971]\ttrain-auc:1\teval-auc:0.882314\n",
      "[972]\ttrain-auc:1\teval-auc:0.882315\n",
      "[973]\ttrain-auc:1\teval-auc:0.882309\n",
      "[974]\ttrain-auc:1\teval-auc:0.882298\n",
      "[975]\ttrain-auc:1\teval-auc:0.882296\n",
      "[976]\ttrain-auc:1\teval-auc:0.882321\n",
      "[977]\ttrain-auc:1\teval-auc:0.882316\n",
      "[978]\ttrain-auc:1\teval-auc:0.882308\n",
      "[979]\ttrain-auc:1\teval-auc:0.882329\n",
      "[980]\ttrain-auc:1\teval-auc:0.88232\n",
      "[981]\ttrain-auc:1\teval-auc:0.88233\n",
      "[982]\ttrain-auc:1\teval-auc:0.882327\n",
      "[983]\ttrain-auc:1\teval-auc:0.882328\n",
      "[984]\ttrain-auc:1\teval-auc:0.882332\n",
      "[985]\ttrain-auc:1\teval-auc:0.882331\n",
      "[986]\ttrain-auc:1\teval-auc:0.882345\n",
      "[987]\ttrain-auc:1\teval-auc:0.882349\n",
      "[988]\ttrain-auc:1\teval-auc:0.882344\n",
      "[989]\ttrain-auc:1\teval-auc:0.882342\n",
      "[990]\ttrain-auc:1\teval-auc:0.882361\n",
      "[991]\ttrain-auc:1\teval-auc:0.882354\n",
      "[992]\ttrain-auc:1\teval-auc:0.88234\n",
      "[993]\ttrain-auc:1\teval-auc:0.882339\n",
      "[994]\ttrain-auc:1\teval-auc:0.882333\n",
      "[995]\ttrain-auc:1\teval-auc:0.882329\n",
      "[996]\ttrain-auc:1\teval-auc:0.882322\n",
      "[997]\ttrain-auc:1\teval-auc:0.882335\n",
      "[998]\ttrain-auc:1\teval-auc:0.882328\n",
      "[999]\ttrain-auc:1\teval-auc:0.882335\n",
      "[1000]\ttrain-auc:1\teval-auc:0.882336\n",
      "[1001]\ttrain-auc:1\teval-auc:0.882354\n",
      "[1002]\ttrain-auc:1\teval-auc:0.882363\n",
      "[1003]\ttrain-auc:1\teval-auc:0.882361\n",
      "[1004]\ttrain-auc:1\teval-auc:0.882363\n",
      "[1005]\ttrain-auc:1\teval-auc:0.882367\n",
      "[1006]\ttrain-auc:1\teval-auc:0.882363\n",
      "[1007]\ttrain-auc:1\teval-auc:0.882385\n",
      "[1008]\ttrain-auc:1\teval-auc:0.882401\n",
      "[1009]\ttrain-auc:1\teval-auc:0.882406\n",
      "[1010]\ttrain-auc:1\teval-auc:0.8824\n",
      "[1011]\ttrain-auc:1\teval-auc:0.882407\n",
      "[1012]\ttrain-auc:1\teval-auc:0.882408\n",
      "[1013]\ttrain-auc:1\teval-auc:0.882419\n",
      "[1014]\ttrain-auc:1\teval-auc:0.88243\n",
      "[1015]\ttrain-auc:1\teval-auc:0.882421\n",
      "[1016]\ttrain-auc:1\teval-auc:0.882419\n",
      "[1017]\ttrain-auc:1\teval-auc:0.882422\n",
      "[1018]\ttrain-auc:1\teval-auc:0.882432\n",
      "[1019]\ttrain-auc:1\teval-auc:0.882441\n",
      "[1020]\ttrain-auc:1\teval-auc:0.882439\n",
      "[1021]\ttrain-auc:1\teval-auc:0.88245\n",
      "[1022]\ttrain-auc:1\teval-auc:0.882457\n",
      "[1023]\ttrain-auc:1\teval-auc:0.882453\n",
      "[1024]\ttrain-auc:1\teval-auc:0.882453\n",
      "[1025]\ttrain-auc:1\teval-auc:0.882456\n",
      "[1026]\ttrain-auc:1\teval-auc:0.882459\n",
      "[1027]\ttrain-auc:1\teval-auc:0.882472\n",
      "[1028]\ttrain-auc:1\teval-auc:0.882474\n",
      "[1029]\ttrain-auc:1\teval-auc:0.882473\n",
      "[1030]\ttrain-auc:1\teval-auc:0.88248\n",
      "[1031]\ttrain-auc:1\teval-auc:0.882486\n",
      "[1032]\ttrain-auc:1\teval-auc:0.882485\n",
      "[1033]\ttrain-auc:1\teval-auc:0.882488\n",
      "[1034]\ttrain-auc:1\teval-auc:0.882494\n",
      "[1035]\ttrain-auc:1\teval-auc:0.882486\n",
      "[1036]\ttrain-auc:1\teval-auc:0.882479\n",
      "[1037]\ttrain-auc:1\teval-auc:0.882505\n",
      "[1038]\ttrain-auc:1\teval-auc:0.882519\n",
      "[1039]\ttrain-auc:1\teval-auc:0.882524\n",
      "[1040]\ttrain-auc:1\teval-auc:0.882513\n",
      "[1041]\ttrain-auc:1\teval-auc:0.882512\n",
      "[1042]\ttrain-auc:1\teval-auc:0.882513\n",
      "[1043]\ttrain-auc:1\teval-auc:0.88253\n",
      "[1044]\ttrain-auc:1\teval-auc:0.882525\n",
      "[1045]\ttrain-auc:1\teval-auc:0.882535\n",
      "[1046]\ttrain-auc:1\teval-auc:0.882542\n",
      "[1047]\ttrain-auc:1\teval-auc:0.882537\n",
      "[1048]\ttrain-auc:1\teval-auc:0.882532\n",
      "[1049]\ttrain-auc:1\teval-auc:0.882522\n",
      "[1050]\ttrain-auc:1\teval-auc:0.882533\n",
      "[1051]\ttrain-auc:1\teval-auc:0.882546\n",
      "[1052]\ttrain-auc:1\teval-auc:0.882551\n",
      "[1053]\ttrain-auc:1\teval-auc:0.882544\n",
      "[1054]\ttrain-auc:1\teval-auc:0.882544\n",
      "[1055]\ttrain-auc:1\teval-auc:0.882574\n",
      "[1056]\ttrain-auc:1\teval-auc:0.88256\n",
      "[1057]\ttrain-auc:1\teval-auc:0.882552\n",
      "[1058]\ttrain-auc:1\teval-auc:0.882552\n",
      "[1059]\ttrain-auc:1\teval-auc:0.882566\n",
      "[1060]\ttrain-auc:1\teval-auc:0.882563\n",
      "[1061]\ttrain-auc:1\teval-auc:0.882561\n",
      "[1062]\ttrain-auc:1\teval-auc:0.882581\n",
      "[1063]\ttrain-auc:1\teval-auc:0.882589\n",
      "[1064]\ttrain-auc:1\teval-auc:0.882595\n",
      "[1065]\ttrain-auc:1\teval-auc:0.882609\n",
      "[1066]\ttrain-auc:1\teval-auc:0.882607\n",
      "[1067]\ttrain-auc:1\teval-auc:0.882629\n",
      "[1068]\ttrain-auc:1\teval-auc:0.8826\n",
      "[1069]\ttrain-auc:1\teval-auc:0.882597\n",
      "[1070]\ttrain-auc:1\teval-auc:0.88262\n",
      "[1071]\ttrain-auc:1\teval-auc:0.882626\n",
      "[1072]\ttrain-auc:1\teval-auc:0.882637\n",
      "[1073]\ttrain-auc:1\teval-auc:0.88267\n",
      "[1074]\ttrain-auc:1\teval-auc:0.882678\n",
      "[1075]\ttrain-auc:1\teval-auc:0.882672\n",
      "[1076]\ttrain-auc:1\teval-auc:0.882665\n",
      "[1077]\ttrain-auc:1\teval-auc:0.882679\n",
      "[1078]\ttrain-auc:1\teval-auc:0.882689\n",
      "[1079]\ttrain-auc:1\teval-auc:0.882697\n",
      "[1080]\ttrain-auc:1\teval-auc:0.882716\n",
      "[1081]\ttrain-auc:1\teval-auc:0.882727\n",
      "[1082]\ttrain-auc:1\teval-auc:0.882731\n",
      "[1083]\ttrain-auc:1\teval-auc:0.882723\n",
      "[1084]\ttrain-auc:1\teval-auc:0.882733\n",
      "[1085]\ttrain-auc:1\teval-auc:0.882742\n",
      "[1086]\ttrain-auc:1\teval-auc:0.882742\n",
      "[1087]\ttrain-auc:1\teval-auc:0.882741\n",
      "[1088]\ttrain-auc:1\teval-auc:0.882746\n",
      "[1089]\ttrain-auc:1\teval-auc:0.88275\n",
      "[1090]\ttrain-auc:1\teval-auc:0.882741\n",
      "[1091]\ttrain-auc:1\teval-auc:0.882747\n",
      "[1092]\ttrain-auc:1\teval-auc:0.882754\n",
      "[1093]\ttrain-auc:1\teval-auc:0.882758\n",
      "[1094]\ttrain-auc:1\teval-auc:0.882753\n",
      "[1095]\ttrain-auc:1\teval-auc:0.882758\n",
      "[1096]\ttrain-auc:1\teval-auc:0.882759\n",
      "[1097]\ttrain-auc:1\teval-auc:0.882762\n",
      "[1098]\ttrain-auc:1\teval-auc:0.882763\n",
      "[1099]\ttrain-auc:1\teval-auc:0.882764\n",
      "[1100]\ttrain-auc:1\teval-auc:0.882775\n",
      "[1101]\ttrain-auc:1\teval-auc:0.882766\n",
      "[1102]\ttrain-auc:1\teval-auc:0.882778\n",
      "[1103]\ttrain-auc:1\teval-auc:0.882796\n",
      "[1104]\ttrain-auc:1\teval-auc:0.882805\n",
      "[1105]\ttrain-auc:1\teval-auc:0.882807\n",
      "[1106]\ttrain-auc:1\teval-auc:0.882808\n",
      "[1107]\ttrain-auc:1\teval-auc:0.882809\n",
      "[1108]\ttrain-auc:1\teval-auc:0.882816\n",
      "[1109]\ttrain-auc:1\teval-auc:0.882811\n",
      "[1110]\ttrain-auc:1\teval-auc:0.882812\n",
      "[1111]\ttrain-auc:1\teval-auc:0.882828\n",
      "[1112]\ttrain-auc:1\teval-auc:0.882832\n",
      "[1113]\ttrain-auc:1\teval-auc:0.882829\n",
      "[1114]\ttrain-auc:1\teval-auc:0.882825\n",
      "[1115]\ttrain-auc:1\teval-auc:0.882828\n",
      "[1116]\ttrain-auc:1\teval-auc:0.882838\n",
      "[1117]\ttrain-auc:1\teval-auc:0.882828\n",
      "[1118]\ttrain-auc:1\teval-auc:0.882822\n",
      "[1119]\ttrain-auc:1\teval-auc:0.882824\n",
      "[1120]\ttrain-auc:1\teval-auc:0.882836\n",
      "[1121]\ttrain-auc:1\teval-auc:0.88285\n",
      "[1122]\ttrain-auc:1\teval-auc:0.882852\n",
      "[1123]\ttrain-auc:1\teval-auc:0.882862\n",
      "[1124]\ttrain-auc:1\teval-auc:0.882847\n",
      "[1125]\ttrain-auc:1\teval-auc:0.882854\n",
      "[1126]\ttrain-auc:1\teval-auc:0.882857\n",
      "[1127]\ttrain-auc:1\teval-auc:0.882867\n",
      "[1128]\ttrain-auc:1\teval-auc:0.882863\n",
      "[1129]\ttrain-auc:1\teval-auc:0.882863\n",
      "[1130]\ttrain-auc:1\teval-auc:0.882863\n",
      "[1131]\ttrain-auc:1\teval-auc:0.882856\n",
      "[1132]\ttrain-auc:1\teval-auc:0.882849\n",
      "[1133]\ttrain-auc:1\teval-auc:0.882857\n",
      "[1134]\ttrain-auc:1\teval-auc:0.882868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1135]\ttrain-auc:1\teval-auc:0.882869\n",
      "[1136]\ttrain-auc:1\teval-auc:0.882878\n",
      "[1137]\ttrain-auc:1\teval-auc:0.882891\n",
      "[1138]\ttrain-auc:1\teval-auc:0.88288\n",
      "[1139]\ttrain-auc:1\teval-auc:0.882891\n",
      "[1140]\ttrain-auc:1\teval-auc:0.882909\n",
      "[1141]\ttrain-auc:1\teval-auc:0.882927\n",
      "[1142]\ttrain-auc:1\teval-auc:0.882929\n",
      "[1143]\ttrain-auc:1\teval-auc:0.882934\n",
      "[1144]\ttrain-auc:1\teval-auc:0.882937\n",
      "[1145]\ttrain-auc:1\teval-auc:0.882954\n",
      "[1146]\ttrain-auc:1\teval-auc:0.882961\n",
      "[1147]\ttrain-auc:1\teval-auc:0.882968\n",
      "[1148]\ttrain-auc:1\teval-auc:0.882984\n",
      "[1149]\ttrain-auc:1\teval-auc:0.882978\n",
      "[1150]\ttrain-auc:1\teval-auc:0.882976\n",
      "[1151]\ttrain-auc:1\teval-auc:0.882989\n",
      "[1152]\ttrain-auc:1\teval-auc:0.882986\n",
      "[1153]\ttrain-auc:1\teval-auc:0.88299\n",
      "[1154]\ttrain-auc:1\teval-auc:0.882981\n",
      "[1155]\ttrain-auc:1\teval-auc:0.882975\n",
      "[1156]\ttrain-auc:1\teval-auc:0.88297\n",
      "[1157]\ttrain-auc:1\teval-auc:0.882977\n",
      "[1158]\ttrain-auc:1\teval-auc:0.882986\n",
      "[1159]\ttrain-auc:1\teval-auc:0.882981\n",
      "[1160]\ttrain-auc:1\teval-auc:0.882993\n",
      "[1161]\ttrain-auc:1\teval-auc:0.883004\n",
      "[1162]\ttrain-auc:1\teval-auc:0.883\n",
      "[1163]\ttrain-auc:1\teval-auc:0.88299\n",
      "[1164]\ttrain-auc:1\teval-auc:0.882998\n",
      "[1165]\ttrain-auc:1\teval-auc:0.882995\n",
      "[1166]\ttrain-auc:1\teval-auc:0.882998\n",
      "[1167]\ttrain-auc:1\teval-auc:0.883003\n",
      "[1168]\ttrain-auc:1\teval-auc:0.882996\n",
      "[1169]\ttrain-auc:1\teval-auc:0.882996\n",
      "[1170]\ttrain-auc:1\teval-auc:0.88298\n",
      "[1171]\ttrain-auc:1\teval-auc:0.882981\n",
      "[1172]\ttrain-auc:1\teval-auc:0.88299\n",
      "[1173]\ttrain-auc:1\teval-auc:0.882997\n",
      "[1174]\ttrain-auc:1\teval-auc:0.883\n",
      "[1175]\ttrain-auc:1\teval-auc:0.882997\n",
      "[1176]\ttrain-auc:1\teval-auc:0.883002\n",
      "[1177]\ttrain-auc:1\teval-auc:0.883015\n",
      "[1178]\ttrain-auc:1\teval-auc:0.883023\n",
      "[1179]\ttrain-auc:1\teval-auc:0.883025\n",
      "[1180]\ttrain-auc:1\teval-auc:0.883034\n",
      "[1181]\ttrain-auc:1\teval-auc:0.883041\n",
      "[1182]\ttrain-auc:1\teval-auc:0.883038\n",
      "[1183]\ttrain-auc:1\teval-auc:0.883034\n",
      "[1184]\ttrain-auc:1\teval-auc:0.883026\n",
      "[1185]\ttrain-auc:1\teval-auc:0.883023\n",
      "[1186]\ttrain-auc:1\teval-auc:0.883025\n",
      "[1187]\ttrain-auc:1\teval-auc:0.883023\n",
      "[1188]\ttrain-auc:1\teval-auc:0.883025\n",
      "[1189]\ttrain-auc:1\teval-auc:0.88304\n",
      "[1190]\ttrain-auc:1\teval-auc:0.883031\n",
      "[1191]\ttrain-auc:1\teval-auc:0.883043\n",
      "[1192]\ttrain-auc:1\teval-auc:0.883046\n",
      "[1193]\ttrain-auc:1\teval-auc:0.883051\n",
      "[1194]\ttrain-auc:1\teval-auc:0.883039\n",
      "[1195]\ttrain-auc:1\teval-auc:0.883054\n",
      "[1196]\ttrain-auc:1\teval-auc:0.883048\n",
      "[1197]\ttrain-auc:1\teval-auc:0.883056\n",
      "[1198]\ttrain-auc:1\teval-auc:0.883044\n",
      "[1199]\ttrain-auc:1\teval-auc:0.883053\n",
      "[1200]\ttrain-auc:1\teval-auc:0.883052\n",
      "[1201]\ttrain-auc:1\teval-auc:0.883059\n",
      "[1202]\ttrain-auc:1\teval-auc:0.883045\n",
      "[1203]\ttrain-auc:1\teval-auc:0.883047\n",
      "[1204]\ttrain-auc:1\teval-auc:0.883036\n",
      "[1205]\ttrain-auc:1\teval-auc:0.883041\n",
      "[1206]\ttrain-auc:1\teval-auc:0.883026\n",
      "[1207]\ttrain-auc:1\teval-auc:0.883026\n",
      "[1208]\ttrain-auc:1\teval-auc:0.883011\n",
      "[1209]\ttrain-auc:1\teval-auc:0.883026\n",
      "[1210]\ttrain-auc:1\teval-auc:0.883026\n",
      "[1211]\ttrain-auc:1\teval-auc:0.883042\n",
      "[1212]\ttrain-auc:1\teval-auc:0.883021\n",
      "[1213]\ttrain-auc:1\teval-auc:0.883018\n",
      "[1214]\ttrain-auc:1\teval-auc:0.883024\n",
      "[1215]\ttrain-auc:1\teval-auc:0.883029\n",
      "[1216]\ttrain-auc:1\teval-auc:0.883034\n",
      "[1217]\ttrain-auc:1\teval-auc:0.883045\n",
      "[1218]\ttrain-auc:1\teval-auc:0.883042\n",
      "[1219]\ttrain-auc:1\teval-auc:0.883042\n",
      "[1220]\ttrain-auc:1\teval-auc:0.883059\n",
      "[1221]\ttrain-auc:1\teval-auc:0.883068\n",
      "[1222]\ttrain-auc:1\teval-auc:0.883082\n",
      "[1223]\ttrain-auc:1\teval-auc:0.883085\n",
      "[1224]\ttrain-auc:1\teval-auc:0.883101\n",
      "[1225]\ttrain-auc:1\teval-auc:0.883102\n",
      "[1226]\ttrain-auc:1\teval-auc:0.883102\n",
      "[1227]\ttrain-auc:1\teval-auc:0.883109\n",
      "[1228]\ttrain-auc:1\teval-auc:0.883105\n",
      "[1229]\ttrain-auc:1\teval-auc:0.883097\n",
      "[1230]\ttrain-auc:1\teval-auc:0.88309\n",
      "[1231]\ttrain-auc:1\teval-auc:0.883084\n",
      "[1232]\ttrain-auc:1\teval-auc:0.883085\n",
      "[1233]\ttrain-auc:1\teval-auc:0.883078\n",
      "[1234]\ttrain-auc:1\teval-auc:0.883078\n",
      "[1235]\ttrain-auc:1\teval-auc:0.883087\n",
      "[1236]\ttrain-auc:1\teval-auc:0.883089\n",
      "[1237]\ttrain-auc:1\teval-auc:0.883095\n",
      "[1238]\ttrain-auc:1\teval-auc:0.883085\n",
      "[1239]\ttrain-auc:1\teval-auc:0.883095\n",
      "[1240]\ttrain-auc:1\teval-auc:0.883115\n",
      "[1241]\ttrain-auc:1\teval-auc:0.883122\n",
      "[1242]\ttrain-auc:1\teval-auc:0.883128\n",
      "[1243]\ttrain-auc:1\teval-auc:0.883135\n",
      "[1244]\ttrain-auc:1\teval-auc:0.883146\n",
      "[1245]\ttrain-auc:1\teval-auc:0.883146\n",
      "[1246]\ttrain-auc:1\teval-auc:0.88313\n",
      "[1247]\ttrain-auc:1\teval-auc:0.883131\n",
      "[1248]\ttrain-auc:1\teval-auc:0.883133\n",
      "[1249]\ttrain-auc:1\teval-auc:0.883141\n",
      "[1250]\ttrain-auc:1\teval-auc:0.883142\n",
      "[1251]\ttrain-auc:1\teval-auc:0.883135\n",
      "[1252]\ttrain-auc:1\teval-auc:0.883127\n",
      "[1253]\ttrain-auc:1\teval-auc:0.88313\n",
      "[1254]\ttrain-auc:1\teval-auc:0.883144\n",
      "[1255]\ttrain-auc:1\teval-auc:0.883143\n",
      "[1256]\ttrain-auc:1\teval-auc:0.883149\n",
      "[1257]\ttrain-auc:1\teval-auc:0.883158\n",
      "[1258]\ttrain-auc:1\teval-auc:0.883162\n",
      "[1259]\ttrain-auc:1\teval-auc:0.883167\n",
      "[1260]\ttrain-auc:1\teval-auc:0.883176\n",
      "[1261]\ttrain-auc:1\teval-auc:0.883181\n",
      "[1262]\ttrain-auc:1\teval-auc:0.88319\n",
      "[1263]\ttrain-auc:1\teval-auc:0.883192\n",
      "[1264]\ttrain-auc:1\teval-auc:0.883195\n",
      "[1265]\ttrain-auc:1\teval-auc:0.883184\n",
      "[1266]\ttrain-auc:1\teval-auc:0.883196\n",
      "[1267]\ttrain-auc:1\teval-auc:0.883205\n",
      "[1268]\ttrain-auc:1\teval-auc:0.883194\n",
      "[1269]\ttrain-auc:1\teval-auc:0.883197\n",
      "[1270]\ttrain-auc:1\teval-auc:0.883203\n",
      "[1271]\ttrain-auc:1\teval-auc:0.883209\n",
      "[1272]\ttrain-auc:1\teval-auc:0.883231\n",
      "[1273]\ttrain-auc:1\teval-auc:0.883231\n",
      "[1274]\ttrain-auc:1\teval-auc:0.88323\n",
      "[1275]\ttrain-auc:1\teval-auc:0.883238\n",
      "[1276]\ttrain-auc:1\teval-auc:0.883249\n",
      "[1277]\ttrain-auc:1\teval-auc:0.883252\n",
      "[1278]\ttrain-auc:1\teval-auc:0.883253\n",
      "[1279]\ttrain-auc:1\teval-auc:0.883259\n",
      "[1280]\ttrain-auc:1\teval-auc:0.883264\n",
      "[1281]\ttrain-auc:1\teval-auc:0.88325\n",
      "[1282]\ttrain-auc:1\teval-auc:0.883244\n",
      "[1283]\ttrain-auc:1\teval-auc:0.883244\n",
      "[1284]\ttrain-auc:1\teval-auc:0.883235\n",
      "[1285]\ttrain-auc:1\teval-auc:0.883236\n",
      "[1286]\ttrain-auc:1\teval-auc:0.883241\n",
      "[1287]\ttrain-auc:1\teval-auc:0.883255\n",
      "[1288]\ttrain-auc:1\teval-auc:0.883262\n",
      "[1289]\ttrain-auc:1\teval-auc:0.883255\n",
      "[1290]\ttrain-auc:1\teval-auc:0.883278\n",
      "[1291]\ttrain-auc:1\teval-auc:0.88327\n",
      "[1292]\ttrain-auc:1\teval-auc:0.883272\n",
      "[1293]\ttrain-auc:1\teval-auc:0.883277\n",
      "[1294]\ttrain-auc:1\teval-auc:0.883293\n",
      "[1295]\ttrain-auc:1\teval-auc:0.88328\n",
      "[1296]\ttrain-auc:1\teval-auc:0.883284\n",
      "[1297]\ttrain-auc:1\teval-auc:0.883289\n",
      "[1298]\ttrain-auc:1\teval-auc:0.883294\n",
      "[1299]\ttrain-auc:1\teval-auc:0.883301\n",
      "[1300]\ttrain-auc:1\teval-auc:0.883301\n",
      "[1301]\ttrain-auc:1\teval-auc:0.883301\n",
      "[1302]\ttrain-auc:1\teval-auc:0.883307\n",
      "[1303]\ttrain-auc:1\teval-auc:0.883305\n",
      "[1304]\ttrain-auc:1\teval-auc:0.883323\n",
      "[1305]\ttrain-auc:1\teval-auc:0.883322\n",
      "[1306]\ttrain-auc:1\teval-auc:0.883315\n",
      "[1307]\ttrain-auc:1\teval-auc:0.883325\n",
      "[1308]\ttrain-auc:1\teval-auc:0.883333\n",
      "[1309]\ttrain-auc:1\teval-auc:0.883343\n",
      "[1310]\ttrain-auc:1\teval-auc:0.883357\n",
      "[1311]\ttrain-auc:1\teval-auc:0.883369\n",
      "[1312]\ttrain-auc:1\teval-auc:0.883374\n",
      "[1313]\ttrain-auc:1\teval-auc:0.883377\n",
      "[1314]\ttrain-auc:1\teval-auc:0.883381\n",
      "[1315]\ttrain-auc:1\teval-auc:0.883382\n",
      "[1316]\ttrain-auc:1\teval-auc:0.883386\n",
      "[1317]\ttrain-auc:1\teval-auc:0.883393\n",
      "[1318]\ttrain-auc:1\teval-auc:0.883398\n",
      "[1319]\ttrain-auc:1\teval-auc:0.883407\n",
      "[1320]\ttrain-auc:1\teval-auc:0.883418\n",
      "[1321]\ttrain-auc:1\teval-auc:0.883418\n",
      "[1322]\ttrain-auc:1\teval-auc:0.883423\n",
      "[1323]\ttrain-auc:1\teval-auc:0.883422\n",
      "[1324]\ttrain-auc:1\teval-auc:0.883437\n",
      "[1325]\ttrain-auc:1\teval-auc:0.883438\n",
      "[1326]\ttrain-auc:1\teval-auc:0.88344\n",
      "[1327]\ttrain-auc:1\teval-auc:0.883429\n",
      "[1328]\ttrain-auc:1\teval-auc:0.883426\n",
      "[1329]\ttrain-auc:1\teval-auc:0.883433\n",
      "[1330]\ttrain-auc:1\teval-auc:0.883424\n",
      "[1331]\ttrain-auc:1\teval-auc:0.883425\n",
      "[1332]\ttrain-auc:1\teval-auc:0.88343\n",
      "[1333]\ttrain-auc:1\teval-auc:0.883421\n",
      "[1334]\ttrain-auc:1\teval-auc:0.883428\n",
      "[1335]\ttrain-auc:1\teval-auc:0.883438\n",
      "[1336]\ttrain-auc:1\teval-auc:0.88345\n",
      "[1337]\ttrain-auc:1\teval-auc:0.883456\n",
      "[1338]\ttrain-auc:1\teval-auc:0.883459\n",
      "[1339]\ttrain-auc:1\teval-auc:0.883453\n",
      "[1340]\ttrain-auc:1\teval-auc:0.883456\n",
      "[1341]\ttrain-auc:1\teval-auc:0.883462\n",
      "[1342]\ttrain-auc:1\teval-auc:0.883457\n",
      "[1343]\ttrain-auc:1\teval-auc:0.883466\n",
      "[1344]\ttrain-auc:1\teval-auc:0.883459\n",
      "[1345]\ttrain-auc:1\teval-auc:0.883449\n",
      "[1346]\ttrain-auc:1\teval-auc:0.883448\n",
      "[1347]\ttrain-auc:1\teval-auc:0.883449\n",
      "[1348]\ttrain-auc:1\teval-auc:0.883447\n",
      "[1349]\ttrain-auc:1\teval-auc:0.883437\n",
      "[1350]\ttrain-auc:1\teval-auc:0.883438\n",
      "[1351]\ttrain-auc:1\teval-auc:0.883425\n",
      "[1352]\ttrain-auc:1\teval-auc:0.883422\n",
      "[1353]\ttrain-auc:1\teval-auc:0.883411\n",
      "[1354]\ttrain-auc:1\teval-auc:0.883411\n",
      "[1355]\ttrain-auc:1\teval-auc:0.883408\n",
      "[1356]\ttrain-auc:1\teval-auc:0.883412\n",
      "[1357]\ttrain-auc:1\teval-auc:0.883409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1358]\ttrain-auc:1\teval-auc:0.88341\n",
      "[1359]\ttrain-auc:1\teval-auc:0.883412\n",
      "[1360]\ttrain-auc:1\teval-auc:0.883416\n",
      "[1361]\ttrain-auc:1\teval-auc:0.883426\n",
      "[1362]\ttrain-auc:1\teval-auc:0.883422\n",
      "[1363]\ttrain-auc:1\teval-auc:0.883417\n",
      "[1364]\ttrain-auc:1\teval-auc:0.883414\n",
      "[1365]\ttrain-auc:1\teval-auc:0.88341\n",
      "[1366]\ttrain-auc:1\teval-auc:0.883416\n",
      "[1367]\ttrain-auc:1\teval-auc:0.883406\n",
      "[1368]\ttrain-auc:1\teval-auc:0.883397\n",
      "[1369]\ttrain-auc:1\teval-auc:0.883398\n",
      "[1370]\ttrain-auc:1\teval-auc:0.883412\n",
      "[1371]\ttrain-auc:1\teval-auc:0.883411\n",
      "[1372]\ttrain-auc:1\teval-auc:0.88342\n",
      "[1373]\ttrain-auc:1\teval-auc:0.883411\n",
      "[1374]\ttrain-auc:1\teval-auc:0.883417\n",
      "[1375]\ttrain-auc:1\teval-auc:0.883434\n",
      "[1376]\ttrain-auc:1\teval-auc:0.883434\n",
      "[1377]\ttrain-auc:1\teval-auc:0.883432\n",
      "[1378]\ttrain-auc:1\teval-auc:0.883431\n",
      "[1379]\ttrain-auc:1\teval-auc:0.883435\n",
      "[1380]\ttrain-auc:1\teval-auc:0.883445\n",
      "[1381]\ttrain-auc:1\teval-auc:0.883454\n",
      "[1382]\ttrain-auc:1\teval-auc:0.883455\n",
      "[1383]\ttrain-auc:1\teval-auc:0.883461\n",
      "[1384]\ttrain-auc:1\teval-auc:0.883468\n",
      "[1385]\ttrain-auc:1\teval-auc:0.883481\n",
      "[1386]\ttrain-auc:1\teval-auc:0.883474\n",
      "[1387]\ttrain-auc:1\teval-auc:0.883477\n",
      "[1388]\ttrain-auc:1\teval-auc:0.883468\n",
      "[1389]\ttrain-auc:1\teval-auc:0.883482\n",
      "[1390]\ttrain-auc:1\teval-auc:0.883492\n",
      "[1391]\ttrain-auc:1\teval-auc:0.883498\n",
      "[1392]\ttrain-auc:1\teval-auc:0.883499\n",
      "[1393]\ttrain-auc:1\teval-auc:0.883498\n",
      "[1394]\ttrain-auc:1\teval-auc:0.883482\n",
      "[1395]\ttrain-auc:1\teval-auc:0.883493\n",
      "[1396]\ttrain-auc:1\teval-auc:0.88348\n",
      "[1397]\ttrain-auc:1\teval-auc:0.88348\n",
      "[1398]\ttrain-auc:1\teval-auc:0.883465\n",
      "[1399]\ttrain-auc:1\teval-auc:0.883456\n",
      "[1400]\ttrain-auc:1\teval-auc:0.883462\n",
      "[1401]\ttrain-auc:1\teval-auc:0.883455\n",
      "[1402]\ttrain-auc:1\teval-auc:0.883457\n",
      "[1403]\ttrain-auc:1\teval-auc:0.88347\n",
      "[1404]\ttrain-auc:1\teval-auc:0.883476\n",
      "[1405]\ttrain-auc:1\teval-auc:0.88347\n",
      "[1406]\ttrain-auc:1\teval-auc:0.883471\n",
      "[1407]\ttrain-auc:1\teval-auc:0.883466\n",
      "[1408]\ttrain-auc:1\teval-auc:0.883477\n",
      "[1409]\ttrain-auc:1\teval-auc:0.883482\n",
      "[1410]\ttrain-auc:1\teval-auc:0.883489\n",
      "[1411]\ttrain-auc:1\teval-auc:0.88349\n",
      "[1412]\ttrain-auc:1\teval-auc:0.883483\n",
      "[1413]\ttrain-auc:1\teval-auc:0.883471\n",
      "[1414]\ttrain-auc:1\teval-auc:0.883471\n",
      "[1415]\ttrain-auc:1\teval-auc:0.883483\n",
      "[1416]\ttrain-auc:1\teval-auc:0.883497\n",
      "[1417]\ttrain-auc:1\teval-auc:0.883498\n",
      "[1418]\ttrain-auc:1\teval-auc:0.883501\n",
      "[1419]\ttrain-auc:1\teval-auc:0.883508\n",
      "[1420]\ttrain-auc:1\teval-auc:0.883517\n",
      "[1421]\ttrain-auc:1\teval-auc:0.883535\n",
      "[1422]\ttrain-auc:1\teval-auc:0.883537\n",
      "[1423]\ttrain-auc:1\teval-auc:0.883548\n",
      "[1424]\ttrain-auc:1\teval-auc:0.883545\n",
      "[1425]\ttrain-auc:1\teval-auc:0.883532\n",
      "[1426]\ttrain-auc:1\teval-auc:0.883533\n",
      "[1427]\ttrain-auc:1\teval-auc:0.883545\n",
      "[1428]\ttrain-auc:1\teval-auc:0.883561\n",
      "[1429]\ttrain-auc:1\teval-auc:0.883556\n",
      "[1430]\ttrain-auc:1\teval-auc:0.883548\n",
      "[1431]\ttrain-auc:1\teval-auc:0.883542\n",
      "[1432]\ttrain-auc:1\teval-auc:0.883546\n",
      "[1433]\ttrain-auc:1\teval-auc:0.883537\n",
      "[1434]\ttrain-auc:1\teval-auc:0.883535\n",
      "[1435]\ttrain-auc:1\teval-auc:0.883535\n",
      "[1436]\ttrain-auc:1\teval-auc:0.883537\n",
      "[1437]\ttrain-auc:1\teval-auc:0.88354\n",
      "[1438]\ttrain-auc:1\teval-auc:0.88354\n",
      "[1439]\ttrain-auc:1\teval-auc:0.883546\n",
      "[1440]\ttrain-auc:1\teval-auc:0.883543\n",
      "[1441]\ttrain-auc:1\teval-auc:0.883537\n",
      "[1442]\ttrain-auc:1\teval-auc:0.883538\n",
      "[1443]\ttrain-auc:1\teval-auc:0.883548\n",
      "[1444]\ttrain-auc:1\teval-auc:0.883545\n",
      "[1445]\ttrain-auc:1\teval-auc:0.883541\n",
      "[1446]\ttrain-auc:1\teval-auc:0.883541\n",
      "[1447]\ttrain-auc:1\teval-auc:0.883545\n",
      "[1448]\ttrain-auc:1\teval-auc:0.883557\n",
      "[1449]\ttrain-auc:1\teval-auc:0.883547\n",
      "[1450]\ttrain-auc:1\teval-auc:0.883551\n",
      "[1451]\ttrain-auc:1\teval-auc:0.883551\n",
      "[1452]\ttrain-auc:1\teval-auc:0.883552\n",
      "[1453]\ttrain-auc:1\teval-auc:0.88355\n",
      "[1454]\ttrain-auc:1\teval-auc:0.883559\n",
      "[1455]\ttrain-auc:1\teval-auc:0.883563\n",
      "[1456]\ttrain-auc:1\teval-auc:0.883561\n",
      "[1457]\ttrain-auc:1\teval-auc:0.883571\n",
      "[1458]\ttrain-auc:1\teval-auc:0.883564\n",
      "[1459]\ttrain-auc:1\teval-auc:0.883571\n",
      "[1460]\ttrain-auc:1\teval-auc:0.883569\n",
      "[1461]\ttrain-auc:1\teval-auc:0.883565\n",
      "[1462]\ttrain-auc:1\teval-auc:0.883569\n",
      "[1463]\ttrain-auc:1\teval-auc:0.88357\n",
      "[1464]\ttrain-auc:1\teval-auc:0.883581\n",
      "[1465]\ttrain-auc:1\teval-auc:0.883576\n",
      "[1466]\ttrain-auc:1\teval-auc:0.883581\n",
      "[1467]\ttrain-auc:1\teval-auc:0.883593\n",
      "[1468]\ttrain-auc:1\teval-auc:0.883596\n",
      "[1469]\ttrain-auc:1\teval-auc:0.883597\n",
      "[1470]\ttrain-auc:1\teval-auc:0.8836\n",
      "[1471]\ttrain-auc:1\teval-auc:0.883599\n",
      "[1472]\ttrain-auc:1\teval-auc:0.883597\n",
      "[1473]\ttrain-auc:1\teval-auc:0.883602\n",
      "[1474]\ttrain-auc:1\teval-auc:0.883599\n",
      "[1475]\ttrain-auc:1\teval-auc:0.883598\n",
      "[1476]\ttrain-auc:1\teval-auc:0.883592\n",
      "[1477]\ttrain-auc:1\teval-auc:0.883597\n",
      "[1478]\ttrain-auc:1\teval-auc:0.883596\n",
      "[1479]\ttrain-auc:1\teval-auc:0.883594\n",
      "[1480]\ttrain-auc:1\teval-auc:0.883599\n",
      "[1481]\ttrain-auc:1\teval-auc:0.883586\n",
      "[1482]\ttrain-auc:1\teval-auc:0.883584\n",
      "[1483]\ttrain-auc:1\teval-auc:0.883577\n",
      "[1484]\ttrain-auc:1\teval-auc:0.883581\n",
      "[1485]\ttrain-auc:1\teval-auc:0.883577\n",
      "[1486]\ttrain-auc:1\teval-auc:0.88358\n",
      "[1487]\ttrain-auc:1\teval-auc:0.883591\n",
      "[1488]\ttrain-auc:1\teval-auc:0.883599\n",
      "[1489]\ttrain-auc:1\teval-auc:0.883588\n",
      "[1490]\ttrain-auc:1\teval-auc:0.883595\n",
      "[1491]\ttrain-auc:1\teval-auc:0.883607\n",
      "[1492]\ttrain-auc:1\teval-auc:0.883614\n",
      "[1493]\ttrain-auc:1\teval-auc:0.883622\n",
      "[1494]\ttrain-auc:1\teval-auc:0.88362\n",
      "[1495]\ttrain-auc:1\teval-auc:0.883613\n",
      "[1496]\ttrain-auc:1\teval-auc:0.883606\n",
      "[1497]\ttrain-auc:1\teval-auc:0.883599\n",
      "[1498]\ttrain-auc:1\teval-auc:0.883609\n",
      "[1499]\ttrain-auc:1\teval-auc:0.883611\n",
      "[1500]\ttrain-auc:1\teval-auc:0.883614\n",
      "[1501]\ttrain-auc:1\teval-auc:0.883613\n",
      "[1502]\ttrain-auc:1\teval-auc:0.883613\n",
      "[1503]\ttrain-auc:1\teval-auc:0.8836\n",
      "[1504]\ttrain-auc:1\teval-auc:0.883606\n",
      "[1505]\ttrain-auc:1\teval-auc:0.883602\n",
      "[1506]\ttrain-auc:1\teval-auc:0.883603\n",
      "[1507]\ttrain-auc:1\teval-auc:0.883616\n",
      "[1508]\ttrain-auc:1\teval-auc:0.883625\n",
      "[1509]\ttrain-auc:1\teval-auc:0.883632\n",
      "[1510]\ttrain-auc:1\teval-auc:0.883639\n",
      "[1511]\ttrain-auc:1\teval-auc:0.883638\n",
      "[1512]\ttrain-auc:1\teval-auc:0.883643\n",
      "[1513]\ttrain-auc:1\teval-auc:0.883632\n",
      "[1514]\ttrain-auc:1\teval-auc:0.883617\n",
      "[1515]\ttrain-auc:1\teval-auc:0.883622\n",
      "[1516]\ttrain-auc:1\teval-auc:0.883621\n",
      "[1517]\ttrain-auc:1\teval-auc:0.883625\n",
      "[1518]\ttrain-auc:1\teval-auc:0.883621\n",
      "[1519]\ttrain-auc:1\teval-auc:0.883613\n",
      "[1520]\ttrain-auc:1\teval-auc:0.883609\n",
      "[1521]\ttrain-auc:1\teval-auc:0.883612\n",
      "[1522]\ttrain-auc:1\teval-auc:0.883611\n",
      "[1523]\ttrain-auc:1\teval-auc:0.883615\n",
      "[1524]\ttrain-auc:1\teval-auc:0.883611\n",
      "[1525]\ttrain-auc:1\teval-auc:0.883606\n",
      "[1526]\ttrain-auc:1\teval-auc:0.883606\n",
      "[1527]\ttrain-auc:1\teval-auc:0.883599\n",
      "[1528]\ttrain-auc:1\teval-auc:0.883603\n",
      "[1529]\ttrain-auc:1\teval-auc:0.883591\n",
      "[1530]\ttrain-auc:1\teval-auc:0.883593\n",
      "[1531]\ttrain-auc:1\teval-auc:0.883596\n",
      "[1532]\ttrain-auc:1\teval-auc:0.883588\n",
      "[1533]\ttrain-auc:1\teval-auc:0.883597\n",
      "[1534]\ttrain-auc:1\teval-auc:0.883594\n",
      "[1535]\ttrain-auc:1\teval-auc:0.883603\n",
      "[1536]\ttrain-auc:1\teval-auc:0.883609\n",
      "[1537]\ttrain-auc:1\teval-auc:0.883609\n",
      "[1538]\ttrain-auc:1\teval-auc:0.883609\n",
      "[1539]\ttrain-auc:1\teval-auc:0.883604\n",
      "[1540]\ttrain-auc:1\teval-auc:0.883615\n",
      "[1541]\ttrain-auc:1\teval-auc:0.883614\n",
      "[1542]\ttrain-auc:1\teval-auc:0.883608\n",
      "[1543]\ttrain-auc:1\teval-auc:0.88361\n",
      "[1544]\ttrain-auc:1\teval-auc:0.883604\n",
      "[1545]\ttrain-auc:1\teval-auc:0.883596\n",
      "[1546]\ttrain-auc:1\teval-auc:0.8836\n",
      "[1547]\ttrain-auc:1\teval-auc:0.883596\n",
      "[1548]\ttrain-auc:1\teval-auc:0.88359\n",
      "[1549]\ttrain-auc:1\teval-auc:0.88359\n",
      "[1550]\ttrain-auc:1\teval-auc:0.883593\n",
      "[1551]\ttrain-auc:1\teval-auc:0.883609\n",
      "[1552]\ttrain-auc:1\teval-auc:0.883605\n",
      "[1553]\ttrain-auc:1\teval-auc:0.883606\n",
      "[1554]\ttrain-auc:1\teval-auc:0.883604\n",
      "[1555]\ttrain-auc:1\teval-auc:0.883608\n",
      "[1556]\ttrain-auc:1\teval-auc:0.883596\n",
      "[1557]\ttrain-auc:1\teval-auc:0.883596\n",
      "[1558]\ttrain-auc:1\teval-auc:0.883595\n",
      "[1559]\ttrain-auc:1\teval-auc:0.883604\n",
      "[1560]\ttrain-auc:1\teval-auc:0.8836\n",
      "[1561]\ttrain-auc:1\teval-auc:0.883601\n",
      "[1562]\ttrain-auc:1\teval-auc:0.883599\n",
      "Stopping. Best iteration:\n",
      "[1512]\ttrain-auc:1\teval-auc:0.883643\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbm = xgb.train(params, dtrain, num_boost_round, evals=watchlist, early_stopping_rounds=early_stopping_rounds, verbose_eval=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gbm.predict(xgb.DMatrix(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['target'] = y_pred\n",
    "#sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test.loc[:,['ID_code','target']].to_csv('submission_lower_lr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " fpr, tpr, _ = roc_curve(X_valid[target].values, check)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    #xgb.plot_importance(gbm)\n",
    "    #plt.show()\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([-0.02, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,BatchNormalization,Dropout\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaller=MinMaxScaler()\n",
    "X=scaller.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "PartA_X, PartB_X, PartA_Y, PartB_Y = train_test_split(X, y, test_size=0.66, random_state=42)\n",
    "#split the test again to get 20% dev and 20% test\n",
    "PartB_X, PartC_X, PartB_Y, PartC_Y = train_test_split(PartB_X, PartB_Y, test_size=0.5, random_state=42)\n",
    "\n",
    "#print(y_train.shape,y_dev.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((68000, 200), (66000, 200), (66000, 200))"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PartA_X.shape,PartB_X.shape,PartC_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((68000,), (66000,), (66000,))"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PartA_Y.shape,PartB_Y.shape,PartC_Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(200, input_dim=200))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced',np.unique(PartA_Y),PartA_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(PartA_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights={0:1,1:5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"model.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='max')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping=EarlyStopping(monitor='val_acc', min_delta=0.01, patience=50, verbose=0, mode='max', baseline=None, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 68000 samples, validate on 66000 samples\n",
      "Epoch 1/150\n",
      "68000/68000 [==============================] - ETA: 32s - loss: 0.6072 - acc: 0.84 - ETA: 3s - loss: 0.6064 - acc: 0.8659 - ETA: 1s - loss: 0.5921 - acc: 0.875 - ETA: 1s - loss: 0.6017 - acc: 0.871 - ETA: 0s - loss: 0.6076 - acc: 0.870 - ETA: 0s - loss: 0.6097 - acc: 0.870 - ETA: 0s - loss: 0.6098 - acc: 0.870 - ETA: 0s - loss: 0.6112 - acc: 0.870 - ETA: 0s - loss: 0.6107 - acc: 0.870 - 1s 17us/step - loss: 0.6103 - acc: 0.8705 - val_loss: 0.3343 - val_acc: 0.8666\n",
      "Epoch 2/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5985 - acc: 0.869 - ETA: 0s - loss: 0.5927 - acc: 0.876 - ETA: 0s - loss: 0.5873 - acc: 0.878 - ETA: 0s - loss: 0.5951 - acc: 0.877 - ETA: 0s - loss: 0.6068 - acc: 0.874 - ETA: 0s - loss: 0.5999 - acc: 0.875 - ETA: 0s - loss: 0.6011 - acc: 0.875 - ETA: 0s - loss: 0.6053 - acc: 0.874 - 1s 9us/step - loss: 0.6038 - acc: 0.8735 - val_loss: 0.3401 - val_acc: 0.8610\n",
      "Epoch 3/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6400 - acc: 0.868 - ETA: 0s - loss: 0.6155 - acc: 0.873 - ETA: 0s - loss: 0.6114 - acc: 0.872 - ETA: 0s - loss: 0.6083 - acc: 0.872 - ETA: 0s - loss: 0.6051 - acc: 0.872 - ETA: 0s - loss: 0.6024 - acc: 0.875 - ETA: 0s - loss: 0.6006 - acc: 0.875 - ETA: 0s - loss: 0.6006 - acc: 0.874 - ETA: 0s - loss: 0.6015 - acc: 0.874 - 1s 9us/step - loss: 0.6022 - acc: 0.8744 - val_loss: 0.3597 - val_acc: 0.8574\n",
      "Epoch 4/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5439 - acc: 0.888 - ETA: 0s - loss: 0.6038 - acc: 0.881 - ETA: 0s - loss: 0.6053 - acc: 0.875 - ETA: 0s - loss: 0.6094 - acc: 0.872 - ETA: 0s - loss: 0.6044 - acc: 0.876 - ETA: 0s - loss: 0.6046 - acc: 0.875 - ETA: 0s - loss: 0.6038 - acc: 0.876 - ETA: 0s - loss: 0.6071 - acc: 0.875 - ETA: 0s - loss: 0.6071 - acc: 0.875 - 1s 9us/step - loss: 0.6072 - acc: 0.8753 - val_loss: 0.3635 - val_acc: 0.8519\n",
      "Epoch 5/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5909 - acc: 0.871 - ETA: 0s - loss: 0.5921 - acc: 0.873 - ETA: 0s - loss: 0.6079 - acc: 0.872 - ETA: 0s - loss: 0.6076 - acc: 0.876 - ETA: 0s - loss: 0.6077 - acc: 0.875 - ETA: 0s - loss: 0.6078 - acc: 0.876 - ETA: 0s - loss: 0.6054 - acc: 0.876 - ETA: 0s - loss: 0.6052 - acc: 0.875 - ETA: 0s - loss: 0.6042 - acc: 0.875 - 1s 9us/step - loss: 0.6039 - acc: 0.8757 - val_loss: 0.3679 - val_acc: 0.8505\n",
      "Epoch 6/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6699 - acc: 0.867 - ETA: 0s - loss: 0.6138 - acc: 0.867 - ETA: 0s - loss: 0.6152 - acc: 0.872 - ETA: 0s - loss: 0.6060 - acc: 0.874 - ETA: 0s - loss: 0.6005 - acc: 0.876 - ETA: 0s - loss: 0.6056 - acc: 0.875 - ETA: 0s - loss: 0.6039 - acc: 0.876 - ETA: 0s - loss: 0.6007 - acc: 0.877 - 1s 9us/step - loss: 0.6046 - acc: 0.8767 - val_loss: 0.3598 - val_acc: 0.8598\n",
      "Epoch 7/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6197 - acc: 0.889 - ETA: 0s - loss: 0.5979 - acc: 0.878 - ETA: 0s - loss: 0.5986 - acc: 0.878 - ETA: 0s - loss: 0.6001 - acc: 0.879 - ETA: 0s - loss: 0.6056 - acc: 0.878 - ETA: 0s - loss: 0.6032 - acc: 0.877 - ETA: 0s - loss: 0.6023 - acc: 0.877 - ETA: 0s - loss: 0.5994 - acc: 0.877 - ETA: 0s - loss: 0.5998 - acc: 0.877 - 1s 9us/step - loss: 0.5998 - acc: 0.8776 - val_loss: 0.3648 - val_acc: 0.8562\n",
      "Epoch 8/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6316 - acc: 0.881 - ETA: 0s - loss: 0.5899 - acc: 0.883 - ETA: 0s - loss: 0.5884 - acc: 0.883 - ETA: 0s - loss: 0.5840 - acc: 0.881 - ETA: 0s - loss: 0.5905 - acc: 0.880 - ETA: 0s - loss: 0.5973 - acc: 0.878 - ETA: 0s - loss: 0.5994 - acc: 0.879 - ETA: 0s - loss: 0.6006 - acc: 0.877 - ETA: 0s - loss: 0.5991 - acc: 0.878 - 1s 9us/step - loss: 0.5991 - acc: 0.8784 - val_loss: 0.3713 - val_acc: 0.8496\n",
      "Epoch 9/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.7184 - acc: 0.852 - ETA: 0s - loss: 0.5993 - acc: 0.880 - ETA: 0s - loss: 0.6040 - acc: 0.875 - ETA: 0s - loss: 0.6054 - acc: 0.875 - ETA: 0s - loss: 0.6023 - acc: 0.878 - ETA: 0s - loss: 0.5947 - acc: 0.879 - ETA: 0s - loss: 0.5944 - acc: 0.880 - ETA: 0s - loss: 0.5984 - acc: 0.879 - ETA: 0s - loss: 0.6002 - acc: 0.879 - 1s 9us/step - loss: 0.6026 - acc: 0.8791 - val_loss: 0.3530 - val_acc: 0.8608\n",
      "Epoch 10/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5804 - acc: 0.879 - ETA: 0s - loss: 0.5918 - acc: 0.879 - ETA: 0s - loss: 0.5911 - acc: 0.878 - ETA: 0s - loss: 0.5992 - acc: 0.876 - ETA: 0s - loss: 0.6020 - acc: 0.877 - ETA: 0s - loss: 0.6034 - acc: 0.876 - ETA: 0s - loss: 0.6019 - acc: 0.876 - ETA: 0s - loss: 0.6037 - acc: 0.876 - ETA: 0s - loss: 0.6016 - acc: 0.876 - 1s 10us/step - loss: 0.6019 - acc: 0.8770 - val_loss: 0.3172 - val_acc: 0.8794\n",
      "Epoch 11/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6994 - acc: 0.876 - ETA: 0s - loss: 0.6080 - acc: 0.880 - ETA: 0s - loss: 0.5901 - acc: 0.883 - ETA: 0s - loss: 0.5920 - acc: 0.881 - ETA: 0s - loss: 0.5928 - acc: 0.882 - ETA: 0s - loss: 0.5907 - acc: 0.882 - ETA: 0s - loss: 0.5938 - acc: 0.880 - ETA: 0s - loss: 0.5975 - acc: 0.880 - ETA: 0s - loss: 0.5990 - acc: 0.880 - 1s 9us/step - loss: 0.5992 - acc: 0.8794 - val_loss: 0.3548 - val_acc: 0.8592\n",
      "Epoch 12/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5375 - acc: 0.881 - ETA: 0s - loss: 0.5858 - acc: 0.885 - ETA: 0s - loss: 0.5946 - acc: 0.882 - ETA: 0s - loss: 0.6029 - acc: 0.880 - ETA: 0s - loss: 0.5969 - acc: 0.881 - ETA: 0s - loss: 0.5965 - acc: 0.881 - ETA: 0s - loss: 0.5993 - acc: 0.881 - ETA: 0s - loss: 0.6023 - acc: 0.880 - ETA: 0s - loss: 0.6040 - acc: 0.879 - 1s 9us/step - loss: 0.6028 - acc: 0.8795 - val_loss: 0.3424 - val_acc: 0.8649\n",
      "Epoch 13/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5957 - acc: 0.871 - ETA: 0s - loss: 0.6258 - acc: 0.877 - ETA: 0s - loss: 0.6035 - acc: 0.881 - ETA: 0s - loss: 0.6070 - acc: 0.877 - ETA: 0s - loss: 0.6042 - acc: 0.879 - ETA: 0s - loss: 0.6012 - acc: 0.878 - ETA: 0s - loss: 0.6016 - acc: 0.880 - ETA: 0s - loss: 0.6008 - acc: 0.879 - ETA: 0s - loss: 0.5973 - acc: 0.879 - 1s 9us/step - loss: 0.5952 - acc: 0.8803 - val_loss: 0.3096 - val_acc: 0.8807\n",
      "Epoch 14/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6067 - acc: 0.879 - ETA: 0s - loss: 0.6113 - acc: 0.883 - ETA: 0s - loss: 0.6087 - acc: 0.882 - ETA: 0s - loss: 0.6059 - acc: 0.882 - ETA: 0s - loss: 0.6010 - acc: 0.882 - ETA: 0s - loss: 0.6000 - acc: 0.882 - ETA: 0s - loss: 0.5984 - acc: 0.882 - ETA: 0s - loss: 0.5977 - acc: 0.882 - 1s 9us/step - loss: 0.5985 - acc: 0.8823 - val_loss: 0.3395 - val_acc: 0.8732\n",
      "Epoch 15/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6156 - acc: 0.899 - ETA: 0s - loss: 0.6040 - acc: 0.879 - ETA: 0s - loss: 0.5884 - acc: 0.881 - ETA: 0s - loss: 0.5991 - acc: 0.879 - ETA: 0s - loss: 0.5971 - acc: 0.880 - ETA: 0s - loss: 0.5960 - acc: 0.881 - ETA: 0s - loss: 0.5974 - acc: 0.882 - ETA: 0s - loss: 0.5993 - acc: 0.882 - ETA: 0s - loss: 0.6005 - acc: 0.881 - 1s 9us/step - loss: 0.6002 - acc: 0.8813 - val_loss: 0.3479 - val_acc: 0.8683\n",
      "Epoch 16/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6354 - acc: 0.876 - ETA: 0s - loss: 0.5943 - acc: 0.880 - ETA: 0s - loss: 0.5998 - acc: 0.878 - ETA: 0s - loss: 0.5982 - acc: 0.878 - ETA: 0s - loss: 0.5958 - acc: 0.878 - ETA: 0s - loss: 0.5976 - acc: 0.879 - ETA: 0s - loss: 0.5970 - acc: 0.881 - ETA: 0s - loss: 0.5989 - acc: 0.880 - ETA: 0s - loss: 0.6006 - acc: 0.879 - 1s 9us/step - loss: 0.6018 - acc: 0.8794 - val_loss: 0.3574 - val_acc: 0.8647\n",
      "Epoch 17/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5615 - acc: 0.884 - ETA: 0s - loss: 0.6018 - acc: 0.878 - ETA: 0s - loss: 0.5990 - acc: 0.881 - ETA: 0s - loss: 0.5919 - acc: 0.882 - ETA: 0s - loss: 0.5887 - acc: 0.882 - ETA: 0s - loss: 0.5895 - acc: 0.882 - ETA: 0s - loss: 0.5922 - acc: 0.881 - ETA: 0s - loss: 0.5986 - acc: 0.881 - ETA: 0s - loss: 0.5994 - acc: 0.880 - 1s 9us/step - loss: 0.6004 - acc: 0.8800 - val_loss: 0.3529 - val_acc: 0.8601\n",
      "Epoch 18/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5964 - acc: 0.855 - ETA: 0s - loss: 0.5861 - acc: 0.880 - ETA: 0s - loss: 0.5750 - acc: 0.882 - ETA: 0s - loss: 0.5843 - acc: 0.882 - ETA: 0s - loss: 0.5891 - acc: 0.881 - ETA: 0s - loss: 0.5921 - acc: 0.881 - ETA: 0s - loss: 0.5930 - acc: 0.881 - ETA: 0s - loss: 0.5962 - acc: 0.881 - ETA: 0s - loss: 0.5982 - acc: 0.880 - 1s 9us/step - loss: 0.6001 - acc: 0.8809 - val_loss: 0.3487 - val_acc: 0.8705\n",
      "Epoch 19/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5466 - acc: 0.898 - ETA: 0s - loss: 0.6109 - acc: 0.881 - ETA: 0s - loss: 0.5997 - acc: 0.879 - ETA: 0s - loss: 0.5909 - acc: 0.885 - ETA: 0s - loss: 0.5969 - acc: 0.881 - ETA: 0s - loss: 0.5998 - acc: 0.881 - ETA: 0s - loss: 0.6001 - acc: 0.880 - ETA: 0s - loss: 0.5987 - acc: 0.881 - 1s 9us/step - loss: 0.5992 - acc: 0.8814 - val_loss: 0.3477 - val_acc: 0.8736\n",
      "Epoch 20/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6989 - acc: 0.863 - ETA: 0s - loss: 0.6134 - acc: 0.882 - ETA: 0s - loss: 0.6052 - acc: 0.882 - ETA: 0s - loss: 0.5985 - acc: 0.883 - ETA: 0s - loss: 0.5961 - acc: 0.883 - ETA: 0s - loss: 0.5993 - acc: 0.881 - ETA: 0s - loss: 0.5984 - acc: 0.882 - ETA: 0s - loss: 0.5961 - acc: 0.882 - ETA: 0s - loss: 0.5975 - acc: 0.882 - 1s 9us/step - loss: 0.5965 - acc: 0.8819 - val_loss: 0.3727 - val_acc: 0.8501\n",
      "Epoch 21/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5795 - acc: 0.872 - ETA: 0s - loss: 0.5743 - acc: 0.885 - ETA: 0s - loss: 0.5886 - acc: 0.882 - ETA: 0s - loss: 0.5959 - acc: 0.881 - ETA: 0s - loss: 0.5960 - acc: 0.881 - ETA: 0s - loss: 0.5970 - acc: 0.881 - ETA: 0s - loss: 0.5993 - acc: 0.881 - ETA: 0s - loss: 0.6021 - acc: 0.880 - ETA: 0s - loss: 0.5996 - acc: 0.881 - 1s 9us/step - loss: 0.5986 - acc: 0.8816 - val_loss: 0.3354 - val_acc: 0.8741\n",
      "Epoch 22/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5346 - acc: 0.883 - ETA: 0s - loss: 0.5710 - acc: 0.886 - ETA: 0s - loss: 0.5879 - acc: 0.885 - ETA: 0s - loss: 0.5923 - acc: 0.885 - ETA: 0s - loss: 0.5960 - acc: 0.883 - ETA: 0s - loss: 0.5987 - acc: 0.881 - ETA: 0s - loss: 0.6024 - acc: 0.881 - ETA: 0s - loss: 0.5997 - acc: 0.881 - 1s 8us/step - loss: 0.6013 - acc: 0.8815 - val_loss: 0.3695 - val_acc: 0.8624\n",
      "Epoch 23/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6605 - acc: 0.862 - ETA: 0s - loss: 0.6071 - acc: 0.878 - ETA: 0s - loss: 0.5917 - acc: 0.878 - ETA: 0s - loss: 0.5927 - acc: 0.880 - ETA: 0s - loss: 0.5927 - acc: 0.882 - ETA: 0s - loss: 0.5958 - acc: 0.882 - ETA: 0s - loss: 0.5981 - acc: 0.881 - ETA: 0s - loss: 0.5960 - acc: 0.881 - 1s 8us/step - loss: 0.5950 - acc: 0.8816 - val_loss: 0.3349 - val_acc: 0.8730\n",
      "Epoch 24/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6366 - acc: 0.882 - ETA: 0s - loss: 0.5940 - acc: 0.890 - ETA: 0s - loss: 0.5961 - acc: 0.886 - ETA: 0s - loss: 0.5910 - acc: 0.884 - ETA: 0s - loss: 0.5936 - acc: 0.882 - ETA: 0s - loss: 0.5887 - acc: 0.884 - ETA: 0s - loss: 0.5938 - acc: 0.882 - ETA: 0s - loss: 0.5960 - acc: 0.882 - 1s 9us/step - loss: 0.5949 - acc: 0.8826 - val_loss: 0.3696 - val_acc: 0.8510\n",
      "Epoch 25/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.7002 - acc: 0.844 - ETA: 0s - loss: 0.6162 - acc: 0.877 - ETA: 0s - loss: 0.6079 - acc: 0.876 - ETA: 0s - loss: 0.6067 - acc: 0.878 - ETA: 0s - loss: 0.6010 - acc: 0.880 - ETA: 0s - loss: 0.5996 - acc: 0.881 - ETA: 0s - loss: 0.5972 - acc: 0.881 - ETA: 0s - loss: 0.6001 - acc: 0.881 - 1s 8us/step - loss: 0.5988 - acc: 0.8815 - val_loss: 0.3401 - val_acc: 0.8714\n",
      "Epoch 26/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6456 - acc: 0.869 - ETA: 0s - loss: 0.6156 - acc: 0.879 - ETA: 0s - loss: 0.6114 - acc: 0.880 - ETA: 0s - loss: 0.5984 - acc: 0.881 - ETA: 0s - loss: 0.5946 - acc: 0.882 - ETA: 0s - loss: 0.5978 - acc: 0.882 - ETA: 0s - loss: 0.5990 - acc: 0.882 - ETA: 0s - loss: 0.5983 - acc: 0.883 - 1s 8us/step - loss: 0.6000 - acc: 0.8825 - val_loss: 0.3411 - val_acc: 0.8688\n",
      "Epoch 27/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6157 - acc: 0.871 - ETA: 0s - loss: 0.5882 - acc: 0.885 - ETA: 0s - loss: 0.5866 - acc: 0.883 - ETA: 0s - loss: 0.5906 - acc: 0.883 - ETA: 0s - loss: 0.5920 - acc: 0.883 - ETA: 0s - loss: 0.5970 - acc: 0.881 - ETA: 0s - loss: 0.6005 - acc: 0.881 - ETA: 0s - loss: 0.6015 - acc: 0.880 - 1s 8us/step - loss: 0.6030 - acc: 0.8795 - val_loss: 0.3454 - val_acc: 0.8780\n",
      "Epoch 28/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6539 - acc: 0.899 - ETA: 0s - loss: 0.5970 - acc: 0.888 - ETA: 0s - loss: 0.6011 - acc: 0.885 - ETA: 0s - loss: 0.6005 - acc: 0.885 - ETA: 0s - loss: 0.5975 - acc: 0.885 - ETA: 0s - loss: 0.5985 - acc: 0.884 - ETA: 0s - loss: 0.6009 - acc: 0.884 - ETA: 0s - loss: 0.5989 - acc: 0.884 - 1s 8us/step - loss: 0.5986 - acc: 0.8845 - val_loss: 0.3377 - val_acc: 0.8726\n",
      "Epoch 29/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5967 - acc: 0.887 - ETA: 0s - loss: 0.6320 - acc: 0.876 - ETA: 0s - loss: 0.6144 - acc: 0.881 - ETA: 0s - loss: 0.6082 - acc: 0.880 - ETA: 0s - loss: 0.5992 - acc: 0.882 - ETA: 0s - loss: 0.5995 - acc: 0.882 - ETA: 0s - loss: 0.6015 - acc: 0.881 - ETA: 0s - loss: 0.5996 - acc: 0.882 - 1s 9us/step - loss: 0.6007 - acc: 0.8817 - val_loss: 0.3357 - val_acc: 0.8738\n",
      "Epoch 30/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6077 - acc: 0.892 - ETA: 0s - loss: 0.6145 - acc: 0.881 - ETA: 0s - loss: 0.5994 - acc: 0.885 - ETA: 0s - loss: 0.5932 - acc: 0.886 - ETA: 0s - loss: 0.5948 - acc: 0.886 - ETA: 0s - loss: 0.5972 - acc: 0.885 - ETA: 0s - loss: 0.5962 - acc: 0.884 - ETA: 0s - loss: 0.5955 - acc: 0.883 - 1s 8us/step - loss: 0.5966 - acc: 0.8838 - val_loss: 0.3507 - val_acc: 0.8603\n",
      "Epoch 31/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6143 - acc: 0.889 - ETA: 0s - loss: 0.5861 - acc: 0.882 - ETA: 0s - loss: 0.5807 - acc: 0.885 - ETA: 0s - loss: 0.5858 - acc: 0.885 - ETA: 0s - loss: 0.5972 - acc: 0.882 - ETA: 0s - loss: 0.5996 - acc: 0.881 - ETA: 0s - loss: 0.5964 - acc: 0.881 - ETA: 0s - loss: 0.6008 - acc: 0.881 - 1s 8us/step - loss: 0.6019 - acc: 0.8812 - val_loss: 0.3356 - val_acc: 0.8727\n",
      "Epoch 32/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5506 - acc: 0.891 - ETA: 0s - loss: 0.5583 - acc: 0.889 - ETA: 0s - loss: 0.5730 - acc: 0.889 - ETA: 0s - loss: 0.5886 - acc: 0.885 - ETA: 0s - loss: 0.5942 - acc: 0.884 - ETA: 0s - loss: 0.5991 - acc: 0.882 - ETA: 0s - loss: 0.5978 - acc: 0.883 - ETA: 0s - loss: 0.5939 - acc: 0.884 - 1s 8us/step - loss: 0.5948 - acc: 0.8833 - val_loss: 0.3334 - val_acc: 0.8738\n",
      "Epoch 33/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5500 - acc: 0.892 - ETA: 0s - loss: 0.5619 - acc: 0.897 - ETA: 0s - loss: 0.5883 - acc: 0.884 - ETA: 0s - loss: 0.5931 - acc: 0.885 - ETA: 0s - loss: 0.5931 - acc: 0.883 - ETA: 0s - loss: 0.5932 - acc: 0.885 - ETA: 0s - loss: 0.5971 - acc: 0.884 - ETA: 0s - loss: 0.6029 - acc: 0.884 - 1s 8us/step - loss: 0.6024 - acc: 0.8832 - val_loss: 0.3318 - val_acc: 0.8737\n",
      "Epoch 34/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5943 - acc: 0.887 - ETA: 0s - loss: 0.5823 - acc: 0.886 - ETA: 0s - loss: 0.5950 - acc: 0.884 - ETA: 0s - loss: 0.5969 - acc: 0.883 - ETA: 0s - loss: 0.5977 - acc: 0.882 - ETA: 0s - loss: 0.5911 - acc: 0.884 - ETA: 0s - loss: 0.5986 - acc: 0.883 - ETA: 0s - loss: 0.5979 - acc: 0.883 - 1s 8us/step - loss: 0.5983 - acc: 0.8837 - val_loss: 0.3314 - val_acc: 0.8695\n",
      "Epoch 35/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5903 - acc: 0.879 - ETA: 0s - loss: 0.5871 - acc: 0.885 - ETA: 0s - loss: 0.5944 - acc: 0.887 - ETA: 0s - loss: 0.5979 - acc: 0.884 - ETA: 0s - loss: 0.5973 - acc: 0.885 - ETA: 0s - loss: 0.5899 - acc: 0.886 - ETA: 0s - loss: 0.5947 - acc: 0.884 - ETA: 0s - loss: 0.5979 - acc: 0.884 - 1s 8us/step - loss: 0.5973 - acc: 0.8845 - val_loss: 0.3454 - val_acc: 0.8653\n",
      "Epoch 36/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6315 - acc: 0.861 - ETA: 0s - loss: 0.5846 - acc: 0.882 - ETA: 0s - loss: 0.5836 - acc: 0.883 - ETA: 0s - loss: 0.5905 - acc: 0.882 - ETA: 0s - loss: 0.5932 - acc: 0.883 - ETA: 0s - loss: 0.5951 - acc: 0.882 - ETA: 0s - loss: 0.5925 - acc: 0.884 - ETA: 0s - loss: 0.5964 - acc: 0.883 - ETA: 0s - loss: 0.5961 - acc: 0.883 - 1s 9us/step - loss: 0.5964 - acc: 0.8836 - val_loss: 0.3210 - val_acc: 0.8863\n",
      "Epoch 37/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5311 - acc: 0.905 - ETA: 0s - loss: 0.5786 - acc: 0.886 - ETA: 0s - loss: 0.5812 - acc: 0.881 - ETA: 0s - loss: 0.5898 - acc: 0.885 - ETA: 0s - loss: 0.5997 - acc: 0.882 - ETA: 0s - loss: 0.5999 - acc: 0.883 - ETA: 0s - loss: 0.5982 - acc: 0.884 - ETA: 0s - loss: 0.5981 - acc: 0.883 - 1s 9us/step - loss: 0.5982 - acc: 0.8839 - val_loss: 0.3406 - val_acc: 0.8685\n",
      "Epoch 38/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5687 - acc: 0.885 - ETA: 0s - loss: 0.6021 - acc: 0.876 - ETA: 0s - loss: 0.6043 - acc: 0.881 - ETA: 0s - loss: 0.5961 - acc: 0.882 - ETA: 0s - loss: 0.5949 - acc: 0.881 - ETA: 0s - loss: 0.5957 - acc: 0.881 - ETA: 0s - loss: 0.5938 - acc: 0.881 - ETA: 0s - loss: 0.5943 - acc: 0.882 - ETA: 0s - loss: 0.5937 - acc: 0.883 - 1s 9us/step - loss: 0.5938 - acc: 0.8827 - val_loss: 0.3473 - val_acc: 0.8670\n",
      "Epoch 39/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6741 - acc: 0.899 - ETA: 0s - loss: 0.6178 - acc: 0.883 - ETA: 0s - loss: 0.6139 - acc: 0.882 - ETA: 0s - loss: 0.6158 - acc: 0.879 - ETA: 0s - loss: 0.6123 - acc: 0.882 - ETA: 0s - loss: 0.6071 - acc: 0.881 - ETA: 0s - loss: 0.6016 - acc: 0.882 - ETA: 0s - loss: 0.6031 - acc: 0.882 - 1s 9us/step - loss: 0.5995 - acc: 0.8839 - val_loss: 0.3298 - val_acc: 0.8772\n",
      "Epoch 40/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5150 - acc: 0.910 - ETA: 0s - loss: 0.6026 - acc: 0.882 - ETA: 0s - loss: 0.6002 - acc: 0.882 - ETA: 0s - loss: 0.6000 - acc: 0.884 - ETA: 0s - loss: 0.5992 - acc: 0.885 - ETA: 0s - loss: 0.6004 - acc: 0.884 - ETA: 0s - loss: 0.6019 - acc: 0.883 - ETA: 0s - loss: 0.5978 - acc: 0.884 - ETA: 0s - loss: 0.5994 - acc: 0.882 - 1s 9us/step - loss: 0.5984 - acc: 0.8829 - val_loss: 0.3289 - val_acc: 0.8787\n",
      "Epoch 41/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5695 - acc: 0.892 - ETA: 0s - loss: 0.6066 - acc: 0.882 - ETA: 0s - loss: 0.5817 - acc: 0.885 - ETA: 0s - loss: 0.5960 - acc: 0.882 - ETA: 0s - loss: 0.5958 - acc: 0.884 - ETA: 0s - loss: 0.5963 - acc: 0.883 - ETA: 0s - loss: 0.5988 - acc: 0.883 - ETA: 0s - loss: 0.6012 - acc: 0.882 - 1s 8us/step - loss: 0.5997 - acc: 0.8827 - val_loss: 0.3278 - val_acc: 0.8800\n",
      "Epoch 42/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6009 - acc: 0.889 - ETA: 0s - loss: 0.5964 - acc: 0.886 - ETA: 0s - loss: 0.5778 - acc: 0.888 - ETA: 0s - loss: 0.5827 - acc: 0.888 - ETA: 0s - loss: 0.5914 - acc: 0.886 - ETA: 0s - loss: 0.5915 - acc: 0.886 - ETA: 0s - loss: 0.5936 - acc: 0.885 - ETA: 0s - loss: 0.5951 - acc: 0.884 - 1s 8us/step - loss: 0.5977 - acc: 0.8841 - val_loss: 0.3520 - val_acc: 0.8609\n",
      "Epoch 43/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5475 - acc: 0.880 - ETA: 0s - loss: 0.5629 - acc: 0.891 - ETA: 0s - loss: 0.5854 - acc: 0.882 - ETA: 0s - loss: 0.5933 - acc: 0.882 - ETA: 0s - loss: 0.5911 - acc: 0.882 - ETA: 0s - loss: 0.5934 - acc: 0.882 - ETA: 0s - loss: 0.5951 - acc: 0.883 - ETA: 0s - loss: 0.5987 - acc: 0.881 - 1s 9us/step - loss: 0.5969 - acc: 0.8821 - val_loss: 0.3046 - val_acc: 0.8878\n",
      "Epoch 44/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6347 - acc: 0.882 - ETA: 0s - loss: 0.5868 - acc: 0.882 - ETA: 0s - loss: 0.5956 - acc: 0.881 - ETA: 0s - loss: 0.5930 - acc: 0.882 - ETA: 0s - loss: 0.5876 - acc: 0.884 - ETA: 0s - loss: 0.5926 - acc: 0.883 - ETA: 0s - loss: 0.5942 - acc: 0.884 - ETA: 0s - loss: 0.5931 - acc: 0.884 - 1s 8us/step - loss: 0.5962 - acc: 0.8839 - val_loss: 0.3540 - val_acc: 0.8725\n",
      "Epoch 45/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6594 - acc: 0.869 - ETA: 0s - loss: 0.6209 - acc: 0.882 - ETA: 0s - loss: 0.6004 - acc: 0.883 - ETA: 0s - loss: 0.6015 - acc: 0.881 - ETA: 0s - loss: 0.5977 - acc: 0.881 - ETA: 0s - loss: 0.5965 - acc: 0.883 - ETA: 0s - loss: 0.5973 - acc: 0.883 - ETA: 0s - loss: 0.5972 - acc: 0.883 - 1s 8us/step - loss: 0.5949 - acc: 0.8840 - val_loss: 0.3520 - val_acc: 0.8624\n",
      "Epoch 46/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5944 - acc: 0.876 - ETA: 0s - loss: 0.6013 - acc: 0.881 - ETA: 0s - loss: 0.5909 - acc: 0.884 - ETA: 0s - loss: 0.5872 - acc: 0.884 - ETA: 0s - loss: 0.5894 - acc: 0.883 - ETA: 0s - loss: 0.5933 - acc: 0.882 - ETA: 0s - loss: 0.5950 - acc: 0.882 - ETA: 0s - loss: 0.5966 - acc: 0.882 - 1s 8us/step - loss: 0.5971 - acc: 0.8820 - val_loss: 0.3409 - val_acc: 0.8709\n",
      "Epoch 47/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6147 - acc: 0.884 - ETA: 0s - loss: 0.5884 - acc: 0.886 - ETA: 0s - loss: 0.5808 - acc: 0.885 - ETA: 0s - loss: 0.6003 - acc: 0.881 - ETA: 0s - loss: 0.6015 - acc: 0.880 - ETA: 0s - loss: 0.5975 - acc: 0.882 - ETA: 0s - loss: 0.6033 - acc: 0.881 - ETA: 0s - loss: 0.6038 - acc: 0.880 - ETA: 0s - loss: 0.6008 - acc: 0.882 - 1s 9us/step - loss: 0.5983 - acc: 0.8828 - val_loss: 0.3588 - val_acc: 0.8620\n",
      "Epoch 48/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6065 - acc: 0.879 - ETA: 0s - loss: 0.5958 - acc: 0.881 - ETA: 0s - loss: 0.6048 - acc: 0.880 - ETA: 0s - loss: 0.6015 - acc: 0.880 - ETA: 0s - loss: 0.6072 - acc: 0.881 - ETA: 0s - loss: 0.6033 - acc: 0.882 - ETA: 0s - loss: 0.5991 - acc: 0.883 - ETA: 0s - loss: 0.5961 - acc: 0.883 - 1s 9us/step - loss: 0.5967 - acc: 0.8840 - val_loss: 0.3712 - val_acc: 0.8645\n",
      "Epoch 49/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5838 - acc: 0.885 - ETA: 0s - loss: 0.5867 - acc: 0.887 - ETA: 0s - loss: 0.5921 - acc: 0.887 - ETA: 0s - loss: 0.5957 - acc: 0.887 - ETA: 0s - loss: 0.5944 - acc: 0.886 - ETA: 0s - loss: 0.5985 - acc: 0.884 - ETA: 0s - loss: 0.5985 - acc: 0.884 - ETA: 0s - loss: 0.5987 - acc: 0.884 - 1s 9us/step - loss: 0.5980 - acc: 0.8844 - val_loss: 0.3277 - val_acc: 0.8741\n",
      "Epoch 50/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6144 - acc: 0.884 - ETA: 0s - loss: 0.6065 - acc: 0.878 - ETA: 0s - loss: 0.6016 - acc: 0.881 - ETA: 0s - loss: 0.6031 - acc: 0.881 - ETA: 0s - loss: 0.5942 - acc: 0.884 - ETA: 0s - loss: 0.5961 - acc: 0.883 - ETA: 0s - loss: 0.5949 - acc: 0.883 - ETA: 0s - loss: 0.5978 - acc: 0.882 - 1s 9us/step - loss: 0.5986 - acc: 0.8831 - val_loss: 0.3379 - val_acc: 0.8851\n",
      "Epoch 51/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5681 - acc: 0.898 - ETA: 0s - loss: 0.5914 - acc: 0.889 - ETA: 0s - loss: 0.6159 - acc: 0.883 - ETA: 0s - loss: 0.6027 - acc: 0.886 - ETA: 0s - loss: 0.6034 - acc: 0.884 - ETA: 0s - loss: 0.6014 - acc: 0.886 - ETA: 0s - loss: 0.6002 - acc: 0.884 - ETA: 0s - loss: 0.6004 - acc: 0.884 - 1s 8us/step - loss: 0.5973 - acc: 0.8852 - val_loss: 0.3254 - val_acc: 0.8744\n",
      "Epoch 52/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6525 - acc: 0.881 - ETA: 0s - loss: 0.6170 - acc: 0.879 - ETA: 0s - loss: 0.6103 - acc: 0.881 - ETA: 0s - loss: 0.6029 - acc: 0.883 - ETA: 0s - loss: 0.5990 - acc: 0.883 - ETA: 0s - loss: 0.5983 - acc: 0.885 - ETA: 0s - loss: 0.5997 - acc: 0.882 - ETA: 0s - loss: 0.6011 - acc: 0.883 - ETA: 0s - loss: 0.6027 - acc: 0.882 - 1s 9us/step - loss: 0.6020 - acc: 0.8830 - val_loss: 0.3380 - val_acc: 0.8722\n",
      "Epoch 53/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5992 - acc: 0.890 - ETA: 0s - loss: 0.5924 - acc: 0.886 - ETA: 0s - loss: 0.5947 - acc: 0.883 - ETA: 0s - loss: 0.5870 - acc: 0.884 - ETA: 0s - loss: 0.5880 - acc: 0.886 - ETA: 0s - loss: 0.5928 - acc: 0.884 - ETA: 0s - loss: 0.5948 - acc: 0.884 - ETA: 0s - loss: 0.5947 - acc: 0.884 - 1s 9us/step - loss: 0.5960 - acc: 0.8844 - val_loss: 0.3399 - val_acc: 0.8676\n",
      "Epoch 54/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5074 - acc: 0.903 - ETA: 0s - loss: 0.5725 - acc: 0.893 - ETA: 0s - loss: 0.5926 - acc: 0.886 - ETA: 0s - loss: 0.5931 - acc: 0.886 - ETA: 0s - loss: 0.5931 - acc: 0.885 - ETA: 0s - loss: 0.5922 - acc: 0.885 - ETA: 0s - loss: 0.5959 - acc: 0.884 - ETA: 0s - loss: 0.5984 - acc: 0.884 - 1s 9us/step - loss: 0.5968 - acc: 0.8845 - val_loss: 0.3351 - val_acc: 0.8709\n",
      "Epoch 55/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5917 - acc: 0.887 - ETA: 0s - loss: 0.5950 - acc: 0.880 - ETA: 0s - loss: 0.5994 - acc: 0.882 - ETA: 0s - loss: 0.5923 - acc: 0.884 - ETA: 0s - loss: 0.5879 - acc: 0.883 - ETA: 0s - loss: 0.5881 - acc: 0.884 - ETA: 0s - loss: 0.5882 - acc: 0.884 - ETA: 0s - loss: 0.5919 - acc: 0.883 - 1s 9us/step - loss: 0.5947 - acc: 0.8830 - val_loss: 0.3514 - val_acc: 0.8643\n",
      "Epoch 56/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5894 - acc: 0.883 - ETA: 0s - loss: 0.5832 - acc: 0.888 - ETA: 0s - loss: 0.5939 - acc: 0.882 - ETA: 0s - loss: 0.5930 - acc: 0.882 - ETA: 0s - loss: 0.5931 - acc: 0.881 - ETA: 0s - loss: 0.5945 - acc: 0.883 - ETA: 0s - loss: 0.5960 - acc: 0.883 - ETA: 0s - loss: 0.5977 - acc: 0.883 - 1s 9us/step - loss: 0.5978 - acc: 0.8837 - val_loss: 0.3234 - val_acc: 0.8735\n",
      "Epoch 57/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6538 - acc: 0.885 - ETA: 0s - loss: 0.5903 - acc: 0.878 - ETA: 0s - loss: 0.5909 - acc: 0.883 - ETA: 0s - loss: 0.5930 - acc: 0.883 - ETA: 0s - loss: 0.5939 - acc: 0.882 - ETA: 0s - loss: 0.5904 - acc: 0.883 - ETA: 0s - loss: 0.5943 - acc: 0.882 - ETA: 0s - loss: 0.5943 - acc: 0.884 - 1s 9us/step - loss: 0.5950 - acc: 0.8832 - val_loss: 0.3473 - val_acc: 0.8691\n",
      "Epoch 58/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6407 - acc: 0.887 - ETA: 0s - loss: 0.5945 - acc: 0.888 - ETA: 0s - loss: 0.6061 - acc: 0.882 - ETA: 0s - loss: 0.6080 - acc: 0.883 - ETA: 0s - loss: 0.6026 - acc: 0.881 - ETA: 0s - loss: 0.5992 - acc: 0.883 - ETA: 0s - loss: 0.5974 - acc: 0.883 - ETA: 0s - loss: 0.5995 - acc: 0.883 - 1s 9us/step - loss: 0.5970 - acc: 0.8835 - val_loss: 0.3195 - val_acc: 0.8830\n",
      "Epoch 59/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5358 - acc: 0.904 - ETA: 0s - loss: 0.5984 - acc: 0.885 - ETA: 0s - loss: 0.5868 - acc: 0.887 - ETA: 0s - loss: 0.5913 - acc: 0.885 - ETA: 0s - loss: 0.6028 - acc: 0.882 - ETA: 0s - loss: 0.6042 - acc: 0.881 - ETA: 0s - loss: 0.6008 - acc: 0.882 - ETA: 0s - loss: 0.6005 - acc: 0.882 - 1s 8us/step - loss: 0.5996 - acc: 0.8826 - val_loss: 0.3306 - val_acc: 0.8739\n",
      "Epoch 60/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6069 - acc: 0.886 - ETA: 0s - loss: 0.5997 - acc: 0.883 - ETA: 0s - loss: 0.6110 - acc: 0.883 - ETA: 0s - loss: 0.5985 - acc: 0.884 - ETA: 0s - loss: 0.6007 - acc: 0.884 - ETA: 0s - loss: 0.6026 - acc: 0.882 - ETA: 0s - loss: 0.6001 - acc: 0.882 - ETA: 0s - loss: 0.6003 - acc: 0.882 - 1s 8us/step - loss: 0.5988 - acc: 0.8831 - val_loss: 0.3260 - val_acc: 0.8751\n",
      "Epoch 61/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5433 - acc: 0.884 - ETA: 0s - loss: 0.5831 - acc: 0.890 - ETA: 0s - loss: 0.5874 - acc: 0.889 - ETA: 0s - loss: 0.5890 - acc: 0.888 - ETA: 0s - loss: 0.5925 - acc: 0.886 - ETA: 0s - loss: 0.5951 - acc: 0.885 - ETA: 0s - loss: 0.5941 - acc: 0.885 - ETA: 0s - loss: 0.5934 - acc: 0.885 - 1s 8us/step - loss: 0.5931 - acc: 0.8856 - val_loss: 0.3619 - val_acc: 0.8630\n",
      "Epoch 62/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5681 - acc: 0.885 - ETA: 0s - loss: 0.6081 - acc: 0.884 - ETA: 0s - loss: 0.5955 - acc: 0.884 - ETA: 0s - loss: 0.6074 - acc: 0.883 - ETA: 0s - loss: 0.5982 - acc: 0.883 - ETA: 0s - loss: 0.5943 - acc: 0.884 - ETA: 0s - loss: 0.6004 - acc: 0.883 - ETA: 0s - loss: 0.5974 - acc: 0.884 - 1s 8us/step - loss: 0.5968 - acc: 0.8844 - val_loss: 0.3451 - val_acc: 0.8638\n",
      "Epoch 63/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5227 - acc: 0.881 - ETA: 0s - loss: 0.6003 - acc: 0.879 - ETA: 0s - loss: 0.6030 - acc: 0.884 - ETA: 0s - loss: 0.5955 - acc: 0.884 - ETA: 0s - loss: 0.5913 - acc: 0.885 - ETA: 0s - loss: 0.5933 - acc: 0.884 - ETA: 0s - loss: 0.5964 - acc: 0.883 - ETA: 0s - loss: 0.5945 - acc: 0.883 - 1s 8us/step - loss: 0.5954 - acc: 0.8837 - val_loss: 0.3284 - val_acc: 0.8797\n",
      "Epoch 64/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5845 - acc: 0.890 - ETA: 0s - loss: 0.5984 - acc: 0.885 - ETA: 0s - loss: 0.6070 - acc: 0.885 - ETA: 0s - loss: 0.6010 - acc: 0.884 - ETA: 0s - loss: 0.5984 - acc: 0.884 - ETA: 0s - loss: 0.5988 - acc: 0.884 - ETA: 0s - loss: 0.5979 - acc: 0.884 - ETA: 0s - loss: 0.5968 - acc: 0.884 - 1s 8us/step - loss: 0.5983 - acc: 0.8836 - val_loss: 0.3579 - val_acc: 0.8595\n",
      "Epoch 65/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6150 - acc: 0.871 - ETA: 0s - loss: 0.6005 - acc: 0.880 - ETA: 0s - loss: 0.6017 - acc: 0.881 - ETA: 0s - loss: 0.6062 - acc: 0.880 - ETA: 0s - loss: 0.6022 - acc: 0.881 - ETA: 0s - loss: 0.6022 - acc: 0.881 - ETA: 0s - loss: 0.6027 - acc: 0.881 - ETA: 0s - loss: 0.5993 - acc: 0.882 - 1s 8us/step - loss: 0.5983 - acc: 0.8823 - val_loss: 0.3214 - val_acc: 0.8781\n",
      "Epoch 66/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5919 - acc: 0.891 - ETA: 0s - loss: 0.5673 - acc: 0.887 - ETA: 0s - loss: 0.5798 - acc: 0.887 - ETA: 0s - loss: 0.5894 - acc: 0.885 - ETA: 0s - loss: 0.5889 - acc: 0.886 - ETA: 0s - loss: 0.5919 - acc: 0.885 - ETA: 0s - loss: 0.5950 - acc: 0.885 - ETA: 0s - loss: 0.5946 - acc: 0.886 - 1s 9us/step - loss: 0.5976 - acc: 0.8857 - val_loss: 0.3242 - val_acc: 0.8785\n",
      "Epoch 67/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6098 - acc: 0.897 - ETA: 0s - loss: 0.6111 - acc: 0.885 - ETA: 0s - loss: 0.5977 - acc: 0.888 - ETA: 0s - loss: 0.5893 - acc: 0.888 - ETA: 0s - loss: 0.5836 - acc: 0.888 - ETA: 0s - loss: 0.5832 - acc: 0.887 - ETA: 0s - loss: 0.5890 - acc: 0.887 - ETA: 0s - loss: 0.5928 - acc: 0.886 - 1s 9us/step - loss: 0.5943 - acc: 0.8851 - val_loss: 0.3566 - val_acc: 0.8625\n",
      "Epoch 68/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5699 - acc: 0.871 - ETA: 0s - loss: 0.6034 - acc: 0.883 - ETA: 0s - loss: 0.5864 - acc: 0.882 - ETA: 0s - loss: 0.5872 - acc: 0.882 - ETA: 0s - loss: 0.5939 - acc: 0.883 - ETA: 0s - loss: 0.5982 - acc: 0.883 - ETA: 0s - loss: 0.5951 - acc: 0.883 - ETA: 0s - loss: 0.5972 - acc: 0.883 - 1s 9us/step - loss: 0.5974 - acc: 0.8834 - val_loss: 0.3356 - val_acc: 0.8776\n",
      "Epoch 69/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6010 - acc: 0.875 - ETA: 0s - loss: 0.6042 - acc: 0.890 - ETA: 0s - loss: 0.6060 - acc: 0.883 - ETA: 0s - loss: 0.5985 - acc: 0.887 - ETA: 0s - loss: 0.5982 - acc: 0.884 - ETA: 0s - loss: 0.5987 - acc: 0.885 - ETA: 0s - loss: 0.5959 - acc: 0.885 - ETA: 0s - loss: 0.5950 - acc: 0.884 - ETA: 0s - loss: 0.5964 - acc: 0.884 - 1s 9us/step - loss: 0.5965 - acc: 0.8845 - val_loss: 0.3489 - val_acc: 0.8671\n",
      "Epoch 70/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6385 - acc: 0.872 - ETA: 0s - loss: 0.6029 - acc: 0.882 - ETA: 0s - loss: 0.5982 - acc: 0.884 - ETA: 0s - loss: 0.5977 - acc: 0.881 - ETA: 0s - loss: 0.6071 - acc: 0.879 - ETA: 0s - loss: 0.6005 - acc: 0.881 - ETA: 0s - loss: 0.5983 - acc: 0.883 - ETA: 0s - loss: 0.5995 - acc: 0.882 - 1s 8us/step - loss: 0.5966 - acc: 0.8837 - val_loss: 0.3295 - val_acc: 0.8760\n",
      "Epoch 71/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5189 - acc: 0.903 - ETA: 0s - loss: 0.5901 - acc: 0.891 - ETA: 0s - loss: 0.6038 - acc: 0.883 - ETA: 0s - loss: 0.6045 - acc: 0.881 - ETA: 0s - loss: 0.6030 - acc: 0.883 - ETA: 0s - loss: 0.6018 - acc: 0.882 - ETA: 0s - loss: 0.5957 - acc: 0.883 - ETA: 0s - loss: 0.5975 - acc: 0.883 - 1s 8us/step - loss: 0.5965 - acc: 0.8839 - val_loss: 0.3295 - val_acc: 0.8791\n",
      "Epoch 72/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5868 - acc: 0.879 - ETA: 0s - loss: 0.5951 - acc: 0.882 - ETA: 0s - loss: 0.5933 - acc: 0.882 - ETA: 0s - loss: 0.5962 - acc: 0.882 - ETA: 0s - loss: 0.5976 - acc: 0.883 - ETA: 0s - loss: 0.5926 - acc: 0.884 - ETA: 0s - loss: 0.5965 - acc: 0.883 - ETA: 0s - loss: 0.5933 - acc: 0.883 - 1s 8us/step - loss: 0.5939 - acc: 0.8832 - val_loss: 0.3204 - val_acc: 0.8778\n",
      "Epoch 73/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5889 - acc: 0.896 - ETA: 0s - loss: 0.5763 - acc: 0.890 - ETA: 0s - loss: 0.5824 - acc: 0.889 - ETA: 0s - loss: 0.5910 - acc: 0.887 - ETA: 0s - loss: 0.5951 - acc: 0.886 - ETA: 0s - loss: 0.5965 - acc: 0.885 - ETA: 0s - loss: 0.5957 - acc: 0.885 - ETA: 0s - loss: 0.5963 - acc: 0.885 - 1s 8us/step - loss: 0.5965 - acc: 0.8852 - val_loss: 0.3417 - val_acc: 0.8732\n",
      "Epoch 74/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5271 - acc: 0.883 - ETA: 0s - loss: 0.5830 - acc: 0.888 - ETA: 0s - loss: 0.5968 - acc: 0.883 - ETA: 0s - loss: 0.6018 - acc: 0.882 - ETA: 0s - loss: 0.5972 - acc: 0.883 - ETA: 0s - loss: 0.5972 - acc: 0.883 - ETA: 0s - loss: 0.5948 - acc: 0.883 - ETA: 0s - loss: 0.5973 - acc: 0.882 - 1s 8us/step - loss: 0.5967 - acc: 0.8821 - val_loss: 0.3333 - val_acc: 0.8812\n",
      "Epoch 75/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6155 - acc: 0.897 - ETA: 0s - loss: 0.6138 - acc: 0.881 - ETA: 0s - loss: 0.6067 - acc: 0.880 - ETA: 0s - loss: 0.6053 - acc: 0.881 - ETA: 0s - loss: 0.6060 - acc: 0.880 - ETA: 0s - loss: 0.6030 - acc: 0.883 - ETA: 0s - loss: 0.5997 - acc: 0.883 - ETA: 0s - loss: 0.6007 - acc: 0.883 - 1s 8us/step - loss: 0.6002 - acc: 0.8830 - val_loss: 0.3441 - val_acc: 0.8764\n",
      "Epoch 76/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6066 - acc: 0.889 - ETA: 0s - loss: 0.5872 - acc: 0.889 - ETA: 0s - loss: 0.6042 - acc: 0.882 - ETA: 0s - loss: 0.5937 - acc: 0.883 - ETA: 0s - loss: 0.6006 - acc: 0.882 - ETA: 0s - loss: 0.6020 - acc: 0.883 - ETA: 0s - loss: 0.6006 - acc: 0.882 - ETA: 0s - loss: 0.5982 - acc: 0.883 - 1s 8us/step - loss: 0.5984 - acc: 0.8836 - val_loss: 0.3494 - val_acc: 0.8635\n",
      "Epoch 77/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5975 - acc: 0.865 - ETA: 0s - loss: 0.5588 - acc: 0.890 - ETA: 0s - loss: 0.5793 - acc: 0.886 - ETA: 0s - loss: 0.5846 - acc: 0.886 - ETA: 0s - loss: 0.5844 - acc: 0.884 - ETA: 0s - loss: 0.5838 - acc: 0.884 - ETA: 0s - loss: 0.5900 - acc: 0.883 - ETA: 0s - loss: 0.5919 - acc: 0.883 - 1s 8us/step - loss: 0.5931 - acc: 0.8836 - val_loss: 0.3445 - val_acc: 0.8669\n",
      "Epoch 78/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5837 - acc: 0.897 - ETA: 0s - loss: 0.5811 - acc: 0.883 - ETA: 0s - loss: 0.5829 - acc: 0.885 - ETA: 0s - loss: 0.5924 - acc: 0.884 - ETA: 0s - loss: 0.5950 - acc: 0.884 - ETA: 0s - loss: 0.5926 - acc: 0.885 - ETA: 0s - loss: 0.5946 - acc: 0.884 - ETA: 0s - loss: 0.5974 - acc: 0.883 - 1s 9us/step - loss: 0.5960 - acc: 0.8835 - val_loss: 0.3381 - val_acc: 0.8707\n",
      "Epoch 79/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6189 - acc: 0.887 - ETA: 0s - loss: 0.5917 - acc: 0.887 - ETA: 0s - loss: 0.6053 - acc: 0.884 - ETA: 0s - loss: 0.6039 - acc: 0.881 - ETA: 0s - loss: 0.6031 - acc: 0.882 - ETA: 0s - loss: 0.5995 - acc: 0.882 - ETA: 0s - loss: 0.5988 - acc: 0.882 - ETA: 0s - loss: 0.5974 - acc: 0.882 - 1s 8us/step - loss: 0.5965 - acc: 0.8826 - val_loss: 0.3381 - val_acc: 0.8729\n",
      "Epoch 80/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6476 - acc: 0.879 - ETA: 0s - loss: 0.6016 - acc: 0.880 - ETA: 0s - loss: 0.6044 - acc: 0.881 - ETA: 0s - loss: 0.5988 - acc: 0.882 - ETA: 0s - loss: 0.6020 - acc: 0.882 - ETA: 0s - loss: 0.6015 - acc: 0.883 - ETA: 0s - loss: 0.6041 - acc: 0.881 - ETA: 0s - loss: 0.6015 - acc: 0.882 - 1s 8us/step - loss: 0.6027 - acc: 0.8828 - val_loss: 0.3387 - val_acc: 0.8782\n",
      "Epoch 81/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5288 - acc: 0.901 - ETA: 0s - loss: 0.5843 - acc: 0.887 - ETA: 0s - loss: 0.5956 - acc: 0.886 - ETA: 0s - loss: 0.5859 - acc: 0.889 - ETA: 0s - loss: 0.5904 - acc: 0.886 - ETA: 0s - loss: 0.5962 - acc: 0.885 - ETA: 0s - loss: 0.5959 - acc: 0.884 - ETA: 0s - loss: 0.5993 - acc: 0.884 - 1s 9us/step - loss: 0.5987 - acc: 0.8851 - val_loss: 0.3424 - val_acc: 0.8690\n",
      "Epoch 82/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5808 - acc: 0.881 - ETA: 0s - loss: 0.6070 - acc: 0.874 - ETA: 0s - loss: 0.6002 - acc: 0.880 - ETA: 0s - loss: 0.6006 - acc: 0.881 - ETA: 0s - loss: 0.5994 - acc: 0.881 - ETA: 0s - loss: 0.5963 - acc: 0.883 - ETA: 0s - loss: 0.5966 - acc: 0.883 - ETA: 0s - loss: 0.5941 - acc: 0.884 - 1s 8us/step - loss: 0.5941 - acc: 0.8834 - val_loss: 0.3212 - val_acc: 0.8820\n",
      "Epoch 83/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6351 - acc: 0.894 - ETA: 0s - loss: 0.5937 - acc: 0.884 - ETA: 0s - loss: 0.5949 - acc: 0.884 - ETA: 0s - loss: 0.5991 - acc: 0.886 - ETA: 0s - loss: 0.6032 - acc: 0.885 - ETA: 0s - loss: 0.6004 - acc: 0.886 - ETA: 0s - loss: 0.5950 - acc: 0.885 - ETA: 0s - loss: 0.5963 - acc: 0.885 - 1s 9us/step - loss: 0.5972 - acc: 0.8850 - val_loss: 0.3429 - val_acc: 0.8748\n",
      "Epoch 84/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6063 - acc: 0.871 - ETA: 0s - loss: 0.5872 - acc: 0.889 - ETA: 0s - loss: 0.5930 - acc: 0.886 - ETA: 0s - loss: 0.5959 - acc: 0.885 - ETA: 0s - loss: 0.5977 - acc: 0.884 - ETA: 0s - loss: 0.5954 - acc: 0.886 - ETA: 0s - loss: 0.5993 - acc: 0.884 - ETA: 0s - loss: 0.6000 - acc: 0.883 - 1s 9us/step - loss: 0.6007 - acc: 0.8836 - val_loss: 0.3425 - val_acc: 0.8721\n",
      "Epoch 85/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6265 - acc: 0.868 - ETA: 0s - loss: 0.6038 - acc: 0.880 - ETA: 0s - loss: 0.5950 - acc: 0.883 - ETA: 0s - loss: 0.5968 - acc: 0.883 - ETA: 0s - loss: 0.5921 - acc: 0.883 - ETA: 0s - loss: 0.5910 - acc: 0.885 - ETA: 0s - loss: 0.5903 - acc: 0.885 - ETA: 0s - loss: 0.5943 - acc: 0.885 - 1s 9us/step - loss: 0.5944 - acc: 0.8846 - val_loss: 0.3485 - val_acc: 0.8713\n",
      "Epoch 86/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6185 - acc: 0.890 - ETA: 0s - loss: 0.6184 - acc: 0.885 - ETA: 0s - loss: 0.6126 - acc: 0.879 - ETA: 0s - loss: 0.6115 - acc: 0.883 - ETA: 0s - loss: 0.6042 - acc: 0.884 - ETA: 0s - loss: 0.5994 - acc: 0.884 - ETA: 0s - loss: 0.5970 - acc: 0.885 - ETA: 0s - loss: 0.5948 - acc: 0.886 - ETA: 0s - loss: 0.5965 - acc: 0.885 - 1s 9us/step - loss: 0.5979 - acc: 0.8852 - val_loss: 0.3711 - val_acc: 0.8607\n",
      "Epoch 87/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6717 - acc: 0.872 - ETA: 0s - loss: 0.6277 - acc: 0.881 - ETA: 0s - loss: 0.6031 - acc: 0.885 - ETA: 0s - loss: 0.6049 - acc: 0.884 - ETA: 0s - loss: 0.6013 - acc: 0.885 - ETA: 0s - loss: 0.5958 - acc: 0.884 - ETA: 0s - loss: 0.5962 - acc: 0.885 - ETA: 0s - loss: 0.5939 - acc: 0.885 - 1s 9us/step - loss: 0.5953 - acc: 0.8852 - val_loss: 0.3437 - val_acc: 0.8702\n",
      "Epoch 88/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5248 - acc: 0.902 - ETA: 0s - loss: 0.5532 - acc: 0.887 - ETA: 0s - loss: 0.5705 - acc: 0.886 - ETA: 0s - loss: 0.5795 - acc: 0.885 - ETA: 0s - loss: 0.5889 - acc: 0.884 - ETA: 0s - loss: 0.5894 - acc: 0.884 - ETA: 0s - loss: 0.5912 - acc: 0.884 - ETA: 0s - loss: 0.5931 - acc: 0.883 - 1s 8us/step - loss: 0.5957 - acc: 0.8832 - val_loss: 0.3396 - val_acc: 0.8724\n",
      "Epoch 89/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6542 - acc: 0.880 - ETA: 0s - loss: 0.6049 - acc: 0.880 - ETA: 0s - loss: 0.6045 - acc: 0.880 - ETA: 0s - loss: 0.6030 - acc: 0.881 - ETA: 0s - loss: 0.6038 - acc: 0.883 - ETA: 0s - loss: 0.5995 - acc: 0.884 - ETA: 0s - loss: 0.5967 - acc: 0.883 - ETA: 0s - loss: 0.5990 - acc: 0.883 - 1s 9us/step - loss: 0.5974 - acc: 0.8839 - val_loss: 0.3209 - val_acc: 0.8771\n",
      "Epoch 90/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6364 - acc: 0.889 - ETA: 0s - loss: 0.5968 - acc: 0.880 - ETA: 0s - loss: 0.6022 - acc: 0.879 - ETA: 0s - loss: 0.5894 - acc: 0.884 - ETA: 0s - loss: 0.5899 - acc: 0.884 - ETA: 0s - loss: 0.5926 - acc: 0.884 - ETA: 0s - loss: 0.5943 - acc: 0.883 - ETA: 0s - loss: 0.5986 - acc: 0.882 - 1s 9us/step - loss: 0.5961 - acc: 0.8831 - val_loss: 0.3115 - val_acc: 0.8832\n",
      "Epoch 91/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6663 - acc: 0.902 - ETA: 0s - loss: 0.6086 - acc: 0.882 - ETA: 0s - loss: 0.5844 - acc: 0.887 - ETA: 0s - loss: 0.5865 - acc: 0.886 - ETA: 0s - loss: 0.5859 - acc: 0.888 - ETA: 0s - loss: 0.5892 - acc: 0.885 - ETA: 0s - loss: 0.5871 - acc: 0.885 - ETA: 0s - loss: 0.5876 - acc: 0.885 - 1s 9us/step - loss: 0.5918 - acc: 0.8842 - val_loss: 0.3449 - val_acc: 0.8694\n",
      "Epoch 92/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5834 - acc: 0.886 - ETA: 0s - loss: 0.5764 - acc: 0.891 - ETA: 0s - loss: 0.5899 - acc: 0.885 - ETA: 0s - loss: 0.5926 - acc: 0.884 - ETA: 0s - loss: 0.5935 - acc: 0.885 - ETA: 0s - loss: 0.5980 - acc: 0.883 - ETA: 0s - loss: 0.5957 - acc: 0.883 - ETA: 0s - loss: 0.5963 - acc: 0.883 - 1s 9us/step - loss: 0.5942 - acc: 0.8844 - val_loss: 0.3150 - val_acc: 0.8834\n",
      "Epoch 93/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6195 - acc: 0.882 - ETA: 0s - loss: 0.5995 - acc: 0.881 - ETA: 0s - loss: 0.5838 - acc: 0.884 - ETA: 0s - loss: 0.5913 - acc: 0.883 - ETA: 0s - loss: 0.5914 - acc: 0.884 - ETA: 0s - loss: 0.5912 - acc: 0.884 - ETA: 0s - loss: 0.5951 - acc: 0.883 - ETA: 0s - loss: 0.5937 - acc: 0.883 - 1s 9us/step - loss: 0.5942 - acc: 0.8839 - val_loss: 0.3312 - val_acc: 0.8766\n",
      "Epoch 94/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5499 - acc: 0.903 - ETA: 0s - loss: 0.5926 - acc: 0.885 - ETA: 0s - loss: 0.5971 - acc: 0.883 - ETA: 0s - loss: 0.5904 - acc: 0.884 - ETA: 0s - loss: 0.5937 - acc: 0.883 - ETA: 0s - loss: 0.5958 - acc: 0.883 - ETA: 0s - loss: 0.5977 - acc: 0.882 - ETA: 0s - loss: 0.5960 - acc: 0.883 - 1s 9us/step - loss: 0.5970 - acc: 0.8835 - val_loss: 0.3394 - val_acc: 0.8735\n",
      "Epoch 95/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5359 - acc: 0.876 - ETA: 0s - loss: 0.5902 - acc: 0.882 - ETA: 0s - loss: 0.5915 - acc: 0.883 - ETA: 0s - loss: 0.5905 - acc: 0.884 - ETA: 0s - loss: 0.5942 - acc: 0.883 - ETA: 0s - loss: 0.5918 - acc: 0.884 - ETA: 0s - loss: 0.5985 - acc: 0.882 - ETA: 0s - loss: 0.6010 - acc: 0.882 - 1s 9us/step - loss: 0.5965 - acc: 0.8836 - val_loss: 0.3124 - val_acc: 0.8783\n",
      "Epoch 96/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6148 - acc: 0.884 - ETA: 0s - loss: 0.6101 - acc: 0.885 - ETA: 0s - loss: 0.6026 - acc: 0.884 - ETA: 0s - loss: 0.5959 - acc: 0.886 - ETA: 0s - loss: 0.5927 - acc: 0.885 - ETA: 0s - loss: 0.5897 - acc: 0.886 - ETA: 0s - loss: 0.5914 - acc: 0.885 - ETA: 0s - loss: 0.5948 - acc: 0.885 - 1s 9us/step - loss: 0.5957 - acc: 0.8841 - val_loss: 0.3163 - val_acc: 0.8833\n",
      "Epoch 97/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5939 - acc: 0.898 - ETA: 0s - loss: 0.5977 - acc: 0.884 - ETA: 0s - loss: 0.6011 - acc: 0.883 - ETA: 0s - loss: 0.6009 - acc: 0.883 - ETA: 0s - loss: 0.6008 - acc: 0.882 - ETA: 0s - loss: 0.6039 - acc: 0.882 - ETA: 0s - loss: 0.6047 - acc: 0.881 - ETA: 0s - loss: 0.6016 - acc: 0.881 - 1s 9us/step - loss: 0.6002 - acc: 0.8821 - val_loss: 0.3265 - val_acc: 0.8796\n",
      "Epoch 98/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6450 - acc: 0.887 - ETA: 0s - loss: 0.5943 - acc: 0.881 - ETA: 0s - loss: 0.6020 - acc: 0.880 - ETA: 0s - loss: 0.5988 - acc: 0.882 - ETA: 0s - loss: 0.5874 - acc: 0.882 - ETA: 0s - loss: 0.5927 - acc: 0.881 - ETA: 0s - loss: 0.5954 - acc: 0.883 - ETA: 0s - loss: 0.5979 - acc: 0.882 - 1s 9us/step - loss: 0.5943 - acc: 0.8838 - val_loss: 0.3354 - val_acc: 0.8721\n",
      "Epoch 99/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6018 - acc: 0.885 - ETA: 0s - loss: 0.5983 - acc: 0.888 - ETA: 0s - loss: 0.5996 - acc: 0.883 - ETA: 0s - loss: 0.5938 - acc: 0.884 - ETA: 0s - loss: 0.5948 - acc: 0.884 - ETA: 0s - loss: 0.5974 - acc: 0.883 - ETA: 0s - loss: 0.5995 - acc: 0.884 - ETA: 0s - loss: 0.5956 - acc: 0.884 - 1s 9us/step - loss: 0.5959 - acc: 0.8841 - val_loss: 0.3362 - val_acc: 0.8742\n",
      "Epoch 100/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5830 - acc: 0.877 - ETA: 0s - loss: 0.5840 - acc: 0.889 - ETA: 0s - loss: 0.5945 - acc: 0.882 - ETA: 0s - loss: 0.5959 - acc: 0.884 - ETA: 0s - loss: 0.5943 - acc: 0.885 - ETA: 0s - loss: 0.5940 - acc: 0.884 - ETA: 0s - loss: 0.5909 - acc: 0.885 - ETA: 0s - loss: 0.5925 - acc: 0.885 - 1s 9us/step - loss: 0.5942 - acc: 0.8858 - val_loss: 0.3536 - val_acc: 0.8690\n",
      "Epoch 101/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6264 - acc: 0.877 - ETA: 0s - loss: 0.5962 - acc: 0.884 - ETA: 0s - loss: 0.5980 - acc: 0.883 - ETA: 0s - loss: 0.6001 - acc: 0.884 - ETA: 0s - loss: 0.5974 - acc: 0.884 - ETA: 0s - loss: 0.5916 - acc: 0.884 - ETA: 0s - loss: 0.5935 - acc: 0.883 - ETA: 0s - loss: 0.5976 - acc: 0.883 - 1s 9us/step - loss: 0.5937 - acc: 0.8840 - val_loss: 0.3284 - val_acc: 0.8743\n",
      "Epoch 102/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6418 - acc: 0.880 - ETA: 0s - loss: 0.6253 - acc: 0.880 - ETA: 0s - loss: 0.6181 - acc: 0.884 - ETA: 0s - loss: 0.6146 - acc: 0.881 - ETA: 0s - loss: 0.6092 - acc: 0.881 - ETA: 0s - loss: 0.6083 - acc: 0.881 - ETA: 0s - loss: 0.6051 - acc: 0.882 - ETA: 0s - loss: 0.6011 - acc: 0.882 - 1s 8us/step - loss: 0.6006 - acc: 0.8832 - val_loss: 0.3353 - val_acc: 0.8737\n",
      "Epoch 103/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6046 - acc: 0.897 - ETA: 0s - loss: 0.5834 - acc: 0.887 - ETA: 0s - loss: 0.5983 - acc: 0.884 - ETA: 0s - loss: 0.5971 - acc: 0.883 - ETA: 0s - loss: 0.5967 - acc: 0.883 - ETA: 0s - loss: 0.6003 - acc: 0.883 - ETA: 0s - loss: 0.5959 - acc: 0.884 - ETA: 0s - loss: 0.5956 - acc: 0.885 - 1s 8us/step - loss: 0.5972 - acc: 0.8850 - val_loss: 0.3429 - val_acc: 0.8764\n",
      "Epoch 104/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5318 - acc: 0.895 - ETA: 0s - loss: 0.6060 - acc: 0.885 - ETA: 0s - loss: 0.6064 - acc: 0.883 - ETA: 0s - loss: 0.6080 - acc: 0.883 - ETA: 0s - loss: 0.6075 - acc: 0.883 - ETA: 0s - loss: 0.6000 - acc: 0.885 - ETA: 0s - loss: 0.6024 - acc: 0.883 - ETA: 0s - loss: 0.5997 - acc: 0.884 - ETA: 0s - loss: 0.5973 - acc: 0.884 - 1s 9us/step - loss: 0.5975 - acc: 0.8844 - val_loss: 0.3387 - val_acc: 0.8702\n",
      "Epoch 105/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6276 - acc: 0.888 - ETA: 0s - loss: 0.5888 - acc: 0.888 - ETA: 0s - loss: 0.5954 - acc: 0.884 - ETA: 0s - loss: 0.5925 - acc: 0.885 - ETA: 0s - loss: 0.5913 - acc: 0.885 - ETA: 0s - loss: 0.5918 - acc: 0.883 - ETA: 0s - loss: 0.5932 - acc: 0.884 - ETA: 0s - loss: 0.5981 - acc: 0.883 - 1s 9us/step - loss: 0.5985 - acc: 0.8839 - val_loss: 0.3232 - val_acc: 0.8775\n",
      "Epoch 106/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5970 - acc: 0.871 - ETA: 0s - loss: 0.5991 - acc: 0.880 - ETA: 0s - loss: 0.5985 - acc: 0.886 - ETA: 0s - loss: 0.6050 - acc: 0.881 - ETA: 0s - loss: 0.5990 - acc: 0.882 - ETA: 0s - loss: 0.5965 - acc: 0.882 - ETA: 0s - loss: 0.5958 - acc: 0.883 - ETA: 0s - loss: 0.5945 - acc: 0.884 - 1s 9us/step - loss: 0.5932 - acc: 0.8845 - val_loss: 0.3242 - val_acc: 0.8762\n",
      "Epoch 107/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5226 - acc: 0.902 - ETA: 0s - loss: 0.5783 - acc: 0.890 - ETA: 0s - loss: 0.5917 - acc: 0.887 - ETA: 0s - loss: 0.5857 - acc: 0.886 - ETA: 0s - loss: 0.5885 - acc: 0.887 - ETA: 0s - loss: 0.5913 - acc: 0.884 - ETA: 0s - loss: 0.5924 - acc: 0.884 - ETA: 0s - loss: 0.5937 - acc: 0.884 - ETA: 0s - loss: 0.5923 - acc: 0.884 - 1s 9us/step - loss: 0.5924 - acc: 0.8841 - val_loss: 0.3312 - val_acc: 0.8758\n",
      "Epoch 108/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6143 - acc: 0.877 - ETA: 0s - loss: 0.5969 - acc: 0.886 - ETA: 0s - loss: 0.5866 - acc: 0.885 - ETA: 0s - loss: 0.5929 - acc: 0.885 - ETA: 0s - loss: 0.5954 - acc: 0.883 - ETA: 0s - loss: 0.5946 - acc: 0.883 - ETA: 0s - loss: 0.5975 - acc: 0.884 - ETA: 0s - loss: 0.5964 - acc: 0.884 - 1s 9us/step - loss: 0.5953 - acc: 0.8852 - val_loss: 0.3333 - val_acc: 0.8691\n",
      "Epoch 109/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6642 - acc: 0.875 - ETA: 0s - loss: 0.6219 - acc: 0.883 - ETA: 0s - loss: 0.6042 - acc: 0.885 - ETA: 0s - loss: 0.5963 - acc: 0.884 - ETA: 0s - loss: 0.5973 - acc: 0.883 - ETA: 0s - loss: 0.6008 - acc: 0.883 - ETA: 0s - loss: 0.5981 - acc: 0.884 - ETA: 0s - loss: 0.5952 - acc: 0.884 - 1s 9us/step - loss: 0.5938 - acc: 0.8854 - val_loss: 0.3312 - val_acc: 0.8774\n",
      "Epoch 110/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5987 - acc: 0.890 - ETA: 0s - loss: 0.5975 - acc: 0.888 - ETA: 0s - loss: 0.5969 - acc: 0.886 - ETA: 0s - loss: 0.5974 - acc: 0.886 - ETA: 0s - loss: 0.5963 - acc: 0.885 - ETA: 0s - loss: 0.5999 - acc: 0.885 - ETA: 0s - loss: 0.6000 - acc: 0.884 - ETA: 0s - loss: 0.5987 - acc: 0.884 - 1s 9us/step - loss: 0.5979 - acc: 0.8847 - val_loss: 0.3223 - val_acc: 0.8768\n",
      "Epoch 111/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5760 - acc: 0.882 - ETA: 0s - loss: 0.5781 - acc: 0.885 - ETA: 0s - loss: 0.5876 - acc: 0.885 - ETA: 0s - loss: 0.5840 - acc: 0.883 - ETA: 0s - loss: 0.5907 - acc: 0.883 - ETA: 0s - loss: 0.5916 - acc: 0.883 - ETA: 0s - loss: 0.5955 - acc: 0.883 - ETA: 0s - loss: 0.5957 - acc: 0.883 - 1s 8us/step - loss: 0.5957 - acc: 0.8838 - val_loss: 0.3314 - val_acc: 0.8816\n",
      "Epoch 112/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6083 - acc: 0.894 - ETA: 0s - loss: 0.6086 - acc: 0.880 - ETA: 0s - loss: 0.5942 - acc: 0.887 - ETA: 0s - loss: 0.5975 - acc: 0.884 - ETA: 0s - loss: 0.5990 - acc: 0.883 - ETA: 0s - loss: 0.5995 - acc: 0.883 - ETA: 0s - loss: 0.5970 - acc: 0.883 - ETA: 0s - loss: 0.5980 - acc: 0.883 - 1s 8us/step - loss: 0.5975 - acc: 0.8838 - val_loss: 0.3314 - val_acc: 0.8772\n",
      "Epoch 113/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6681 - acc: 0.876 - ETA: 0s - loss: 0.5996 - acc: 0.878 - ETA: 0s - loss: 0.6020 - acc: 0.882 - ETA: 0s - loss: 0.5924 - acc: 0.883 - ETA: 0s - loss: 0.5897 - acc: 0.884 - ETA: 0s - loss: 0.5948 - acc: 0.883 - ETA: 0s - loss: 0.5929 - acc: 0.883 - ETA: 0s - loss: 0.5934 - acc: 0.884 - 1s 8us/step - loss: 0.5940 - acc: 0.8837 - val_loss: 0.3381 - val_acc: 0.8712\n",
      "Epoch 114/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6542 - acc: 0.889 - ETA: 0s - loss: 0.6069 - acc: 0.883 - ETA: 0s - loss: 0.6142 - acc: 0.881 - ETA: 0s - loss: 0.6034 - acc: 0.884 - ETA: 0s - loss: 0.6005 - acc: 0.884 - ETA: 0s - loss: 0.5973 - acc: 0.885 - ETA: 0s - loss: 0.5943 - acc: 0.885 - ETA: 0s - loss: 0.5932 - acc: 0.884 - 1s 9us/step - loss: 0.5955 - acc: 0.8850 - val_loss: 0.3384 - val_acc: 0.8793\n",
      "Epoch 115/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6300 - acc: 0.890 - ETA: 0s - loss: 0.6082 - acc: 0.877 - ETA: 0s - loss: 0.6055 - acc: 0.881 - ETA: 0s - loss: 0.6027 - acc: 0.881 - ETA: 0s - loss: 0.6022 - acc: 0.882 - ETA: 0s - loss: 0.6037 - acc: 0.882 - ETA: 0s - loss: 0.6007 - acc: 0.883 - ETA: 0s - loss: 0.5968 - acc: 0.883 - 1s 8us/step - loss: 0.5965 - acc: 0.8841 - val_loss: 0.3413 - val_acc: 0.8734\n",
      "Epoch 116/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5136 - acc: 0.896 - ETA: 0s - loss: 0.5862 - acc: 0.883 - ETA: 0s - loss: 0.5863 - acc: 0.884 - ETA: 0s - loss: 0.5928 - acc: 0.882 - ETA: 0s - loss: 0.5883 - acc: 0.883 - ETA: 0s - loss: 0.5840 - acc: 0.884 - ETA: 0s - loss: 0.5905 - acc: 0.883 - ETA: 0s - loss: 0.5895 - acc: 0.884 - 1s 9us/step - loss: 0.5931 - acc: 0.8833 - val_loss: 0.3628 - val_acc: 0.8643\n",
      "Epoch 117/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5642 - acc: 0.888 - ETA: 0s - loss: 0.6035 - acc: 0.880 - ETA: 0s - loss: 0.5967 - acc: 0.884 - ETA: 0s - loss: 0.6049 - acc: 0.882 - ETA: 0s - loss: 0.6010 - acc: 0.882 - ETA: 0s - loss: 0.5952 - acc: 0.884 - ETA: 0s - loss: 0.5961 - acc: 0.885 - ETA: 0s - loss: 0.5952 - acc: 0.884 - 1s 9us/step - loss: 0.5938 - acc: 0.8849 - val_loss: 0.3246 - val_acc: 0.8746\n",
      "Epoch 118/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5733 - acc: 0.883 - ETA: 0s - loss: 0.5773 - acc: 0.884 - ETA: 0s - loss: 0.5716 - acc: 0.885 - ETA: 0s - loss: 0.5848 - acc: 0.881 - ETA: 0s - loss: 0.5959 - acc: 0.883 - ETA: 0s - loss: 0.5947 - acc: 0.883 - ETA: 0s - loss: 0.5956 - acc: 0.883 - ETA: 0s - loss: 0.5964 - acc: 0.884 - 1s 9us/step - loss: 0.5944 - acc: 0.8841 - val_loss: 0.3322 - val_acc: 0.8703\n",
      "Epoch 119/150\n",
      "68000/68000 [==============================] - ETA: 1s - loss: 0.5754 - acc: 0.882 - ETA: 0s - loss: 0.5853 - acc: 0.888 - ETA: 0s - loss: 0.5884 - acc: 0.882 - ETA: 0s - loss: 0.5841 - acc: 0.883 - ETA: 0s - loss: 0.5847 - acc: 0.883 - ETA: 0s - loss: 0.5898 - acc: 0.883 - ETA: 0s - loss: 0.5920 - acc: 0.884 - ETA: 0s - loss: 0.5918 - acc: 0.883 - 1s 9us/step - loss: 0.5946 - acc: 0.8838 - val_loss: 0.3390 - val_acc: 0.8736\n",
      "Epoch 120/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5944 - acc: 0.877 - ETA: 0s - loss: 0.5910 - acc: 0.882 - ETA: 0s - loss: 0.5941 - acc: 0.885 - ETA: 0s - loss: 0.5964 - acc: 0.885 - ETA: 0s - loss: 0.5947 - acc: 0.884 - ETA: 0s - loss: 0.5971 - acc: 0.886 - ETA: 0s - loss: 0.5963 - acc: 0.884 - ETA: 0s - loss: 0.5963 - acc: 0.884 - 1s 9us/step - loss: 0.5972 - acc: 0.8838 - val_loss: 0.3444 - val_acc: 0.8729\n",
      "Epoch 121/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6113 - acc: 0.897 - ETA: 0s - loss: 0.5915 - acc: 0.883 - ETA: 0s - loss: 0.6002 - acc: 0.882 - ETA: 0s - loss: 0.5930 - acc: 0.885 - ETA: 0s - loss: 0.5966 - acc: 0.885 - ETA: 0s - loss: 0.5957 - acc: 0.884 - ETA: 0s - loss: 0.5973 - acc: 0.884 - ETA: 0s - loss: 0.5945 - acc: 0.885 - 1s 8us/step - loss: 0.5924 - acc: 0.8857 - val_loss: 0.3386 - val_acc: 0.8651\n",
      "Epoch 122/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5266 - acc: 0.888 - ETA: 0s - loss: 0.5745 - acc: 0.889 - ETA: 0s - loss: 0.5873 - acc: 0.885 - ETA: 0s - loss: 0.5870 - acc: 0.883 - ETA: 0s - loss: 0.5905 - acc: 0.885 - ETA: 0s - loss: 0.5901 - acc: 0.884 - ETA: 0s - loss: 0.5935 - acc: 0.884 - ETA: 0s - loss: 0.5904 - acc: 0.884 - 1s 9us/step - loss: 0.5928 - acc: 0.8852 - val_loss: 0.3630 - val_acc: 0.8643\n",
      "Epoch 123/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5439 - acc: 0.885 - ETA: 0s - loss: 0.5762 - acc: 0.892 - ETA: 0s - loss: 0.5903 - acc: 0.885 - ETA: 0s - loss: 0.5928 - acc: 0.887 - ETA: 0s - loss: 0.5914 - acc: 0.887 - ETA: 0s - loss: 0.5876 - acc: 0.886 - ETA: 0s - loss: 0.5920 - acc: 0.885 - ETA: 0s - loss: 0.5939 - acc: 0.885 - 1s 9us/step - loss: 0.5958 - acc: 0.8850 - val_loss: 0.3374 - val_acc: 0.8699\n",
      "Epoch 124/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5387 - acc: 0.891 - ETA: 0s - loss: 0.5843 - acc: 0.879 - ETA: 0s - loss: 0.5872 - acc: 0.881 - ETA: 0s - loss: 0.5962 - acc: 0.880 - ETA: 0s - loss: 0.6036 - acc: 0.879 - ETA: 0s - loss: 0.6006 - acc: 0.881 - ETA: 0s - loss: 0.5946 - acc: 0.882 - ETA: 0s - loss: 0.5939 - acc: 0.882 - 1s 8us/step - loss: 0.5940 - acc: 0.8824 - val_loss: 0.3134 - val_acc: 0.8842\n",
      "Epoch 125/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6081 - acc: 0.897 - ETA: 0s - loss: 0.6234 - acc: 0.878 - ETA: 0s - loss: 0.6040 - acc: 0.884 - ETA: 0s - loss: 0.6026 - acc: 0.881 - ETA: 0s - loss: 0.5987 - acc: 0.884 - ETA: 0s - loss: 0.5937 - acc: 0.884 - ETA: 0s - loss: 0.5915 - acc: 0.885 - ETA: 0s - loss: 0.5932 - acc: 0.884 - 1s 8us/step - loss: 0.5920 - acc: 0.8853 - val_loss: 0.3435 - val_acc: 0.8700\n",
      "Epoch 126/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6083 - acc: 0.869 - ETA: 0s - loss: 0.5925 - acc: 0.877 - ETA: 0s - loss: 0.5986 - acc: 0.882 - ETA: 0s - loss: 0.5991 - acc: 0.883 - ETA: 0s - loss: 0.5943 - acc: 0.884 - ETA: 0s - loss: 0.5981 - acc: 0.883 - ETA: 0s - loss: 0.5985 - acc: 0.883 - ETA: 0s - loss: 0.5971 - acc: 0.883 - 1s 8us/step - loss: 0.5968 - acc: 0.8840 - val_loss: 0.3370 - val_acc: 0.8713\n",
      "Epoch 127/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6149 - acc: 0.896 - ETA: 0s - loss: 0.5769 - acc: 0.876 - ETA: 0s - loss: 0.5909 - acc: 0.881 - ETA: 0s - loss: 0.5931 - acc: 0.881 - ETA: 0s - loss: 0.5886 - acc: 0.884 - ETA: 0s - loss: 0.5942 - acc: 0.883 - ETA: 0s - loss: 0.5948 - acc: 0.883 - ETA: 0s - loss: 0.5960 - acc: 0.883 - 1s 8us/step - loss: 0.5950 - acc: 0.8836 - val_loss: 0.3262 - val_acc: 0.8778\n",
      "Epoch 128/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5654 - acc: 0.890 - ETA: 0s - loss: 0.5823 - acc: 0.888 - ETA: 0s - loss: 0.5984 - acc: 0.885 - ETA: 0s - loss: 0.5974 - acc: 0.884 - ETA: 0s - loss: 0.5899 - acc: 0.885 - ETA: 0s - loss: 0.5946 - acc: 0.885 - ETA: 0s - loss: 0.6006 - acc: 0.884 - ETA: 0s - loss: 0.5970 - acc: 0.885 - 1s 8us/step - loss: 0.5987 - acc: 0.8847 - val_loss: 0.3570 - val_acc: 0.8611\n",
      "Epoch 129/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6397 - acc: 0.868 - ETA: 0s - loss: 0.5950 - acc: 0.886 - ETA: 0s - loss: 0.6019 - acc: 0.882 - ETA: 0s - loss: 0.6087 - acc: 0.884 - ETA: 0s - loss: 0.6095 - acc: 0.882 - ETA: 0s - loss: 0.6042 - acc: 0.883 - ETA: 0s - loss: 0.6032 - acc: 0.884 - ETA: 0s - loss: 0.6012 - acc: 0.883 - 1s 9us/step - loss: 0.5976 - acc: 0.8844 - val_loss: 0.3480 - val_acc: 0.8667\n",
      "Epoch 130/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5936 - acc: 0.880 - ETA: 0s - loss: 0.5823 - acc: 0.884 - ETA: 0s - loss: 0.5790 - acc: 0.886 - ETA: 0s - loss: 0.5902 - acc: 0.885 - ETA: 0s - loss: 0.5886 - acc: 0.887 - ETA: 0s - loss: 0.5899 - acc: 0.884 - ETA: 0s - loss: 0.5937 - acc: 0.884 - ETA: 0s - loss: 0.5931 - acc: 0.884 - 1s 9us/step - loss: 0.5948 - acc: 0.8842 - val_loss: 0.3264 - val_acc: 0.8796\n",
      "Epoch 131/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6699 - acc: 0.881 - ETA: 0s - loss: 0.5948 - acc: 0.883 - ETA: 0s - loss: 0.5872 - acc: 0.885 - ETA: 0s - loss: 0.5907 - acc: 0.883 - ETA: 0s - loss: 0.5855 - acc: 0.883 - ETA: 0s - loss: 0.5919 - acc: 0.883 - ETA: 0s - loss: 0.5948 - acc: 0.882 - ETA: 0s - loss: 0.5951 - acc: 0.882 - 1s 8us/step - loss: 0.5946 - acc: 0.8837 - val_loss: 0.3367 - val_acc: 0.8737\n",
      "Epoch 132/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5869 - acc: 0.877 - ETA: 0s - loss: 0.5853 - acc: 0.882 - ETA: 0s - loss: 0.5911 - acc: 0.881 - ETA: 0s - loss: 0.6009 - acc: 0.882 - ETA: 0s - loss: 0.5989 - acc: 0.883 - ETA: 0s - loss: 0.6047 - acc: 0.882 - ETA: 0s - loss: 0.5981 - acc: 0.883 - ETA: 0s - loss: 0.5942 - acc: 0.884 - 1s 8us/step - loss: 0.5939 - acc: 0.8840 - val_loss: 0.3382 - val_acc: 0.8735\n",
      "Epoch 133/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5974 - acc: 0.880 - ETA: 0s - loss: 0.5903 - acc: 0.883 - ETA: 0s - loss: 0.5998 - acc: 0.879 - ETA: 0s - loss: 0.5980 - acc: 0.883 - ETA: 0s - loss: 0.5937 - acc: 0.884 - ETA: 0s - loss: 0.5926 - acc: 0.885 - ETA: 0s - loss: 0.5959 - acc: 0.883 - ETA: 0s - loss: 0.5942 - acc: 0.884 - 1s 8us/step - loss: 0.5959 - acc: 0.8839 - val_loss: 0.3477 - val_acc: 0.8675\n",
      "Epoch 134/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6222 - acc: 0.879 - ETA: 0s - loss: 0.5814 - acc: 0.886 - ETA: 0s - loss: 0.5853 - acc: 0.886 - ETA: 0s - loss: 0.5873 - acc: 0.887 - ETA: 0s - loss: 0.5929 - acc: 0.884 - ETA: 0s - loss: 0.5950 - acc: 0.885 - ETA: 0s - loss: 0.5949 - acc: 0.885 - ETA: 0s - loss: 0.5943 - acc: 0.885 - 1s 8us/step - loss: 0.5943 - acc: 0.8853 - val_loss: 0.3317 - val_acc: 0.8733\n",
      "Epoch 135/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6580 - acc: 0.878 - ETA: 0s - loss: 0.6174 - acc: 0.880 - ETA: 0s - loss: 0.5960 - acc: 0.883 - ETA: 0s - loss: 0.5904 - acc: 0.885 - ETA: 0s - loss: 0.5929 - acc: 0.884 - ETA: 0s - loss: 0.5974 - acc: 0.881 - ETA: 0s - loss: 0.5971 - acc: 0.881 - ETA: 0s - loss: 0.5997 - acc: 0.883 - 1s 8us/step - loss: 0.5979 - acc: 0.8819 - val_loss: 0.3489 - val_acc: 0.8667\n",
      "Epoch 136/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5746 - acc: 0.877 - ETA: 0s - loss: 0.5742 - acc: 0.889 - ETA: 0s - loss: 0.5823 - acc: 0.884 - ETA: 0s - loss: 0.5905 - acc: 0.881 - ETA: 0s - loss: 0.5958 - acc: 0.882 - ETA: 0s - loss: 0.5893 - acc: 0.884 - ETA: 0s - loss: 0.5935 - acc: 0.884 - ETA: 0s - loss: 0.5941 - acc: 0.884 - 1s 8us/step - loss: 0.5948 - acc: 0.8849 - val_loss: 0.3558 - val_acc: 0.8613\n",
      "Epoch 137/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6132 - acc: 0.870 - ETA: 0s - loss: 0.6117 - acc: 0.878 - ETA: 0s - loss: 0.5979 - acc: 0.883 - ETA: 0s - loss: 0.5926 - acc: 0.883 - ETA: 0s - loss: 0.5911 - acc: 0.884 - ETA: 0s - loss: 0.5925 - acc: 0.884 - ETA: 0s - loss: 0.5878 - acc: 0.885 - ETA: 0s - loss: 0.5933 - acc: 0.884 - 1s 8us/step - loss: 0.5927 - acc: 0.8853 - val_loss: 0.3213 - val_acc: 0.8828\n",
      "Epoch 138/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5609 - acc: 0.898 - ETA: 0s - loss: 0.5984 - acc: 0.880 - ETA: 0s - loss: 0.5958 - acc: 0.887 - ETA: 0s - loss: 0.5950 - acc: 0.886 - ETA: 0s - loss: 0.5968 - acc: 0.884 - ETA: 0s - loss: 0.5912 - acc: 0.886 - ETA: 0s - loss: 0.5879 - acc: 0.885 - ETA: 0s - loss: 0.5926 - acc: 0.883 - 1s 8us/step - loss: 0.5911 - acc: 0.8839 - val_loss: 0.3117 - val_acc: 0.8812\n",
      "Epoch 139/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5932 - acc: 0.884 - ETA: 0s - loss: 0.6010 - acc: 0.881 - ETA: 0s - loss: 0.5994 - acc: 0.883 - ETA: 0s - loss: 0.5980 - acc: 0.883 - ETA: 0s - loss: 0.5915 - acc: 0.883 - ETA: 0s - loss: 0.5974 - acc: 0.882 - ETA: 0s - loss: 0.5958 - acc: 0.883 - ETA: 0s - loss: 0.5983 - acc: 0.881 - 1s 9us/step - loss: 0.5986 - acc: 0.8821 - val_loss: 0.3083 - val_acc: 0.8877\n",
      "Epoch 140/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6225 - acc: 0.900 - ETA: 0s - loss: 0.6048 - acc: 0.884 - ETA: 0s - loss: 0.5896 - acc: 0.887 - ETA: 0s - loss: 0.5936 - acc: 0.884 - ETA: 0s - loss: 0.5941 - acc: 0.884 - ETA: 0s - loss: 0.5911 - acc: 0.884 - ETA: 0s - loss: 0.5889 - acc: 0.885 - ETA: 0s - loss: 0.5900 - acc: 0.885 - 1s 8us/step - loss: 0.5924 - acc: 0.8849 - val_loss: 0.3372 - val_acc: 0.8700\n",
      "Epoch 141/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5171 - acc: 0.881 - ETA: 0s - loss: 0.5873 - acc: 0.879 - ETA: 0s - loss: 0.5979 - acc: 0.881 - ETA: 0s - loss: 0.5995 - acc: 0.883 - ETA: 0s - loss: 0.5965 - acc: 0.884 - ETA: 0s - loss: 0.5929 - acc: 0.884 - ETA: 0s - loss: 0.5943 - acc: 0.884 - ETA: 0s - loss: 0.5945 - acc: 0.884 - 1s 8us/step - loss: 0.5961 - acc: 0.8845 - val_loss: 0.3464 - val_acc: 0.8670\n",
      "Epoch 142/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5709 - acc: 0.877 - ETA: 0s - loss: 0.5763 - acc: 0.887 - ETA: 0s - loss: 0.5838 - acc: 0.885 - ETA: 0s - loss: 0.5870 - acc: 0.886 - ETA: 0s - loss: 0.5916 - acc: 0.884 - ETA: 0s - loss: 0.5952 - acc: 0.883 - ETA: 0s - loss: 0.5979 - acc: 0.883 - ETA: 0s - loss: 0.5971 - acc: 0.883 - 1s 9us/step - loss: 0.5974 - acc: 0.8846 - val_loss: 0.3371 - val_acc: 0.8740\n",
      "Epoch 143/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6265 - acc: 0.875 - ETA: 0s - loss: 0.6148 - acc: 0.875 - ETA: 0s - loss: 0.6019 - acc: 0.883 - ETA: 0s - loss: 0.5990 - acc: 0.883 - ETA: 0s - loss: 0.6033 - acc: 0.883 - ETA: 0s - loss: 0.6019 - acc: 0.883 - ETA: 0s - loss: 0.5996 - acc: 0.882 - ETA: 0s - loss: 0.5998 - acc: 0.882 - 1s 8us/step - loss: 0.5982 - acc: 0.8831 - val_loss: 0.3363 - val_acc: 0.8698\n",
      "Epoch 144/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5756 - acc: 0.869 - ETA: 0s - loss: 0.6128 - acc: 0.876 - ETA: 0s - loss: 0.6065 - acc: 0.881 - ETA: 0s - loss: 0.6033 - acc: 0.880 - ETA: 0s - loss: 0.5975 - acc: 0.883 - ETA: 0s - loss: 0.5932 - acc: 0.883 - ETA: 0s - loss: 0.5952 - acc: 0.883 - ETA: 0s - loss: 0.5977 - acc: 0.883 - 1s 8us/step - loss: 0.5966 - acc: 0.8833 - val_loss: 0.3226 - val_acc: 0.8778\n",
      "Epoch 145/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6072 - acc: 0.890 - ETA: 0s - loss: 0.5749 - acc: 0.884 - ETA: 0s - loss: 0.5840 - acc: 0.883 - ETA: 0s - loss: 0.5977 - acc: 0.882 - ETA: 0s - loss: 0.5962 - acc: 0.883 - ETA: 0s - loss: 0.5932 - acc: 0.884 - ETA: 0s - loss: 0.5927 - acc: 0.885 - ETA: 0s - loss: 0.5929 - acc: 0.883 - 1s 8us/step - loss: 0.5933 - acc: 0.8845 - val_loss: 0.3337 - val_acc: 0.8746\n",
      "Epoch 146/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5987 - acc: 0.888 - ETA: 0s - loss: 0.5952 - acc: 0.878 - ETA: 0s - loss: 0.6117 - acc: 0.876 - ETA: 0s - loss: 0.6003 - acc: 0.880 - ETA: 0s - loss: 0.6038 - acc: 0.880 - ETA: 0s - loss: 0.6041 - acc: 0.881 - ETA: 0s - loss: 0.6026 - acc: 0.880 - ETA: 0s - loss: 0.5994 - acc: 0.882 - 1s 8us/step - loss: 0.5963 - acc: 0.8826 - val_loss: 0.3279 - val_acc: 0.8743\n",
      "Epoch 147/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5702 - acc: 0.886 - ETA: 0s - loss: 0.5863 - acc: 0.888 - ETA: 0s - loss: 0.6043 - acc: 0.886 - ETA: 0s - loss: 0.6001 - acc: 0.883 - ETA: 0s - loss: 0.5945 - acc: 0.884 - ETA: 0s - loss: 0.5943 - acc: 0.885 - ETA: 0s - loss: 0.5901 - acc: 0.886 - ETA: 0s - loss: 0.5907 - acc: 0.885 - 1s 8us/step - loss: 0.5919 - acc: 0.8847 - val_loss: 0.3402 - val_acc: 0.8708\n",
      "Epoch 148/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.5421 - acc: 0.890 - ETA: 0s - loss: 0.6050 - acc: 0.884 - ETA: 0s - loss: 0.6153 - acc: 0.880 - ETA: 0s - loss: 0.6011 - acc: 0.882 - ETA: 0s - loss: 0.5979 - acc: 0.882 - ETA: 0s - loss: 0.6021 - acc: 0.882 - ETA: 0s - loss: 0.5991 - acc: 0.883 - ETA: 0s - loss: 0.5971 - acc: 0.882 - 1s 8us/step - loss: 0.5959 - acc: 0.8827 - val_loss: 0.3215 - val_acc: 0.8806\n",
      "Epoch 149/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.6484 - acc: 0.886 - ETA: 0s - loss: 0.6109 - acc: 0.889 - ETA: 0s - loss: 0.5997 - acc: 0.887 - ETA: 0s - loss: 0.5960 - acc: 0.889 - ETA: 0s - loss: 0.5961 - acc: 0.886 - ETA: 0s - loss: 0.5995 - acc: 0.884 - ETA: 0s - loss: 0.5959 - acc: 0.884 - ETA: 0s - loss: 0.5941 - acc: 0.884 - 1s 9us/step - loss: 0.5923 - acc: 0.8847 - val_loss: 0.3230 - val_acc: 0.8780\n",
      "Epoch 150/150\n",
      "68000/68000 [==============================] - ETA: 0s - loss: 0.4932 - acc: 0.901 - ETA: 0s - loss: 0.6123 - acc: 0.878 - ETA: 0s - loss: 0.6043 - acc: 0.885 - ETA: 0s - loss: 0.6036 - acc: 0.884 - ETA: 0s - loss: 0.5973 - acc: 0.884 - ETA: 0s - loss: 0.5944 - acc: 0.884 - ETA: 0s - loss: 0.5914 - acc: 0.885 - ETA: 0s - loss: 0.5946 - acc: 0.884 - 1s 9us/step - loss: 0.5957 - acc: 0.8848 - val_loss: 0.3396 - val_acc: 0.8770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fb84953780>"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(PartA_X, PartA_Y,validation_data=(PartB_X, PartB_Y), epochs=150, batch_size=1000,class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
